---
description: Guidelines for managing and adding output formats
globs: 
alwaysApply: false
---
---
description: "Guidelines for managing and adding output formats"
globs: ["src/clipscribe/retrievers/**/*.py", "**/output*.py", "**/save*.py"]
alwaysApply: false
---

# Output Format Management

## Directory Structure (v2.17.0 Enhanced Temporal Intelligence)

ClipScribe uses a structured, machine-readable output format optimized for enhanced temporal intelligence:

```
output/
└── 20250624_youtube_DizuEaYDWBg/  # {date}_{platform}_{id}
    ├── manifest.json                    # File index and metadata
    ├── metadata.json                    # Video metadata
    ├── transcript.txt                   # Plain text transcript
    ├── transcript.json                  # Structured transcript with word-level timestamps
    ├── temporal_intelligence.json       # Enhanced temporal intelligence data
    ├── timeline.json                    # Temporal event timeline
    ├── entities.json                    # Entities with temporal context
    ├── relationships.json               # Entity relationships
    ├── knowledge_graph.json             # Graph structure with temporal intelligence
    ├── facts.txt                        # Key facts with temporal anchoring
    ├── report.md                        # Interactive markdown report with visualizations
    └── chimera_format.json              # Chimera-compatible format

# Video Retention (if enabled)
video_archive/
├── processed/
│   └── 20250624_youtube_DizuEaYDWBg.mp4  # Archived processed videos
└── failed/
    └── failed_videos_with_metadata.json

# Collections (multi-video)
collections/
└── {collection-id}/
    ├── collection_metadata.json
    ├── consolidated_timeline.json       # Cross-video timeline synthesis
    ├── unified_knowledge_graph.json     # Merged knowledge graph
    └── videos/                          # Individual video outputs
        ├── video1/
        └── video2/
```

## Adding New Formats

### 1. Define Format Function
```python
def _generate_markdown(self, video: VideoIntelligence) -> str:
    """Generate Markdown format output."""
    md_lines = [
        f"# {video.metadata.title}",
        f"**Channel:** {video.metadata.channel}",
        f"**Duration:** {video.metadata.duration // 60}:{video.metadata.duration % 60:02d}",
        "",
        "## Transcript",
        video.transcript.full_text,
        "",
        "## Key Points",
    ]
    
    for point in video.key_points:
        timestamp = f"{point.timestamp // 60}:{point.timestamp % 60:02d}"
        md_lines.append(f"- [{timestamp}] {point.text}")
    
    return "\n".join(md_lines)
```

### 2. Add to Save Method
```python
def save_all_formats(self, video: VideoIntelligence, output_dir: str):
    # ... existing formats ...
    
    # Markdown format
    if "md" in self.output_formats:
        md_path = paths["directory"] / "transcript.md"
        md_content = self._generate_markdown(video)
        with open(md_path, 'w', encoding='utf-8') as f:
            f.write(md_content)
        paths["markdown"] = md_path
```

### 3. Update Manifest
```python
# Add to manifest
if "markdown" in paths:
    manifest["files"]["markdown"] = {
        "path": "transcript.md",
        "format": "markdown",
        "size": os.path.getsize(paths["markdown"])
    }
```

## Format Generators

### Enhanced Temporal Intelligence Format (v2.17.0)
```python
def _generate_temporal_intelligence(self, video: VideoIntelligence) -> dict:
    """Generate enhanced temporal intelligence format."""
    return {
        "temporal_events": [
            {
                "event_id": event.event_id,
                "event_type": event.event_type,
                "timestamp": event.timestamp,
                "extracted_date": event.extracted_date,
                "date_source": event.date_source,
                "description": event.description,
                "confidence": event.confidence,
                "visual_indicators": event.visual_indicators,
                "context": event.context
            }
            for event in video.temporal_intelligence.temporal_events
        ],
        "visual_timestamps": [
            {
                "timestamp": vt.timestamp,
                "visual_text": vt.visual_text,
                "extracted_date": vt.extracted_date,
                "confidence": vt.confidence,
                "source_type": vt.source_type  # document, calendar, chyron, etc.
            }
            for vt in video.temporal_intelligence.visual_timestamps
        ],
        "transcript_segments": [
            {
                "start_time": segment.start_time,
                "end_time": segment.end_time,
                "text": segment.text,
                "speaker": segment.speaker,
                "temporal_references": segment.temporal_references,
                "entity_mentions": segment.entity_mentions
            }
            for segment in video.temporal_intelligence.transcript_segments
        ],
        "processing_metadata": {
            "enhancement_level": video.temporal_intelligence.enhancement_level,
            "processing_cost": video.temporal_intelligence.processing_cost,
            "extraction_timestamp": video.temporal_intelligence.extraction_timestamp.isoformat(),
            "visual_analysis_enabled": video.temporal_intelligence.visual_analysis_enabled
        }
    }
```

### Timeline Synthesis Format
```python
def _generate_timeline(self, timeline: ConsolidatedTimeline) -> dict:
    """Generate timeline synthesis format."""
    return {
        "timeline_id": timeline.timeline_id,
        "events": [
            {
                "event_id": event.event_id,
                "timestamp": event.timestamp.isoformat(),
                "title": event.title,
                "description": event.description,
                "event_type": event.event_type,
                "confidence": event.confidence,
                "source_videos": event.source_videos,
                "related_entities": event.related_entities,
                "temporal_context": event.temporal_context
            }
            for event in timeline.events
        ],
        "synthesis_metadata": {
            "total_events": len(timeline.events),
            "time_span": {
                "earliest_event": timeline.earliest_event.isoformat(),
                "latest_event": timeline.latest_event.isoformat()
            },
            "cross_video_correlations": timeline.cross_video_correlations,
            "synthesis_timestamp": timeline.synthesis_timestamp.isoformat()
        }
    }
```

## Specialized Formats

### Knowledge Graph Export
```python
def export_knowledge_graph(video: VideoIntelligence, format: str = "json"):
    """Export knowledge graph in various formats."""
    if format == "json":
        return {
            "nodes": [
                {"id": e.name, "type": e.type, "properties": e.properties}
                for e in video.entities
            ],
            "edges": [
                {"source": r.subject, "target": r.object, "type": r.predicate}
                for r in video.relationships
            ],
            "metadata": {
                "node_count": len(video.entities),
                "edge_count": len(video.relationships),
                "density": calculate_graph_density(video)
            }
        }
    elif format == "gexf":  # Gephi format
        return generate_gexf(video)
    elif format == "graphml":
        return generate_graphml(video)
```

### Chimera Format
```python
def _to_chimera_format(self, video: VideoIntelligence) -> Dict[str, Any]:
    """Convert to Chimera research agent format."""
    return {
        "type": "video",
        "source": "video_intelligence",
        "url": video.metadata.url,
        "title": video.metadata.title,
        "content": video.transcript.full_text,
        "summary": video.summary,
        "metadata": {
            "channel": video.metadata.channel,
            "duration": video.metadata.duration,
            "published_at": video.metadata.published_at.isoformat(),
            "key_points": [kp.dict() for kp in video.key_points],
            "entities": [e.dict() for e in video.entities],
            "processing_cost": video.processing_cost
        }
    }
```

## Filename Management

### Sanitization
```python
def sanitize_filename(text: str, max_length: int = 100) -> str:
    """Create safe filename from text."""
    # Remove invalid characters
    text = re.sub(r'[<>:"/\\|?*]', '', text)
    
    # Replace spaces with underscores
    text = text.replace(' ', '_')
    
    # Truncate if needed
    if len(text) > max_length:
        text = text[:max_length].rsplit('_', 1)[0]
    
    return text or "untitled"
```

### Structured Naming
```python
def create_output_structure(metadata: Dict[str, Any], base_dir: str) -> Dict[str, Path]:
    """Create structured output directory."""
    # Extract components
    date = datetime.now().strftime("%Y%m%d")
    platform = extract_platform_from_url(metadata['url'])
    video_id = extract_video_id(metadata['url'])
    
    # Create directory name
    dir_name = f"{date}_{platform}_{video_id}"
    output_dir = Path(base_dir) / dir_name
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Return path mapping
    return {
        "directory": output_dir,
        "transcript_txt": output_dir / "transcript.txt",
        "transcript_json": output_dir / "transcript.json",
        "transcript_srt": output_dir / "transcript.srt",
        "transcript_vtt": output_dir / "transcript.vtt",
        "metadata": output_dir / "metadata.json",
        "entities": output_dir / "entities.json",
        "manifest": output_dir / "manifest.json"
    }
```

## Format Validation

### Output Verification
```python
def validate_output(paths: Dict[str, Path]) -> bool:
    """Validate all output files were created."""
    required_files = [
        "transcript_txt", "transcript_json", 
        "metadata", "manifest"
    ]
    
    for file_key in required_files:
        if file_key not in paths:
            logger.error(f"Missing required file: {file_key}")
            return False
        
        if not paths[file_key].exists():
            logger.error(f"File not created: {paths[file_key]}")
            return False
        
        if paths[file_key].stat().st_size == 0:
            logger.warning(f"Empty file: {paths[file_key]}")
    
    return True
```

## Video Retention Management (v2.17.0)

### Retention Metadata Format
```python
def _generate_retention_metadata(self, video_path: Path, retention_info: RetentionInfo) -> dict:
    """Generate video retention metadata."""
    return {
        "retention_policy": retention_info.policy,
        "original_video_path": str(video_path),
        "archived_video_path": str(retention_info.archived_path) if retention_info.archived_path else None,
        "processing_timestamp": retention_info.processing_timestamp.isoformat(),
        "retention_decision": {
            "storage_cost": retention_info.storage_cost,
            "reprocessing_cost": retention_info.reprocessing_cost,
            "recommendation": retention_info.recommendation,
            "break_even_days": retention_info.break_even_days
        },
        "video_metadata": {
            "file_size_mb": retention_info.file_size_mb,
            "duration_minutes": retention_info.duration_minutes,
            "format": retention_info.video_format
        }
    }
```

### Archive Organization
```python
def organize_video_archive(self, retention_policy: VideoRetentionPolicy, video_metadata: dict):
    """Organize video archive based on policy and metadata."""
    
    if retention_policy == VideoRetentionPolicy.KEEP_PROCESSED:
        # Organize by date and platform
        archive_path = self.archive_dir / "processed" / metadata["date"] / metadata["platform"]
        archive_path.mkdir(parents=True, exist_ok=True)
        
    elif retention_policy == VideoRetentionPolicy.KEEP_ALL:
        # Organize by processing status
        status = "success" if metadata["processing_successful"] else "failed"
        archive_path = self.archive_dir / status / metadata["date"]
        archive_path.mkdir(parents=True, exist_ok=True)
    
    return archive_path
```

## Best Practices (v2.17.0)

1. **Always use UTF-8 encoding** for text files
2. **Include file size and checksums** in manifest for validation
3. **Use consistent naming** across all formats with temporal context
4. **Validate output** after generation including temporal intelligence
5. **Handle missing data gracefully** (empty lists, None values, missing temporal events)
6. **Version your formats** in manifest with temporal intelligence schema version
7. **Make formats self-documenting** with clear structure and temporal metadata
8. **Implement smart retention** based on cost analysis and processing success
9. **Archive with metadata** to enable future analysis and clip extraction
10. **Cross-video correlation** for timeline synthesis and collection intelligence

## CLI Integration (v2.17.0 Enhanced)

```python
@click.option(
    "--format", "-f",
    type=click.Choice(['txt', 'json', 'temporal', 'timeline', 'gexf', 'md', 'all']),
    default='json',
    help='Output format for enhanced video intelligence'
)

@click.option(
    "--temporal-level",
    type=click.Choice(['basic', 'optimized', 'enhanced']),
    default='optimized',
    help='Temporal intelligence enhancement level'
)

@click.option(
    "--retention-policy",
    type=click.Choice(['delete', 'keep_processed', 'keep_all']),
    default='delete',
    help='Video retention policy after processing'
)

@click.option(
    "--enable-visual-timestamps/--disable-visual-timestamps",
    default=True,
    help='Extract timestamps from visual elements'
)
```
