---
description: Guidelines for video/audio processing and transcription
globs: 
alwaysApply: false
---
---
description: "Guidelines for video/audio processing and transcription"
globs: ["src/clipscribe/retrievers/**/*.py", "**/transcriber.py"]
alwaysApply: false
---

# Video Processing Guidelines (v2.17.0 Optimized Architecture)

## Core Principle: Direct Video Intelligence

ClipScribe v2.17.0+ uses **streamlined video processing** that eliminates audio extraction inefficiency while maximizing temporal intelligence extraction.

## Optimized Processing Pipeline

```
Video URL → Download Video → Direct Gemini 2.5 Flash Processing → {
    accurate_transcript_with_timestamps,
    temporal_events_from_speech,
    visual_timestamp_recognition,
    entities_with_temporal_context
} → Timeline Synthesis → Video Retention → Intelligence Export
```

### Key Architecture Changes
- **NO Audio Extraction**: Direct video-to-Gemini processing eliminates inefficiency
- **Single Processing Call**: Audio + visual intelligence in one operation
- **Enhanced Temporal Intelligence**: 12-20% cost increase for 300% temporal intelligence
- **Video Retention**: Configurable policies for source material preservation

## Video Retention System

ClipScribe now supports configurable video retention for enhanced capabilities:

```python
class VideoRetentionPolicy(Enum):
    DELETE = "delete"              # Remove after processing (current behavior)
    KEEP_PROCESSED = "keep_processed"  # Archive successfully processed videos
    KEEP_ALL = "keep_all"         # Full archival system

# Configuration
retention_policy = settings.video_retention_policy
archive_directory = settings.video_archive_dir or "output/video_archive"
```

### Retention Implementation
```python
async def process_with_retention(self, video_path: Path, retention_policy: VideoRetentionPolicy):
    """Process video with configurable retention policy."""
    try:
        # Direct Gemini 2.5 Flash processing
        intelligence = await self._process_video_direct(video_path)
        
        # Handle retention based on policy
        if retention_policy == VideoRetentionPolicy.KEEP_PROCESSED:
            archive_path = self.archive_directory / video_path.name
            shutil.move(video_path, archive_path)
            logger.info(f"Archived processed video: {archive_path}")
        elif retention_policy == VideoRetentionPolicy.KEEP_ALL:
            # Keep in place or move to organized archive
            pass
        else:  # DELETE
            video_path.unlink()
            logger.debug(f"Cleaned up video file: {video_path}")
            
        return intelligence
    except Exception as e:
        if retention_policy == VideoRetentionPolicy.KEEP_ALL:
            # Keep failed videos for debugging
            archive_path = self.archive_directory / "failed" / video_path.name
            shutil.move(video_path, archive_path)
        raise
```

## Enhanced Temporal Intelligence Extraction

### Temporal Intelligence Capabilities
```python
async def extract_temporal_intelligence(self, video_file: Path) -> TemporalIntelligence:
    """Extract comprehensive temporal intelligence from video."""
    
    prompt = """
    Analyze this video for comprehensive temporal intelligence:
    
    1. **Temporal Events**: Extract specific dates, times, and chronological references from speech
       - Parse "In 1984...", "Last Tuesday...", "Next month..." into specific dates
       - Identify historical events and their temporal context
    
    2. **Visual Timestamps**: Recognize dates/times visible on screen
       - Documents, calendars, news chyrons, presentations
       - Correlate visual timestamps with spoken content
    
    3. **Accurate Transcript Segmentation**: Provide word-level timestamps
       - Precise temporal mapping for timeline building
       - Speaker identification where possible
    
    4. **Entity Temporal Context**: Associate entities with temporal information
       - When people/organizations are mentioned in temporal context
       - Event-entity relationships with timestamps
    
    Provide structured output with confidence scores and source attribution.
    """
    
    # Single Gemini 2.5 Flash call for audio + visual intelligence
    response = await self.gemini_client.generate_content_async(
        [prompt, video_file],
        generation_config=self._get_temporal_config()
    )
    
    return self._parse_temporal_intelligence(response.text)
```

### Cost-Optimized Implementation
```python
def _get_temporal_config(self) -> GenerationConfig:
    """Optimized config for temporal intelligence extraction."""
    return GenerationConfig(
        temperature=0.1,          # Low for accuracy
        candidate_count=1,        # Single response
        max_output_tokens=12288,  # Sufficient for temporal data
    )
```

## Platform Support & Processing

### Universal Video Client Integration
```python
class VideoProcessor:
    """Optimized video processing with retention support."""
    
    async def process_url(self, url: str, retention_policy: VideoRetentionPolicy = VideoRetentionPolicy.DELETE):
        """Process video with optimized pipeline."""
        
        # 1. Download video (not audio)
        video_path = await self.universal_client.download_video(url)
        
        # 2. Direct Gemini processing (no audio extraction)
        temporal_intelligence = await self.extract_temporal_intelligence(video_path)
        
        # 3. Timeline synthesis from temporal data
        timeline = await self.synthesize_timeline(temporal_intelligence)
        
        # 4. Handle video retention
        await self.handle_retention(video_path, retention_policy)
        
        return VideoIntelligence(
            temporal_intelligence=temporal_intelligence,
            timeline=timeline,
            processing_cost=self.calculate_cost(video_path)
        )
```

### Platform-Specific Optimizations
```python
# YouTube - prefer direct video download
if platform == "youtube":
    download_format = "best[ext=mp4][height<=720]"  # Balance quality/size
    
# Twitter/X - handle different video qualities
elif platform == "twitter":
    download_format = "best[ext=mp4]"  # Take best available
    
# Generic platforms
else:
    download_format = "best[ext=mp4]/best"
```

## Output Format Standards (v2.17.0)

### Current Supported Formats
```python
# Core intelligence outputs (NO SRT/VTT)
output_formats = [
    "transcript.json",      # Structured transcript with timestamps
    "transcript.txt",       # Plain text transcript
    "entities.json",        # Extracted entities with temporal context
    "relationships.json",   # Entity relationships
    "timeline.json",        # Temporal event timeline
    "knowledge_graph.json", # Complete knowledge graph
    "temporal_intelligence.json",  # Enhanced temporal data
    "metadata.json",        # Video metadata
    "manifest.json"         # File manifest with checksums
]
```

### Directory Structure
```
output/
└── YYYYMMDD_platform_videoid/
    ├── transcript.json           # Structured with word-level timestamps
    ├── transcript.txt           # Human-readable
    ├── entities.json            # Entities with temporal context
    ├── relationships.json       # Entity relationships
    ├── timeline.json           # Temporal event timeline
    ├── temporal_intelligence.json  # Enhanced temporal data
    ├── knowledge_graph.json    # Complete graph structure
    ├── metadata.json           # Video metadata
    └── manifest.json           # File index with checksums
```

## Performance & Cost Optimization

### Processing Efficiency
```python
# OLD (v2.16.0 and earlier): Inefficient
video_url → download_video → extract_audio → transcribe_audio → analyze_transcript
# Cost: Base + audio extraction overhead

# NEW (v2.17.0+): Optimized
video_url → download_video → direct_gemini_processing → enhanced_intelligence
# Cost: Base + 12-20% for 300% more temporal intelligence
```

### Cost Monitoring
```python
def estimate_processing_cost(video_duration_minutes: float) -> float:
    """Estimate cost for enhanced temporal intelligence processing."""
    base_cost_per_minute = 0.002  # Gemini 2.5 Flash
    temporal_enhancement = 1.15   # 15% average increase
    
    return video_duration_minutes * base_cost_per_minute * temporal_enhancement
```

## Error Handling & Recovery

### Robust Processing
```python
async def process_with_recovery(self, video_path: Path):
    """Process video with comprehensive error recovery."""
    try:
        # Attempt enhanced temporal processing
        return await self.extract_temporal_intelligence(video_path)
        
    except GeminiTimeoutError:
        logger.warning("Gemini timeout, retrying with reduced context")
        return await self.extract_temporal_intelligence_lite(video_path)
        
    except VideoTooLargeError:
        logger.warning("Video too large, chunking processing")
        return await self.process_video_chunks(video_path)
        
    except Exception as e:
        logger.error(f"Processing failed: {e}")
        # Keep video if retention policy allows for debugging
        if self.retention_policy != VideoRetentionPolicy.DELETE:
            await self.archive_failed_video(video_path, str(e))
        raise VideoProcessingError(f"Enhanced processing failed: {e}")
```

### Timeline Building Recovery
```python
async def build_timeline_with_fallback(self, temporal_data: dict):
    """Build timeline with graceful degradation."""
    try:
        # Attempt full timeline synthesis
        return await self.synthesize_comprehensive_timeline(temporal_data)
    except Exception as e:
        logger.warning(f"Full timeline synthesis failed: {e}, using basic timeline")
        return self.create_basic_timeline(temporal_data)
```

## Best Practices

### 1. Video Retention Strategy
- **Development**: Use `KEEP_ALL` for debugging and iteration
- **Production**: Use `KEEP_PROCESSED` for valuable content
- **Batch Processing**: Use `DELETE` for large-scale processing

### 2. Temporal Intelligence Optimization
- **Short Videos** (<10 min): Full temporal extraction
- **Long Videos** (>60 min): Chunked processing with correlation
- **Live Streams**: Real-time processing with temporal synthesis

### 3. Cost Management
```python
# Monitor costs during processing
if estimated_cost > cost_threshold:
    logger.warning(f"High cost processing: ${estimated_cost:.2f}")
    if not confirm_processing():
        return None
```

### 4. Quality Assurance
```python
def validate_temporal_output(temporal_intelligence: TemporalIntelligence):
    """Validate temporal intelligence quality."""
    assert temporal_intelligence.events, "No temporal events extracted"
    assert temporal_intelligence.transcript_segments, "No transcript segments"
    
    # Validate temporal event quality
    valid_events = [e for e in temporal_intelligence.events if e.confidence > 0.7]
    assert len(valid_events) > 0, "No high-confidence temporal events"
```

## Integration Points

### Timeline Building Pipeline
```python
# Enhanced temporal intelligence feeds timeline synthesis
temporal_data → event_extraction → cross_video_correlation → timeline_synthesis
```

### Multi-Video Collections
```python
# Video retention enables advanced collection features
retained_videos → clip_extraction → enhanced_synthesis → rich_timelines
```

### Future Capabilities
- **Clip Extraction**: Use retained videos for specific segment extraction
- **Visual Analysis**: Enhanced visual intelligence from retained source material
- **Re-processing**: Upgrade intelligence extraction without re-downloading

Remember: Direct video processing with retention creates a foundation for advanced temporal intelligence while maintaining cost efficiency through optimized single-call processing :-)
