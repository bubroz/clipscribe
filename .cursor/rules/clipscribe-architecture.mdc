
# ClipScribe Architecture Guidelines (v2.19.3)

## Core Principles

1. **Video Intelligence Extraction**: Extract entities, relationships, and knowledge graphs
2. **Cost Optimization**: $0.002-0.0035/minute through intelligent routing  
3. **Platform Support**: 1800+ platforms via yt-dlp integration
4. **Type Safety**: Comprehensive type hints throughout
5. **Async Performance**: Efficient concurrent processing
6. **Quality Focus**: 100% extraction completeness, not arbitrary filtering
7. **Enterprise Ready**: Vertex AI support for scale

## Key Components

### Video Processing Pipeline
```python
# Architecture Flow
Video URL → UniversalVideoClient.download() → 
Transcriber.transcribe() → HybridExtractor.extract() →
GraphBuilder.build() → OutputFormatter.format() →
Structured Intelligence Output
```

### Core Components

#### Retrievers (Video/Audio Processing)
- **UniversalVideoClient**: Downloads from 1800+ platforms via yt-dlp
- **Transcriber**: Gemini 2.5 Flash/Pro API integration
- **YouTubeClient**: Optimized YouTube handling with transcript API
- **VideoModeDetector**: Determines optimal processing mode
- **GeminiPool**: Model management for different tasks

#### Extractors (Entity & Relationship Extraction)
- **HybridExtractor**: Combines SpaCy + GLiNER + REBEL + LLM
- **SpacyExtractor**: Fast local entity extraction
- **GLiNERExtractor**: Advanced local entity detection
- **REBELExtractor**: Relationship extraction
- **AdvancedHybridExtractor**: Enhanced with confidence scoring

#### Models & Data Structures
- **VideoIntelligence**: Core data model with entities and relationships
- **Entity**: Type, name, confidence, source attribution
- **Relationship**: Subject-predicate-object with evidence
- **ProcessingResult**: Complete extraction results

## Architectural Patterns

### 1. Hybrid Extraction Pattern
```python
class HybridExtractor:
    """Combine multiple extraction methods for best results."""
    
    async def extract(self, text: str) -> ExtractedIntelligence:
        # Run extractors in parallel for speed
        spacy_task = self.spacy_extractor.extract(text)
        gliner_task = self.gliner_extractor.extract(text)
        rebel_task = self.rebel_extractor.extract(text)
        
        # Combine and deduplicate results
        results = await asyncio.gather(spacy_task, gliner_task, rebel_task)
        entities = self._merge_entities(results)
        relationships = self._merge_relationships(results)
        
        return ExtractedIntelligence(entities=entities, relationships=relationships)
```

### 2. Cost-Aware Processing
```python
class CostOptimizedProcessor:
    """Choose processing strategy based on cost/quality trade-offs."""
    
    async def process(self, url: str) -> ProcessingResult:
        # Try free methods first
        if youtube_url(url):
            transcript = await self.youtube_client.get_free_transcript(url)
            if transcript:
                return await self.process_transcript(transcript)
        
        # Fall back to paid processing
        video = await self.video_client.download(url)
        result = await self.transcriber.transcribe(video)
        return result
```

### 3. Confidence Scoring
```python
class ConfidenceScorer:
    """Dynamic confidence scoring based on context."""
    
    def score_entity(self, entity: Entity, context: str) -> float:
        # Don't hardcode confidence - calculate based on:
        # - Source extractor reliability
        # - Context relevance
        # - Mention frequency
        # - Cross-validation between extractors
        
        base_score = self.source_weights[entity.source]
        context_boost = self._calculate_context_relevance(entity, context)
        frequency_factor = min(1.0, entity.mention_count / 10)
        
        return base_score * context_boost * frequency_factor
```

## Quality Principles

1. **Completeness Over Filtering**: Extract ALL entities, let users filter
2. **Evidence-Based**: Every relationship needs supporting evidence
3. **Source Attribution**: Track which extractor found each entity
4. **Dynamic Confidence**: Calculate scores based on context, not hardcoded
5. **User Control**: Provide all data, let users set their own thresholds

## Performance Optimization

- **Parallel Processing**: Run extractors concurrently
- **Caching**: Cache expensive API calls
- **Batch Operations**: Process multiple videos efficiently
- **Progressive Loading**: Stream results as available

Remember: Architecture should prioritize extraction completeness and accuracy while maintaining cost efficiency :-)
