# ClipScribe Continuation Prompt

This document captures the current state of ClipScribe for future AI assistants or developers who need to continue work on this project.

## Current State (2024-06-25)

### Just Completed
- Fixed GEXF edge generation bug where predicates were being used as targets
- Replaced NetworkX GEXF export with custom generator for proper edge formatting
- Added REBEL relationship validation to fix malformed subject-predicate-object triples
- Updated to v2.4.1 with the fixes

### Working Well
- 4-hour timeout support for long videos (tested with 57-minute PBS News Hour)
- 9 output formats focused on intelligence extraction:
  - Plain text (transcript.txt)
  - Full JSON (transcript.json)
  - Metadata (metadata.json)
  - Entities (entities.json)
  - Relationships (relationships.json)
  - Knowledge graph (knowledge_graph.json)
  - GEXF for Gephi (knowledge_graph.gexf) - NOW PROPERLY FORMATTED!
  - Facts (facts.txt)
  - Chimera format (chimera_format.json)
- Advanced extraction with SpaCy + GLiNER + REBEL + LLM validation
- Cost optimization (92% reduction vs full video processing)

### Known Issues
- REBEL model sometimes produces malformed relationships (partially mitigated)
- LLM validation occasionally fails with VideoTranscript subscript error (non-critical)
- Some relationships still have awkward predicate/object ordering

### Next Steps
1. Improve REBEL output parsing to better handle various formats
2. Add more sophisticated relationship validation
3. Consider alternative relationship extraction methods
4. Add graph visualization examples to documentation
5. Create video tutorials for Gephi usage

### Recent Changes Summary
- v2.4.1: Fixed GEXF edge generation
- v2.4.0: Removed SRT/VTT formats, added GEXF
- v2.3.0: Added timeout support and extraction improvements
- v2.2.2: Starting point with missing .cursor/rules

### Technical Details
- GEXF edges now properly connect source entities to target entities
- Predicates stored as edge attributes (id="0")
- Node colors mapped by entity type
- Custom GEXF generator in `video_retriever._generate_gexf_content()`

Remember: Always test with news content, not music videos! :-)

### Version 2.4.0 Released! ðŸŽ‰

Major improvements to extraction quality, long video support, and graph visualization have been completed and tested.

### Recent Major Updates

1. **Extraction Quality Improvements** âœ…
   - Chimera format now generated by default (was disabled)
   - Relationship extraction enhanced with better prompts
   - Key points extraction increased to 30-50 for hour-long videos (was ~11)
   - Fact extraction expanded to 100 facts combining multiple sources
   - Direct LLM relationship extraction added to complement REBEL
   - Created `convert_to_chimera.py` script for existing outputs

2. **Graph Visualization Support** âœ…
   - Removed SRT/VTT subtitle formats (unnecessary for intelligence extraction)
   - Added automatic GEXF generation for Gephi visualization
   - Knowledge graphs now directly importable into Gephi
   - Node colors by entity type, sizes by confidence

3. **Timeout Support for Long Videos** âœ…
   - Added `GEMINI_REQUEST_TIMEOUT` setting (default: 14400 seconds / 4 hours)
   - Updated all Gemini API calls to use `RequestOptions(timeout=...)`
   - Successfully tested with 57-minute PBS News Hour episode
   - Fixed issue where videos >15 minutes would timeout with "504 Deadline Exceeded"

4. **Comprehensive .cursor/rules System** âœ…
   - Created 15 rule files aligned with Chimera project standards
   - Established master rule (README.mdc) with task completion checklist
   - Added always-apply rules for cost optimization and file organization

### What's Working Well

- **Video Processing**: Successfully processes videos up to 4 hours long
- **Entity Extraction**: SpaCy + GLiNER + REBEL hybrid working smoothly
- **Cost Efficiency**: 92% cost reduction vs GPT-4 while maintaining quality
- **Output Quality**: All 9 output formats generating correctly
- **Graph Visualization**: GEXF files ready for direct Gephi import
- **Platform Support**: 1800+ platforms via yt-dlp
- **Async Performance**: Fast concurrent processing
- **Caching**: Smart caching reduces redundant API calls

### Known Issues

1. **Relationship Extraction on Non-Factual Content**: REBEL doesn't work well on song lyrics or creative content
2. **Python 3.13 Incompatibility**: Requires Python 3.12 (Poetry handles this automatically)
3. **LLM Validation Error**: Minor error in advanced_hybrid_extractor.py line 222 (non-critical)

### Next Features to Consider

1. **Batch Processing**: Process multiple videos in parallel
2. **Web UI**: Simple interface for non-technical users
3. **Export Formats**: Add more visualization formats (D3.js, Cytoscape)
4. **Language Support**: Multi-language transcription
5. **Custom Extractors**: Plugin system for domain-specific extraction
6. **Real-time Processing**: Stream processing for live videos
7. **Cost Optimization**: Further reduce costs with smart chunking

### Technical Debt

1. **Test Coverage**: Currently minimal, needs comprehensive test suite
2. **Error Handling**: Some edge cases not fully handled
3. **Documentation**: API documentation could be more detailed
4. **Type Hints**: Some functions missing proper type annotations

### Architecture Overview

```
ClipScribe
â”œâ”€â”€ Video Retrieval (1800+ platforms via yt-dlp)
â”œâ”€â”€ Transcription (Gemini 1.5 Flash - audio/video modes)
â”œâ”€â”€ Entity Extraction (SpaCy + GLiNER + REBEL)
â”œâ”€â”€ Relationship Extraction (REBEL + LLM)
â”œâ”€â”€ Knowledge Graph Generation
â””â”€â”€ Multiple Export Formats (9 formats including Chimera + GEXF)
```

### Environment Setup

```bash
# Required
GOOGLE_API_KEY=your_key_here
GEMINI_REQUEST_TIMEOUT=14400  # 4 hours

# Optional
GLINER_MODEL=urchade/gliner_multi-v2.1
REBEL_MODEL=Babelscape/rebel-large
```

### Quick Test Commands

```bash
# Test short video
poetry run clipscribe transcribe "https://www.youtube.com/watch?v=dQw4w9WgXcQ" --mode audio

# Test long video (PBS News Hour)
poetry run clipscribe transcribe "https://www.youtube.com/watch?v=HSODoOfhnks" --mode audio

# Convert existing output to Chimera format
poetry run python scripts/convert_to_chimera.py output/YYYYMMDD_platform_videoId
```

### Recent Test Results

- **PBS News Hour (57 min)**: Processed in 5.3 minutes, cost $0.114, extracted 149 entities, 282 relationships
- **Rick Astley (3.5 min)**: Processed in 33 seconds, cost $0.007, extracted 6 entities, 28 facts

### Development Guidelines

#### Before Starting Work
1. Review `.cursor/rules/` directory for project conventions
2. Check `cost-optimization.mdc` - cost awareness is critical
3. Follow `file-organization.mdc` - maintain clean structure
4. Read `core-identity.mdc` - understand project mission

#### Making Changes
1. Always update tests for new features
2. Follow async patterns for I/O operations
3. Use type hints everywhere
4. End code comments with :-) 
5. Track API costs in all operations

#### After Completing Tasks
1. Run the comprehensive task checklist in `.cursor/rules/README.mdc`
2. Update this CONTINUATION_PROMPT.md
3. Update CHANGELOG.md with your changes
4. Commit with conventional format: `type(scope): description`

### Project Philosophy

ClipScribe is the video intelligence component of the Chimera Researcher ecosystem. It prioritizes:
1. **Cost efficiency** without sacrificing quality
2. **Comprehensive extraction** of all available intelligence
3. **Clean, structured output** for downstream processing
4. **Platform agnosticism** - work with any video source

### Contact & Resources

- GitHub: https://github.com/bubroz/clipscribe
- Issues: Report bugs or request features via GitHub Issues
- Chimera Integration: See chimera_format.json output
- Documentation: See `docs/` directory
- Rules & Conventions: See `.cursor/rules/`

---

*Remember: This is a living document. Update it whenever you make significant changes!*