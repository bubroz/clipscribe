"""Professional DOCX report generator for ClipScribe intelligence extraction.

Generates editable Word documents that open perfectly in:
- Google Docs (auto-converts)
- Microsoft Word
- Apple Pages
- LibreOffice Writer
"""

from datetime import datetime
from pathlib import Path

from docx import Document
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.shared import Inches


def generate_docx_report(
    transcript_result,
    intelligence_result,
    output_path: Path,
    filename: str = "intelligence_report.docx",
):
    """Generate professional DOCX report from ClipScribe results.

    Args:
        transcript_result: TranscriptResult from provider
        intelligence_result: IntelligenceResult from provider
        output_path: Directory to save report
        filename: Output filename (default: intelligence_report.docx)

    Returns:
        Path to generated DOCX file
    """
    doc = Document()

    # Set document properties
    doc.core_properties.title = "ClipScribe Intelligence Extraction Report"
    doc.core_properties.author = "ClipScribe"
    doc.core_properties.comments = "Generated by ClipScribe v3.0.0"

    # Add ClipScribe header
    header = doc.sections[0].header
    header_para = header.paragraphs[0]
    header_para.text = "ClipScribe Intelligence Extraction"
    header_para.alignment = WD_ALIGN_PARAGRAPH.RIGHT

    # Title
    title = doc.add_heading("Intelligence Extraction Report", 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER

    # Metadata
    meta = doc.add_paragraph()
    meta.add_run(f"Processed: {datetime.now().strftime('%B %d, %Y')}\n").bold = True
    meta.add_run(f"Duration: {transcript_result.duration/60:.1f} minutes\n")
    meta.add_run(f"Provider: {transcript_result.provider} + {intelligence_result.provider}\n")
    meta.add_run(f"Cost: ${transcript_result.cost + intelligence_result.cost:.4f}")

    doc.add_page_break()

    # Executive Summary
    doc.add_heading("Executive Summary", 1)
    summary = doc.add_paragraph()
    summary.add_run(f"• {len(intelligence_result.entities)} entities extracted\n")
    summary.add_run(f"• {len(intelligence_result.relationships)} relationships mapped\n")
    summary.add_run(f"• {transcript_result.speakers} speakers identified\n")
    summary.add_run(f"• {len(intelligence_result.topics)} main topics analyzed\n")
    summary.add_run(f"• {len(intelligence_result.key_moments)} key moments identified")

    doc.add_paragraph()  # Spacing

    # Entities Section
    doc.add_heading("Entities Extracted", 1)
    doc.add_paragraph(f"Total: {len(intelligence_result.entities)} entities with evidence quotes")

    if intelligence_result.entities:
        # Add table for top entities
        entity_table = doc.add_table(rows=1, cols=4)
        entity_table.style = "Light Grid Accent 1"

        # Header row
        header_cells = entity_table.rows[0].cells
        header_cells[0].text = "Name"
        header_cells[1].text = "Type"
        header_cells[2].text = "Confidence"
        header_cells[3].text = "Evidence"

        # Add entities (top 20 or all if less)
        for entity in intelligence_result.entities[:20]:
            row_cells = entity_table.add_row().cells
            row_cells[0].text = entity.get("name", "Unknown")
            row_cells[1].text = entity.get("type", "UNKNOWN")
            row_cells[2].text = f"{entity.get('confidence', 0):.2f}"
            # Truncate evidence to 150 chars for table
            evidence = entity.get("evidence", "No evidence")
            row_cells[3].text = evidence[:150] + ("..." if len(evidence) > 150 else "")

        if len(intelligence_result.entities) > 20:
            doc.add_paragraph()
            note = doc.add_paragraph(
                f"Note: Showing top 20 of {len(intelligence_result.entities)} entities. Full data in CSV/JSON."
            )
            note.runs[0].italic = True

    doc.add_page_break()

    # Relationships Section
    doc.add_heading("Relationship Mapping", 1)
    doc.add_paragraph(
        f"Total: {len(intelligence_result.relationships)} relationships with evidence"
    )

    if intelligence_result.relationships:
        for idx, rel in enumerate(intelligence_result.relationships[:15], 1):
            # Relationship statement
            rel_para = doc.add_paragraph()
            rel_para.add_run(f"{idx}. ").bold = True
            rel_para.add_run(f"{rel.get('subject')} ")
            rel_para.add_run(f"→ {rel.get('predicate')} → ").italic = True
            rel_para.add_run(f"{rel.get('object')}")
            rel_para.add_run(f" (confidence: {rel.get('confidence', 0):.2f})")

            # Evidence quote
            evidence = doc.add_paragraph()
            evidence.add_run(f"  Evidence: \"{rel.get('evidence', 'No evidence')}\"")
            evidence.runs[0].italic = True
            evidence.paragraph_format.left_indent = Inches(0.5)

        if len(intelligence_result.relationships) > 15:
            doc.add_paragraph()
            note = doc.add_paragraph(
                f"Note: Showing top 15 of {len(intelligence_result.relationships)} relationships. Full data in CSV/JSON."
            )
            note.runs[0].italic = True

    doc.add_page_break()

    # Topics Section
    doc.add_heading("Topic Analysis", 1)
    doc.add_paragraph(f"Total: {len(intelligence_result.topics)} main topics identified")

    if intelligence_result.topics:
        for topic in intelligence_result.topics:
            topic_para = doc.add_paragraph(style="List Bullet")
            topic_para.add_run(f"{topic.get('name')} ").bold = True
            topic_para.add_run(f"(Relevance: {topic.get('relevance', 0):.2f})")

            # Time range
            time_para = doc.add_paragraph()
            time_para.add_run(f"  Discussed: {topic.get('time_range', 'N/A')}")
            time_para.paragraph_format.left_indent = Inches(0.5)

    doc.add_paragraph()  # Spacing

    # Key Moments Section
    doc.add_heading("Key Moments", 1)
    doc.add_paragraph(f"Total: {len(intelligence_result.key_moments)} significant moments")

    if intelligence_result.key_moments:
        for moment in intelligence_result.key_moments:
            moment_para = doc.add_paragraph()
            moment_para.add_run(f"⏰ {moment.get('timestamp', '00:00')} - ").bold = True
            moment_para.add_run(f"{moment.get('description', 'No description')}")
            moment_para.add_run(f" (significance: {moment.get('significance', 0):.2f})")

            # Quote
            quote_para = doc.add_paragraph()
            quote_para.add_run(f"  \"{moment.get('quote', 'No quote')}\"")
            quote_para.runs[0].italic = True
            quote_para.paragraph_format.left_indent = Inches(0.5)

    doc.add_page_break()

    # Sentiment Analysis
    doc.add_heading("Sentiment Analysis", 1)

    sentiment = intelligence_result.sentiment
    sent_para = doc.add_paragraph()
    sent_para.add_run("Overall Sentiment: ").bold = True
    sent_para.add_run(f"{sentiment.get('overall', 'unknown').upper()}")
    sent_para.add_run(f" (confidence: {sentiment.get('confidence', 0):.2f})")

    # Per-topic sentiment
    if sentiment.get("per_topic"):
        doc.add_paragraph()
        doc.add_paragraph("Per-Topic Sentiment:").runs[0].bold = True
        for topic, topic_sentiment in sentiment.get("per_topic", {}).items():
            topic_sent = doc.add_paragraph(style="List Bullet")
            topic_sent.add_run(f"{topic}: ").bold = True
            topic_sent.add_run(topic_sentiment)

    # Footer
    doc.add_paragraph()
    footer_para = doc.add_paragraph()
    footer_para.add_run("\n---\n")
    footer_para.add_run("Powered by ClipScribe Intelligence Extraction\n").italic = True
    footer_para.add_run("clipscribe.ai • github.com/bubroz/clipscribe")
    footer_para.alignment = WD_ALIGN_PARAGRAPH.CENTER

    # Save
    full_path = output_path / filename
    doc.save(str(full_path))

    return full_path
