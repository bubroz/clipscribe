{
  "metadata": {
    "title": "Code a Discord Chat Bot That Talks Like Your Favorite Character - Tutorial",
    "url": "https://www.youtube.com/watch?v=UjDpW_SOrlw",
    "channel": "freeCodeCamp.org",
    "duration": 3472,
    "published_at": "2021-08-26T06:30:35",
    "view_count": 210967,
    "description": "Use AI to create a Discord chat bot that talks like your favorite characters. Learn how to code it in Python and JavaScript.\n\n\u270f\ufe0f This course was developed by Lynn Zheng. Check out Lynn's YouTube channel, Lynn's DevLab: https://www.youtube.com/channel/UCZ2MeG5jTIqgzEMiByrIzsw\n\n\ud83d\udcbb Lynn's GitHub resource for this video: https://github.com/RuolinZheng08/twewy-discord-chatbot\n\n\ud83d\udd17 Lynn's personal website: https://ruolinzheng08.github.io/\n\nfreeCodeCamp tutorials referenced in this video:\n\ud83d\udd17 https://www.freecodecamp.org/news/create-a-discord-bot-with-python/\n\ud83d\udd17 https://www.freecodecamp.org/news/create-a-discord-bot-with-javascript-nodejs/\n\n\u2b50\ufe0f Course Contents \u2b50\ufe0f\n\u2328\ufe0f (00:00) Intro\n\u2328\ufe0f (01:38) Gather data\n\u2328\ufe0f (12:27) Train the model\n\u2328\ufe0f (24:27) Deploy the model\n\u2328\ufe0f (29:42) Build the Discord bot in Python\n\u2328\ufe0f (41:17) Build the Discord bot in JavaScript\n\u2328\ufe0f (51:35) Keep the bots online\n\n\ud83c\udf89 Thanks to our Champion and Sponsor supporters:\n\ud83d\udc7e Wong Voon jinq\n\ud83d\udc7e hexploitation\n\ud83d\udc7e Katia Moran\n\ud83d\udc7e BlckPhantom\n\ud83d\udc7e Nick Raker\n\ud83d\udc7e Otis Morgan\n\ud83d\udc7e DeezMaster\n\ud83d\udc7e AppWrite\n\n--\n\nLearn to code for free and get a developer job: https://www.freecodecamp.org\n\nRead hundreds of articles on programming: https://freecodecamp.org/news \n\n\u2764\ufe0f Support for this channel comes from our friends at Scrimba \u2013 the coding platform that's reinvented interactive learning: https://scrimba.com/freecodecamp"
  },
  "transcript": {
    "full_text": "Wanna make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you wanna make it talk like another favorite character. In this course, Lynn will show you how to create a Discord bot that uses artificial intelligence to talk like a character of your choice.\n\nHi there. I'm Lynn. I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago.\n\nIn this tutorial, we're going to build a Discord AI chatbot that can speak like your favorite character.\n\nBefore we start, if you have seen that video by any chance, know that this video is something different and more comprehensive. So keep watching till the end. The original tutorial and my first Discord bot started as a joke between me and my friends when we were playing video games, and it really surprised me how popular it became, and a lot of people wanted to build their own bot based on that tutorial. Therefore, I decided to update that tutorial to include more characters, as well as to show you how to find data for your favorite character.\n\nOther topics that we will cover here include, but are not limited to: how to train the model, how to deploy the model, common errors you might see during this model training and deployment pipeline, and how to solve them. Moreover, we will cover how to build the bot in Python, and how to build it in JavaScript.\n\nLastly, we will cover how to properly deploy the bot to a Discord server and limit it to certain channels, and how to keep the bot running indefinitely. I hope you're excited and let's jump into the tutorial.\n\nFirst, we are going to find data for our character. My favorite sources are Kaggle, Transcript Wiki, and just random fandom websites that came out from the Google search. And my research process goes like this: I first search on Kaggle to see if there are pre-made dialogue datasets.\n\nFor example, if we search for Rick and Morty,\n\nwe get this nicely formatted dataset that includes the name of the character and the line they're speaking.\n\nIf we search for Harry Potter,\n\nhere is another dataset that includes the character and the sentence they're speaking. Since we're building a chatbot, we need only these two columns in our dataset: the character name and the line they're speaking. So these dialogue datasets on Kaggle are perfect for our requirement.\n\nAll right. If we succeeded in finding our data on Kaggle, we can move on to the model training step. But what if we cannot find a dataset for our character on Kaggle? For example, if I want to find a dataset for Peppa Pig,\n\nit looks like there is no dataset for the character. In this case, we may need to find the raw transcript of the media, be it a video game, a cartoon, or a show, and I've found that Transcript Wiki has some great resources.\n\nSo here we have a list of movies, shows, video games, musicals, commercials.\n\nFor example, I was able to find a transcript for Peppa Pig, and also movies like Batman on Transcript Wiki. The transcript looks like this. So we have the character name and their actions or the lines they're speaking. We will see shortly how to turn a raw transcript like this into a dataset like those we saw on Kaggle.\n\nBesides Transcript Wiki, you may also just Google the name of your media with the keyword transcript. For example, my first bot was based on the game, \"The Word Ends With You,\" and it has no results either on Kaggle or Transcript Wiki. So what I did was to just Google the name of the game and \"game transcript.\"\n\nAnd it just happened that this fandom website has the full game transcript. So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fictional character, you are more interested in real-life character, you may search for interview scripts as your data source. If you want to create a chatbot that speaks like yourself or your friends, you can treat text messages between you and your friends as dialogues and handcraft your dataset. There are tons of ways to get data for your characters, so be creative. And now we will look at how to turn raw transcript into a dataset.\n\nNow, suppose we have found our raw transcript. Let's see how we can turn it into a two-column character line dataset. Suppose we take this Peppa Pig transcripts and copy them into a text file.\n\nNow we go to Google Colab and upload our data file.\n\nThen we create a Google Colab notebook, and use this to parse our script. So I'm going to name this parse_script.ipynb. And we are going to from Google Colab import drive, and then call drive.mount content drive. This will allow us to read the data from our Google Drive.\n\nAll right. Now that our drive has been mounted, let's import OS and then OS change directory into content drive, my drive. And now we see if there is anything in it. Yeah, we have our peppapig.txt. So here we are going to import regular expression to parse our transcript, put the parsed result into a Pandas data frame, and export it as a CSV file, just like those we saw on Kaggle.\n\nThis is going to be our regular expression pattern.\n\nYou don't have to be a pro in regular expression to understand this part. If we take the pattern to this site, and our test string is Peppa Pig,\n\nyou will see that we have two match capture groups, the first being the character's name, the second being the line spoken, and also for the second line, Mama Pig, we have the character name and the line being spoken.\n\nRight. So that's our regular expression. Now, let's define a dictionary that will store our data. So we know that we need the column name and the column line in our result data frame.\n\nAnd now we open and read the file.\n\nFor each line, we match it with our regular expression pattern.\n\nIf there is a match, we extract name and line from this regular expression match, and then append it to our dictionary here.\n\nAnd then we convert this dictionary into a data frame.\n\nNow we can inspect the data frame. Cool. So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Mama Pig makes a sound. Great. We can also count the number of lines that belong to our character. So we do sum df name is equal to Peppa Pig. And we saw that Peppa Pig has 38 lines in our entire data frame. So the length of our data frame is over 100 and Peppa Pig has one third of the lines. Great. The last step will be to export the data frame. So df.to_csv, the name will be peppapig.csv, and and we will drop the index. Cool. Now we should have a peppapig.csv in our drive.\n\nAnd here it is: name and line. This is how we parse those raw transcripts into a file that could be used in our model training. So next, let's proceed onto the exciting step: model training.\n\nNow we are going to train the model. Go to my GitHub repository linked to in the description below and download the content. We're going to use this model_train_upload_workflow.ipynb, which looks like this.\n\nAll right. Now our file has been downloaded. We unzip the content.\n\nAnd in here we have a model_train_upload_workflow.ipynb.\n\nWe upload this notebook file to Google Drive and open it in Google Colab.\n\nWe're going to train a GPT model, which is short for Generative Pre-trained Transformer. In the runtime, change runtime type. Make sure to select GPU because this will accelerate our model training. So now here we mount the drive.\n\nWe install the Transformers module that we will be using, and we change directory into my drive.\n\nHere are all the modules that we are importing.\n\nIf we're using the dataset from Kaggle, we need to obtain our API key from Kaggle. So go to our Kaggle profile, go to Account, scroll down to the API key section, create a new API token and download this file as kaggle.json.\n\nWe will go back to Google Drive and upload kaggle.json.\n\nNow we can download our dataset from Kaggle. We're going to use the Harry Potter dataset as an example. So grab this username and the dataset name, and our file is harry_potter_1.csv.\n\nNote that because there are white spaces in our file name, we got special characters in the file name. So let's inspect the content of our data file. Well, CSV files are usually separated by commas, has the name CSV. However, this one looks like it's separated by semicolons. So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. So separation is semicolon instead of a comma. Cool. So let's sample our data to see what's inside. All right. So we have character and sentence. Notice that these two column names aren't exactly what we need. We want the two columns of our data frame to be named as name and line, as used down here in this cell. So we need to change the name of our columns.\n\nAll right. Let's resample our data. Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is. So it only has a thousand or so lines, and let's see how many lines our character has.\n\nOur character has 155 lines. So here we change our character name to Harry, and we now run this cell to create a context data frame that includes the current line our character is speaking and several lines directly preceding the line.\n\nA context data frame is useful here because we are creating a conversational chatbot and we want to generate a response based on the conversation context. So let's sample our context data frame. So in the context of clearly something something, our character responds with \"Seems a pity not to ask her.\"\n\nGreat. Now we have our dataset. We split the dataset into a training set and a test set. This is because we don't want to overfit the model. In the case of overfitting, the model will just memorize lines from the dataset and talk back to us using the exact lines. We don't want that. We want the conversation to be more organic. So we're only training the model on the training set and evaluating the model on the test set.\n\nSo we continue running these cells to build datasets, caching checkpoints, and down here we build the model. We will build our model by fine-tuning Microsoft's pre-trained GPT small. Small here refers to the number of parameters in the model. There are also a medium and a large model. Generally, the larger the model, the longer it takes to train, but the smarter the model can get. I would recommend training a medium model as it's pretty smart and not too hard to train. My production chatbot that is currently running on a server with a thousand plus users is also a medium model. For this tutorial, for the sake of time, I'm training just a small model.\n\nYou can see here it's downloading the model and this may take some time because it's essentially 300 megabytes.\n\nHere are some hyperparameters that you may find useful. For example, num_train_epochs is the number of training epochs. This is defined to be four here, and this is the number of times that the model will cycle through the training set. As long as the model is not overfitting, increasing the number of training epochs usually results in smarter models because the model has more time to cycle through the dataset and pick up the nitty-gritty details. There is another hyperparameter called batch size. This is the number of training examples that the model will see in a batch before it updates its gradient. I wouldn't recommend changing this unless you know what you're doing since other hyperparameters like learning rate and temperature might be sensitive to this change in batch size. However, if you're training a larger model on a larger dataset and are running into memory errors, to make the error go away, it might help to decrease the batch size.\n\nThe remaining cells have been configured to take in this context data frame we created, train the model, and save it to a folder called output_small. Now let's run this main function.\n\nTraining will take some time. I trained my medium model for 12 epochs and it took around two hours, so do sit back and grab a snack while the model is training.\n\nYou can see the progress in the progress bars above.\n\nAll right. Here we get back a perplexity answer. This usually refers to how confused the model is. If a model has a large perplexity, it means that the model is pretty confused as to which words to choose to respond to a given situation, and the model might not be very smart. In our case, our dataset is pretty small and only has 150 plus lines, so it makes sense that the perplexity is high. To decrease the perplexity, we might need to train for more epochs. Cool. But now that the training is complete, we can load and chat with the model here.\n\nAll right. Let's change the name of the bot.\n\nHello, fellow Red Rider. So let's ask how's it created?\n\nThere is no such thing as a bad Red Rider.\n\nGreat. It looks like our chatbot is capable of making and maintaining a conversation. Now we can push the model to Hugging Face and start building our Discord chatbot.\n\nAll right. Now let's change directory just into the content folder because we'll be doing our push there, and we do pip install huggingface command-line client, and then we log in using our credentials.\n\nAll right. After logging in, we're assigned this token. We need to grab this token for the cell that we need to do afterwards. So we can create a repository to store our model from the command line. Mine is going to be called dialogue_gpt_small_harry_potter.\n\nAnd our empty model repository is right here. There is nothing except for the git attributes file, but we will be adding the model files soon.\n\nNow we install Git LFS, which stands for Git Large File Storage. This will allows us to push and pull our models. And we replace this token with the token we just copied from above.\n\nSo here's my username and my token.\n\nAnd we call that our training result is stored in this output_small directory.\n\nAnd now we change directory into our dialogue_gpt_small directory because we need to do get, add, and commit from there. We install the Git LFS, and inspect the content of our current directory, which should be dialogue_gpt_small_harry_potter, and also just print out the working directory we're in to make sure that we are inside content. Cool. Now we check the file status on Git. So these files that we need to add to Git. So we do a Git add. This will take some time because the pytorch_model.bin is pretty large. And we configure the global username and user email. These are just my Hugging Face credentials. And we commit with message \"Initial commit.\" And finally, we push the model. It's about 400 megabytes because the PyTorch model is itself about 400 megabytes.\n\nAll right. Looks like the push is complete.\n\nNow we see our PyTorch model here. However, there's one more thing that we need to do before we can converse with the model on Hugging Face. That is, you see here it's tagged as text generation. However, we know that we are training a chatbot model and we want our model to be conversational. For that purpose, we need to add a model card.\n\nSo we create a model card here, and we're putting in our desired model tags. So our tags is conversational.\n\nAnd we commit our model card. And now our model is correctly tagged as conversational. If we go to the main model page, we can start chatting with the model here.\n\nAll right. Now that we have pushed our model to Hugging Face, we're ready to use it in our Discord chatbot.\n\nNow we have our model. Let's build the Discord bot. Here, on Discord, I have my server, Lynn's Dev Lab. I have two channels: one for the Python bot and one for the JavaScript bot. The reason why we have separate channel for the bots is because we don't want the bots to be talking to each other. So after we build the bot, we will learn how to set their permissions correctly so that they don't go outside of their dedicated channel.\n\nSo we go to Discord's developers page, create an application. We need one application per bot. So our name will be ChattyBot Python.\n\nSo here we create a bot, and I'm going to name this Harry Potter Bot Python and upload an icon.\n\nWe will be using this API token here when we create our bot in Python. We're going to host our bot on Repl.it. So sign up for Repl.it and create a new Python Repl here. Going to name this ChattyBot Python.\n\nAnd in here, we will need to store our API tokens for Hugging Face and Discord as environmental variables. So here is a tab for the secrets for the environment variables. So the first one will be huggingface_token.\n\nAnd for the value, we will go to our Hugging Face profile, edit profile, API tokens, copy the API token, come back here, and fill in that value. Next, we'll create a Discord token. And for this value, we go to this Discord developers portal and copy the token. We add the token here, and our environment variables are all set.\n\nNext, I have the Python file in my GitHub repository called discord_bot.py.\n\nSo we grab the code from here, and I will explain the code line by line. Starting from line one, we first import the OS module that will help us reading our environment variables.\n\nNext, we import modules that are useful for querying the Hugging Face model. Finally, we import the Discord module. And here I have my API URL pointing to my username.\n\nAnd we define a bot as follows. In the on_ready function, it takes in a model name, which for me will be dialogue_gpt_small_harry_potter.\n\nThen we store this API endpoint by concatenating this API URL, which is my profile link, with the model name. Then we retrieve the secret API token from the system environment by looking up os.environ huggingface_token.\n\nNext, we format the header in our request to Hugging Face. For the authorization part, we put in bearer and the Hugging Face token. Next, we define a query method that takes in the payload. We dump the payload as a JSON string, and use the request module to make an HTTP POST request to the API endpoint using our defined request headers, which contains our Hugging Face API key and passing in the data.\n\nOnce the request finishes, it should give us a response object, and we decode it from UTF-8 and load the result as a string and return the string. Next, we define an asynchronous function named on_ready. The next two function definitions are based on the Discord API. Both are asynchronous function. The first one is on_ready. This function will be called when the bot is logging in. So when the bot is logging in, we will print out \"Logged in as,\" print out the bot's name and the bot's ID so that we know that the bot is functioning.\n\nNext, because our bot is a chatbot, it needs to respond to messages. So on_message is a method that will be called each time the bot sees a message in the channel. So given the message, if the message is coming from the bot itself, the bot ignores the message and does not reply to it. Otherwise, it will form a query payload with the content of the message.\n\nAnd to make the bot more user-friendly, while the bot is waiting for the HTTP response from the model, we set its status as typing so that the user will know that the bot is generating its response. So this is an asynchronous call with message.channel.typing. We call self.query using the payload and get back the response.\n\nIf there is a valid generated response, there will be a generated_text field in this response, and we'll be able to get that out as the bot's response. Otherwise, there might be an error in the response. We just log out the error message so that we can debug the bot later on.\n\nFinally, we use another asynchronous method to send the bot's response to the channel using message.channel.send. And that's it about our bot definition. In the main function, we just create a bot and pass in the model name. So for me, this is dialogue_gpt_small_harry_potter.\n\nAnd use client.run, looking up the Discord token from the environment variables. Great. Now that our bot should be all set up, let's invite the bot to our channel.\n\nIn the OAuth2 tab, we are going to select the bot.\n\nAnd for the bot permissions, the only thing it needs is to send messages.\n\nSo we copy this URL, paste it in a new browser window, and invite it to my server.\n\nAll right. Now that we see that our bot has appeared. However, it shows as offline. So we need to run the Repl. So we hit run here, and Repl.it is installing all our dependencies and imports.\n\nGreat. Now that our bot has logged in as Harry Potter Bot Python, and this is its unique ID, let's go to the server and now that the bot is online.\n\nI don't want the bot to appear in the general channel, so we go to the channel setting, permissions, advanced permissions, add the bot, and we remove its permission to send messages and save the changes.\n\nNow, let's see what happens if I type something in the general channel. Nothing should happen because the bot shouldn't be able to send a message. Nothing happens, although the bot is online. And now this bot should work in this Python bot channel. So let's do hello.\n\nAnd we briefly saw that there's a typing prompt.\n\nCool. So yeah, this is how we built a bot in Python. One thing to know in our Repl.it is that because we took away the bot's permission to send the messages in the general channel, it is showing an exception, and this is totally okay. If you don't like seeing this exception, you can use a try except block and log out this exception.\n\nGreat. So now we're going to repeat the process for the JavaScript bot. So we go back to the Discord developer portal and create a new application. This time, I'm going to call it ChattyBot JavaScript.\n\nAnd we create a bot.\n\nBack to Repl.it, we create a node.js app. Going to call it chatty_bot.js.\n\nWe again create two environmental variables. The first one is huggingface_token.\n\nCopying my API token from my profile, edit profile, putting here, and copy my Discord bot token. Call this one discord_token, and adding the value. Great. Now we have our environment variable set up.\n\nGo to my GitHub repository. There is a discord_bot.js file that contains the code that we will use for this JavaScript chatbot. Let's copy paste, and I will go through the code line by line. So first we import the Discord API for the JavaScript module, and we import fetch for making HTTP requests, just like we did in Python, and we initialize a new Discord client and define the model URL just as my username and the model name. So this guy is dialogue_gpt_small_harry_potter.\n\nAnd this is the same callback that is called when the bot is ready, just like the on_ready function we saw in Python. So when the bot is ready and logged in, we print out \"Logged in as\" client.user.tag.\n\nAnd here is another callback, this time on_message. We use an asynchronous callback because we are making HTTP requests. Like in the Python script, we ignore the message if the message is from the bot itself by checking if message.author is the bot.\n\nNow we form the payload. So the payload is a dictionary containing inputs with text message.content, which is the message that the bot has received. And we form the request headers by again using the Hugging Face API key. So we read the Hugging Face token from the environment, process.env.huggingface_token, and form the headers.\n\nRight before we start making the HTTP request, we set the bot status to typing. Now we query the server. So the response is the result from this call to fetch using HTTP POST, given the payload as the body and the headers using the Hugging Face token. And we convert the response into JSON format and extract out the generated_text field.\n\nIf there isn't a generated_text field in the response, but instead the response contains an error field, this means that the bot has encountered some errors, and we may want to print out the error for further debugging. Now that we have the bot's response, we can clear out its typing status and send the message to the channel as a reply.\n\nThis ends the definition of our client.on_message call. Down here, we log in using the Discord token. Now let's invite the bot to our server. So we go to OAuth, check the bot. It's only permission is to send messages. We copy this, paste in a new browser window, and invite it to our server.\n\nGreat. Looks like we have another bot.\n\nRemember to click on \"Save Changes,\" otherwise, the bot's icon wouldn't be showing. Now that we have our bot, however, it's not logged in. So we need to go back to Repl to run our script. But before we run our Repl, let's make sure that the bot doesn't have access to the general channel, nor does it have access to the Python channel because it's not supposed to go there. So in permissions,\n\nwe find this ChattyBot JavaScript, remove its permission to send messages, and always remember to save the changes. We do the same thing for it on the Python channel.\n\nAnd go to the JS channel. This time, the one we need to remove is the Python bot. So this Python bot shouldn't be able to send messages to this JavaScript channel.\n\nNow we go back to run our Repl.it.\n\nIf you see this error, this means that the Discord version that npm is trying to install is wrong. You can see that there are those warnings that the newest Discord module is not compatible with Repl.it's version of node or npm. So we need to manually change something in package.json. So here, we just use the older version and rerun it.\n\nNow that we are logged in as ChattyBot JavaScript 1048, let's go back to our Discord channel. Cool. The ChattyBot is also online. Let's see if it responds to our messages.\n\nAll right. So this is now an error message telling us that the model is still loading. The model will usually take one or two minutes to load, so let's give it some time.\n\nGreat. Looks like our bot is responding to us.\n\nAnd because we have set the bot's permissions correctly, the Python bot is not responding to any messages here, and the JavaScript bot shouldn't be able to talk here.\n\nAnd in our general channel, no bot is ever allowed to talk here. Cool. So now we have successfully built the bot both in Python and in JavaScript.\n\nOne thing to note is that if I close the browser tab for the Python bot,\n\nthe bot is no longer responding, although it still shows that the bot is online. So in the next part, we're going to look at how to keep the bot running indefinitely in the browser, even when we close the browser tab.\n\nIn order to get our bot to run indefinitely, we need to create a web server in Repl.it and set up a service called Uptime Robot to continuously ping the web server. So this is for the Python bot, and we create a new file called keep_alive.py.\n\nAnd we add the code for a web server like this.\n\nAnd in our main.py, we import that part.\n\nAnd down here in the main function, right before the bot runs, we ask it to be kept alive.\n\nAnd we run it.\n\nWhen the code runs, we see a URL shown in this tab, and we copy this URL and bring it to our Uptime Robot service. So here is the Uptime Robot website, and I already have an account, so I'll just go to my dashboard and add a new monitor. Monitor type is going to be HTTPS, friendly name Discord Python bot, the URL is the one we copied from here, and the monitoring level will be a ping every five minutes. That should be sufficient. And finally, we create monitor.\n\nAnd close it. Now, let's see if our Python bot is capable of running indefinitely.\n\nAll right. I'm going to close this tab containing my Python script.\n\nAnd it looks like our model is still up. It's just that after some time, the model on Hugging Face backend will reload, but because the bot itself is responding, we know that our web server approach has worked.\n\nNow, let's repeat this process for the JavaScript bot.\n\nWe create a new file called server.js, and copy paste this code.\n\nThen we import this part from the file that we just created.\n\nFinally, right before the bot runs, we are going to call keep_alive. We stop the service and run it.\n\nAll right. The server is now ready. We copy this URL, go to Uptime Robot, and add a new monitor. It's again an HTTP monitor, Discord JS bot, and the URL is like this, and we create a monitor.\n\nNow we can safely close this browser window and go back to our Discord chat.\n\nAnd the bot is still running.\n\nGreat. Now we're all done. We have a cool Python chatbot and a cool JavaScript chatbot that can run indefinitely. I hope you enjoyed this video. Please subscribe for more content like this, and I'll see you in the next one.",
    "segments": [
      {
        "start": 0.0,
        "end": 30.19,
        "text": "Wanna make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you wanna make it talk like another favorite character. In this course, Lynn will show you how to create a Discord bot that uses artificial intelligence to talk"
      },
      {
        "start": 30.17,
        "end": 60.36,
        "text": "like a character of your choice. Hi there. I'm Lynn. I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago. In this tutorial, we're going to build a Discord AI chatbot that can speak like your favorite character. Before we"
      },
      {
        "start": 60.34,
        "end": 90.53,
        "text": "start, if you have seen that video by any chance, know that this video is something different and more comprehensive. So keep watching till the end. The original tutorial and my first Discord bot started as a joke between me and my friends when we"
      },
      {
        "start": 90.5,
        "end": 120.7,
        "text": "were playing video games, and it really surprised me how popular it became, and a lot of people wanted to build their own bot based on that tutorial. Therefore, I decided to update that tutorial to include more characters, as well as to show you"
      },
      {
        "start": 120.67,
        "end": 150.86,
        "text": "how to find data for your favorite character. Other topics that we will cover here include, but are not limited to: how to train the model, how to deploy the model, common errors you might see during this model training and deployment pipeline, and how"
      },
      {
        "start": 150.84,
        "end": 181.03,
        "text": "to solve them. Moreover, we will cover how to build the bot in Python, and how to build it in JavaScript. Lastly, we will cover how to properly deploy the bot to a Discord server and limit it to certain channels, and how to keep"
      },
      {
        "start": 181.01,
        "end": 211.2,
        "text": "the bot running indefinitely. I hope you're excited and let's jump into the tutorial. First, we are going to find data for our character. My favorite sources are Kaggle, Transcript Wiki, and just random fandom websites that came out from the Google search. And my"
      },
      {
        "start": 211.18,
        "end": 241.37,
        "text": "research process goes like this: I first search on Kaggle to see if there are pre-made dialogue datasets. For example, if we search for Rick and Morty, we get this nicely formatted dataset that includes the name of the character and the line they're speaking."
      },
      {
        "start": 241.34,
        "end": 271.54,
        "text": "If we search for Harry Potter, here is another dataset that includes the character and the sentence they're speaking. Since we're building a chatbot, we need only these two columns in our dataset: the character name and the line they're speaking. So these dialogue datasets"
      },
      {
        "start": 271.51,
        "end": 301.7,
        "text": "on Kaggle are perfect for our requirement. All right. If we succeeded in finding our data on Kaggle, we can move on to the model training step. But what if we cannot find a dataset for our character on Kaggle? For example, if I want"
      },
      {
        "start": 301.68,
        "end": 331.87,
        "text": "to find a dataset for Peppa Pig, it looks like there is no dataset for the character. In this case, we may need to find the raw transcript of the media, be it a video game, a cartoon, or a show, and I've found that"
      },
      {
        "start": 331.85,
        "end": 362.04,
        "text": "Transcript Wiki has some great resources. So here we have a list of movies, shows, video games, musicals, commercials. For example, I was able to find a transcript for Peppa Pig, and also movies like Batman on Transcript Wiki. The transcript looks like this. So"
      },
      {
        "start": 362.02,
        "end": 392.21,
        "text": "we have the character name and their actions or the lines they're speaking. We will see shortly how to turn a raw transcript like this into a dataset like those we saw on Kaggle. Besides Transcript Wiki, you may also just Google the name of"
      },
      {
        "start": 392.18,
        "end": 422.38,
        "text": "your media with the keyword transcript. For example, my first bot was based on the game, \"The Word Ends With You,\" and it has no results either on Kaggle or Transcript Wiki. So what I did was to just Google the name of the game"
      },
      {
        "start": 422.35,
        "end": 452.54,
        "text": "and \"game transcript.\" And it just happened that this fandom website has the full game transcript. So be sure to utilize your Google search skills to find data for your character. If, rather than fictional character, you are more interested in real-life character, you may"
      },
      {
        "start": 452.52,
        "end": 482.71,
        "text": "search for interview scripts as your data source. If you want to create a chatbot that speaks like yourself or your friends, you can treat text messages between you and your friends as dialogues and handcraft your dataset. There are tons of ways to get"
      },
      {
        "start": 482.69,
        "end": 512.88,
        "text": "data for your characters, so be creative. And now we will look at how to turn raw transcript into a dataset. Now, suppose we have found our raw transcript. Let's see how we can turn it into a two-column character line dataset. Suppose we take"
      },
      {
        "start": 512.86,
        "end": 543.05,
        "text": "this Peppa Pig transcripts and copy them into a text file. Now we go to Google Colab and upload our data file. Then we create a Google Colab notebook, and use this to parse our script. So I'm going to name this parse_script.ipynb. And we"
      },
      {
        "start": 543.02,
        "end": 573.22,
        "text": "are going to from Google Colab import drive, and then call drive.mount content drive. This will allow us to read the data from our Google Drive. All right. Now that our drive has been mounted, let's import OS and then OS change directory into content"
      },
      {
        "start": 573.19,
        "end": 603.38,
        "text": "drive, my drive. And now we see if there is anything in it. Yeah, we have our peppapig.txt. So here we are going to import regular expression to parse our transcript, put the parsed result into a Pandas data frame, and export it as a"
      },
      {
        "start": 603.36,
        "end": 633.55,
        "text": "CSV file, just like those we saw on Kaggle. This is going to be our regular expression pattern. You don't have to be a pro in regular expression to understand this part. If we take the pattern to this site, and our test string is"
      },
      {
        "start": 633.53,
        "end": 663.72,
        "text": "Peppa Pig, you will see that we have two match capture groups, the first being the character's name, the second being the line spoken, and also for the second line, Mama Pig, we have the character name and the line being spoken. Right. So that's"
      },
      {
        "start": 663.7,
        "end": 693.89,
        "text": "our regular expression. Now, let's define a dictionary that will store our data. So we know that we need the column name and the column line in our result data frame. And now we open and read the file. For each line, we match it"
      },
      {
        "start": 693.86,
        "end": 724.05,
        "text": "with our regular expression pattern. If there is a match, we extract name and line from this regular expression match, and then append it to our dictionary here. And then we convert this dictionary into a data frame. Now we can inspect the data frame."
      },
      {
        "start": 724.03,
        "end": 754.22,
        "text": "Cool. So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Mama Pig makes a sound. Great. We can also count the number of lines that belong to our character. So we do sum df"
      },
      {
        "start": 754.2,
        "end": 784.39,
        "text": "name is equal to Peppa Pig. And we saw that Peppa Pig has 38 lines in our entire data frame. So the length of our data frame is over 100 and Peppa Pig has one third of the lines. Great. The last step will be"
      },
      {
        "start": 784.37,
        "end": 814.56,
        "text": "to export the data frame. So df.to_csv, the name will be peppapig.csv, and and we will drop the index. Cool. Now we should have a peppapig.csv in our drive. And here it is: name and line. This is how we parse those raw transcripts into"
      },
      {
        "start": 814.54,
        "end": 844.73,
        "text": "a file that could be used in our model training. So next, let's proceed onto the exciting step: model training. Now we are going to train the model. Go to my GitHub repository linked to in the description below and download the content. We're going"
      },
      {
        "start": 844.7,
        "end": 874.89,
        "text": "to use this model_train_upload_workflow.ipynb, which looks like this. All right. Now our file has been downloaded. We unzip the content. And in here we have a model_train_upload_workflow.ipynb. We upload this notebook file to Google Drive and open it in Google Colab. We're going to train"
      },
      {
        "start": 874.87,
        "end": 905.06,
        "text": "a GPT model, which is short for Generative Pre-trained Transformer. In the runtime, change runtime type. Make sure to select GPU because this will accelerate our model training. So now here we mount the drive. We install the Transformers module that we will be using,"
      },
      {
        "start": 905.04,
        "end": 935.23,
        "text": "and we change directory into my drive. Here are all the modules that we are importing. If we're using the dataset from Kaggle, we need to obtain our API key from Kaggle. So go to our Kaggle profile, go to Account, scroll down to the"
      },
      {
        "start": 935.21,
        "end": 965.4,
        "text": "API key section, create a new API token and download this file as kaggle.json. We will go back to Google Drive and upload kaggle.json. Now we can download our dataset from Kaggle. We're going to use the Harry Potter dataset as an example. So grab"
      },
      {
        "start": 965.38,
        "end": 995.57,
        "text": "this username and the dataset name, and our file is harry_potter_1.csv. Note that because there are white spaces in our file name, we got special characters in the file name. So let's inspect the content of our data file. Well, CSV files are usually separated"
      },
      {
        "start": 995.54,
        "end": 1025.73,
        "text": "by commas, has the name CSV. However, this one looks like it's separated by semicolons. So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. So separation is semicolon instead of a comma. Cool."
      },
      {
        "start": 1025.71,
        "end": 1055.9,
        "text": "So let's sample our data to see what's inside. All right. So we have character and sentence. Notice that these two column names aren't exactly what we need. We want the two columns of our data frame to be named as name and line, as"
      },
      {
        "start": 1055.88,
        "end": 1086.07,
        "text": "used down here in this cell. So we need to change the name of our columns. All right. Let's resample our data. Looks like we have successfully changed the name of our columns. Now let's see how big our data is. So it only has"
      },
      {
        "start": 1086.05,
        "end": 1116.24,
        "text": "a thousand or so lines, and let's see how many lines our character has. Our character has 155 lines. So here we change our character name to Harry, and we now run this cell to create a context data frame that includes the current line"
      },
      {
        "start": 1116.22,
        "end": 1146.41,
        "text": "our character is speaking and several lines directly preceding the line. A context data frame is useful here because we are creating a conversational chatbot and we want to generate a response based on the conversation context. So let's sample our context data frame. So"
      },
      {
        "start": 1146.38,
        "end": 1176.57,
        "text": "in the context of clearly something something, our character responds with \"Seems a pity not to ask her.\" Great. Now we have our dataset. We split the dataset into a training set and a test set. This is because we don't want to overfit the"
      },
      {
        "start": 1176.55,
        "end": 1206.74,
        "text": "model. In the case of overfitting, the model will just memorize lines from the dataset and talk back to us using the exact lines. We don't want that. We want the conversation to be more organic. So we're only training the model on the training"
      },
      {
        "start": 1206.72,
        "end": 1236.91,
        "text": "set and evaluating the model on the test set. So we continue running these cells to build datasets, caching checkpoints, and down here we build the model. We will build our model by fine-tuning Microsoft's pre-trained GPT small. Small here refers to the number of"
      },
      {
        "start": 1236.89,
        "end": 1267.08,
        "text": "parameters in the model. There are also a medium and a large model. Generally, the larger the model, the longer it takes to train, but the smarter the model can get. I would recommend training a medium model as it's pretty smart and not too"
      },
      {
        "start": 1267.06,
        "end": 1297.25,
        "text": "hard to train. My production chatbot that is currently running on a server with a thousand plus users is also a medium model. For this tutorial, for the sake of time, I'm training just a small model. You can see here it's downloading the model"
      },
      {
        "start": 1297.22,
        "end": 1327.41,
        "text": "and this may take some time because it's essentially 300 megabytes. Here are some hyperparameters that you may find useful. For example, num_train_epochs is the number of training epochs. This is defined to be four here, and this is the number of times that the"
      },
      {
        "start": 1327.39,
        "end": 1357.58,
        "text": "model will cycle through the training set. As long as the model is not overfitting, increasing the number of training epochs usually results in smarter models because the model has more time to cycle through the dataset and pick up the nitty-gritty details. There is"
      },
      {
        "start": 1357.56,
        "end": 1387.75,
        "text": "another hyperparameter called batch size. This is the number of training examples that the model will see in a batch before it updates its gradient. I wouldn't recommend changing this unless you know what you're doing since other hyperparameters like learning rate and temperature might"
      },
      {
        "start": 1387.73,
        "end": 1417.92,
        "text": "be sensitive to this change in batch size. However, if you're training a larger model on a larger dataset and are running into memory errors, to make the error go away, it might help to decrease the batch size. The remaining cells have been configured"
      },
      {
        "start": 1417.9,
        "end": 1448.09,
        "text": "to take in this context data frame we created, train the model, and save it to a folder called output_small. Now let's run this main function. Training will take some time. I trained my medium model for 12 epochs and it took around two hours,"
      },
      {
        "start": 1448.06,
        "end": 1478.25,
        "text": "so do sit back and grab a snack while the model is training. You can see the progress in the progress bars above. All right. Here we get back a perplexity answer. This usually refers to how confused the model is. If a model has"
      },
      {
        "start": 1478.23,
        "end": 1508.42,
        "text": "a large perplexity, it means that the model is pretty confused as to which words to choose to respond to a given situation, and the model might not be very smart. In our case, our dataset is pretty small and only has 150 plus lines,"
      },
      {
        "start": 1508.4,
        "end": 1538.59,
        "text": "so it makes sense that the perplexity is high. To decrease the perplexity, we might need to train for more epochs. Cool. But now that the training is complete, we can load and chat with the model here. All right. Let's change the name of"
      },
      {
        "start": 1538.57,
        "end": 1568.76,
        "text": "the bot. Hello, fellow Red Rider. So let's ask how's it created? There is no such thing as a bad Red Rider. Great. It looks like our chatbot is capable of making and maintaining a conversation. Now we can push the model to Hugging Face"
      },
      {
        "start": 1568.74,
        "end": 1598.93,
        "text": "and start building our Discord chatbot. All right. Now let's change directory just into the content folder because we'll be doing our push there, and we do pip install huggingface command-line client, and then we log in using our credentials. All right. After logging in,"
      },
      {
        "start": 1598.9,
        "end": 1629.09,
        "text": "we're assigned this token. We need to grab this token for the cell that we need to do afterwards. So we can create a repository to store our model from the command line. Mine is going to be called dialogue_gpt_small_harry_potter. And our empty model repository"
      },
      {
        "start": 1629.07,
        "end": 1659.26,
        "text": "is right here. There is nothing except for the git attributes file, but we will be adding the model files soon. Now we install Git LFS, which stands for Git Large File Storage. This will allows us to push and pull our models. And we"
      },
      {
        "start": 1659.24,
        "end": 1689.43,
        "text": "replace this token with the token we just copied from above. So here's my username and my token. And we call that our training result is stored in this output_small directory. And now we change directory into our dialogue_gpt_small directory because we need to do"
      },
      {
        "start": 1689.41,
        "end": 1719.6,
        "text": "get, add, and commit from there. We install the Git LFS, and inspect the content of our current directory, which should be dialogue_gpt_small_harry_potter, and also just print out the working directory we're in to make sure that we are inside content. Cool. Now we check"
      },
      {
        "start": 1719.58,
        "end": 1749.77,
        "text": "the file status on Git. So these files that we need to add to Git. So we do a Git add. This will take some time because the pytorch_model.bin is pretty large. And we configure the global username and user email. These are just my"
      },
      {
        "start": 1749.74,
        "end": 1779.93,
        "text": "Hugging Face credentials. And we commit with message \"Initial commit.\" And finally, we push the model. It's about 400 megabytes because the PyTorch model is itself about 400 megabytes. All right. Looks like the push is complete. Now we see our PyTorch model here. However,"
      },
      {
        "start": 1779.91,
        "end": 1810.1,
        "text": "there's one more thing that we need to do before we can converse with the model on Hugging Face. That is, you see here it's tagged as text generation. However, we know that we are training a chatbot model and we want our model to"
      },
      {
        "start": 1810.08,
        "end": 1840.27,
        "text": "be conversational. For that purpose, we need to add a model card. So we create a model card here, and we're putting in our desired model tags. So our tags is conversational. And we commit our model card. And now our model is correctly tagged"
      },
      {
        "start": 1840.25,
        "end": 1870.44,
        "text": "as conversational. If we go to the main model page, we can start chatting with the model here. All right. Now that we have pushed our model to Hugging Face, we're ready to use it in our Discord chatbot. Now we have our model. Let's"
      },
      {
        "start": 1870.42,
        "end": 1900.61,
        "text": "build the Discord bot. Here, on Discord, I have my server, Lynn's Dev Lab. I have two channels: one for the Python bot and one for the JavaScript bot. The reason why we have separate channel for the bots is because we don't want the"
      },
      {
        "start": 1900.58,
        "end": 1930.77,
        "text": "bots to be talking to each other. So after we build the bot, we will learn how to set their permissions correctly so that they don't go outside of their dedicated channel. So we go to Discord's developers page, create an application. We need one"
      },
      {
        "start": 1930.75,
        "end": 1960.94,
        "text": "application per bot. So our name will be ChattyBot Python. So here we create a bot, and I'm going to name this Harry Potter Bot Python and upload an icon. We will be using this API token here when we create our bot in Python."
      },
      {
        "start": 1960.92,
        "end": 1991.11,
        "text": "We're going to host our bot on Repl.it. So sign up for Repl.it and create a new Python Repl here. Going to name this ChattyBot Python. And in here, we will need to store our API tokens for Hugging Face and Discord as environmental variables."
      },
      {
        "start": 1991.09,
        "end": 2021.28,
        "text": "So here is a tab for the secrets for the environment variables. So the first one will be huggingface_token. And for the value, we will go to our Hugging Face profile, edit profile, API tokens, copy the API token, come back here, and fill in"
      },
      {
        "start": 2021.26,
        "end": 2051.45,
        "text": "that value. Next, we'll create a Discord token. And for this value, we go to this Discord developers portal and copy the token. We add the token here, and our environment variables are all set. Next, I have the Python file in my GitHub repository"
      },
      {
        "start": 2051.42,
        "end": 2081.61,
        "text": "called discord_bot.py. So we grab the code from here, and I will explain the code line by line. Starting from line one, we first import the OS module that will help us reading our environment variables. Next, we import modules that are useful for querying"
      },
      {
        "start": 2081.59,
        "end": 2111.78,
        "text": "the Hugging Face model. Finally, we import the Discord module. And here I have my API URL pointing to my username. And we define a bot as follows. In the on_ready function, it takes in a model name, which for me will be dialogue_gpt_small_harry_potter. Then"
      },
      {
        "start": 2111.76,
        "end": 2141.95,
        "text": "we store this API endpoint by concatenating this API URL, which is my profile link, with the model name. Then we retrieve the secret API token from the system environment by looking up os.environ huggingface_token. Next, we format the header in our request to Hugging"
      },
      {
        "start": 2141.93,
        "end": 2172.12,
        "text": "Face. For the authorization part, we put in bearer and the Hugging Face token. Next, we define a query method that takes in the payload. We dump the payload as a JSON string, and use the request module to make an HTTP POST request to"
      },
      {
        "start": 2172.09,
        "end": 2202.29,
        "text": "the API endpoint using our defined request headers, which contains our Hugging Face API key and passing in the data. Once the request finishes, it should give us a response object, and we decode it from UTF-8 and load the result as a string and"
      },
      {
        "start": 2202.26,
        "end": 2232.45,
        "text": "return the string. Next, we define an asynchronous function named on_ready. The next two function definitions are based on the Discord API. Both are asynchronous function. The first one is on_ready. This function will be called when the bot is logging in. So when the"
      },
      {
        "start": 2232.43,
        "end": 2262.62,
        "text": "bot is logging in, we will print out \"Logged in as,\" print out the bot's name and the bot's ID so that we know that the bot is functioning. Next, because our bot is a chatbot, it needs to respond to messages. So on_message is"
      },
      {
        "start": 2262.6,
        "end": 2292.79,
        "text": "a method that will be called each time the bot sees a message in the channel. So given the message, if the message is coming from the bot itself, the bot ignores the message and does not reply to it. Otherwise, it will form a"
      },
      {
        "start": 2292.77,
        "end": 2322.96,
        "text": "query payload with the content of the message. And to make the bot more user-friendly, while the bot is waiting for the HTTP response from the model, we set its status as typing so that the user will know that the bot is generating its"
      },
      {
        "start": 2322.93,
        "end": 2353.13,
        "text": "response. So this is an asynchronous call with message.channel.typing. We call self.query using the payload and get back the response. If there is a valid generated response, there will be a generated_text field in this response, and we'll be able to get that out as"
      },
      {
        "start": 2353.1,
        "end": 2383.29,
        "text": "the bot's response. Otherwise, there might be an error in the response. We just log out the error message so that we can debug the bot later on. Finally, we use another asynchronous method to send the bot's response to the channel using message.channel.send. And"
      },
      {
        "start": 2383.27,
        "end": 2413.46,
        "text": "that's it about our bot definition. In the main function, we just create a bot and pass in the model name. So for me, this is dialogue_gpt_small_harry_potter. And use client.run, looking up the Discord token from the environment variables. Great. Now that our bot should"
      },
      {
        "start": 2413.44,
        "end": 2443.63,
        "text": "be all set up, let's invite the bot to our channel. In the OAuth2 tab, we are going to select the bot. And for the bot permissions, the only thing it needs is to send messages. So we copy this URL, paste it in a"
      },
      {
        "start": 2443.61,
        "end": 2473.8,
        "text": "new browser window, and invite it to my server. All right. Now that we see that our bot has appeared. However, it shows as offline. So we need to run the Repl. So we hit run here, and Repl.it is installing all our dependencies and"
      },
      {
        "start": 2473.77,
        "end": 2503.97,
        "text": "imports. Great. Now that our bot has logged in as Harry Potter Bot Python, and this is its unique ID, let's go to the server and now that the bot is online. I don't want the bot to appear in the general channel, so we"
      },
      {
        "start": 2503.94,
        "end": 2534.13,
        "text": "go to the channel setting, permissions, advanced permissions, add the bot, and we remove its permission to send messages and save the changes. Now, let's see what happens if I type something in the general channel. Nothing should happen because the bot shouldn't be able"
      },
      {
        "start": 2534.11,
        "end": 2564.3,
        "text": "to send a message. Nothing happens, although the bot is online. And now this bot should work in this Python bot channel. So let's do hello. And we briefly saw that there's a typing prompt. Cool. So yeah, this is how we built a bot"
      },
      {
        "start": 2564.28,
        "end": 2594.47,
        "text": "in Python. One thing to know in our Repl.it is that because we took away the bot's permission to send the messages in the general channel, it is showing an exception, and this is totally okay. If you don't like seeing this exception, you can"
      },
      {
        "start": 2594.45,
        "end": 2624.64,
        "text": "use a try except block and log out this exception. Great. So now we're going to repeat the process for the JavaScript bot. So we go back to the Discord developer portal and create a new application. This time, I'm going to call it ChattyBot"
      },
      {
        "start": 2624.61,
        "end": 2654.81,
        "text": "JavaScript. And we create a bot. Back to Repl.it, we create a node.js app. Going to call it chatty_bot.js. We again create two environmental variables. The first one is huggingface_token. Copying my API token from my profile, edit profile, putting here, and copy my Discord"
      },
      {
        "start": 2654.78,
        "end": 2684.97,
        "text": "bot token. Call this one discord_token, and adding the value. Great. Now we have our environment variable set up. Go to my GitHub repository. There is a discord_bot.js file that contains the code that we will use for this JavaScript chatbot. Let's copy paste, and"
      },
      {
        "start": 2684.95,
        "end": 2715.14,
        "text": "I will go through the code line by line. So first we import the Discord API for the JavaScript module, and we import fetch for making HTTP requests, just like we did in Python, and we initialize a new Discord client and define the model"
      },
      {
        "start": 2715.12,
        "end": 2745.31,
        "text": "URL just as my username and the model name. So this guy is dialogue_gpt_small_harry_potter. And this is the same callback that is called when the bot is ready, just like the on_ready function we saw in Python. So when the bot is ready and logged"
      },
      {
        "start": 2745.29,
        "end": 2775.48,
        "text": "in, we print out \"Logged in as\" client.user.tag. And here is another callback, this time on_message. We use an asynchronous callback because we are making HTTP requests. Like in the Python script, we ignore the message if the message is from the bot itself by"
      },
      {
        "start": 2775.45,
        "end": 2805.65,
        "text": "checking if message.author is the bot. Now we form the payload. So the payload is a dictionary containing inputs with text message.content, which is the message that the bot has received. And we form the request headers by again using the Hugging Face API key."
      },
      {
        "start": 2805.62,
        "end": 2835.81,
        "text": "So we read the Hugging Face token from the environment, process.env.huggingface_token, and form the headers. Right before we start making the HTTP request, we set the bot status to typing. Now we query the server. So the response is the result from this call to"
      },
      {
        "start": 2835.79,
        "end": 2865.98,
        "text": "fetch using HTTP POST, given the payload as the body and the headers using the Hugging Face token. And we convert the response into JSON format and extract out the generated_text field. If there isn't a generated_text field in the response, but instead the response"
      },
      {
        "start": 2865.96,
        "end": 2896.15,
        "text": "contains an error field, this means that the bot has encountered some errors, and we may want to print out the error for further debugging. Now that we have the bot's response, we can clear out its typing status and send the message to the"
      },
      {
        "start": 2896.13,
        "end": 2926.32,
        "text": "channel as a reply. This ends the definition of our client.on_message call. Down here, we log in using the Discord token. Now let's invite the bot to our server. So we go to OAuth, check the bot. It's only permission is to send messages. We"
      },
      {
        "start": 2926.29,
        "end": 2956.49,
        "text": "copy this, paste in a new browser window, and invite it to our server. Great. Looks like we have another bot. Remember to click on \"Save Changes,\" otherwise, the bot's icon wouldn't be showing. Now that we have our bot, however, it's not logged in."
      },
      {
        "start": 2956.46,
        "end": 2986.65,
        "text": "So we need to go back to Repl to run our script. But before we run our Repl, let's make sure that the bot doesn't have access to the general channel, nor does it have access to the Python channel because it's not supposed to"
      },
      {
        "start": 2986.63,
        "end": 3016.82,
        "text": "go there. So in permissions, we find this ChattyBot JavaScript, remove its permission to send messages, and always remember to save the changes. We do the same thing for it on the Python channel. And go to the JS channel. This time, the one we"
      },
      {
        "start": 3016.8,
        "end": 3046.99,
        "text": "need to remove is the Python bot. So this Python bot shouldn't be able to send messages to this JavaScript channel. Now we go back to run our Repl.it. If you see this error, this means that the Discord version that npm is trying to"
      },
      {
        "start": 3046.97,
        "end": 3077.16,
        "text": "install is wrong. You can see that there are those warnings that the newest Discord module is not compatible with Repl.it's version of node or npm. So we need to manually change something in package.json. So here, we just use the older version and rerun"
      },
      {
        "start": 3077.13,
        "end": 3107.33,
        "text": "it. Now that we are logged in as ChattyBot JavaScript 1048, let's go back to our Discord channel. Cool. The ChattyBot is also online. Let's see if it responds to our messages. All right. So this is now an error message telling us that the"
      },
      {
        "start": 3107.3,
        "end": 3137.49,
        "text": "model is still loading. The model will usually take one or two minutes to load, so let's give it some time. Great. Looks like our bot is responding to us. And because we have set the bot's permissions correctly, the Python bot is not responding"
      },
      {
        "start": 3137.47,
        "end": 3167.66,
        "text": "to any messages here, and the JavaScript bot shouldn't be able to talk here. And in our general channel, no bot is ever allowed to talk here. Cool. So now we have successfully built the bot both in Python and in JavaScript. One thing to"
      },
      {
        "start": 3167.64,
        "end": 3197.83,
        "text": "note is that if I close the browser tab for the Python bot, the bot is no longer responding, although it still shows that the bot is online. So in the next part, we're going to look at how to keep the bot running indefinitely"
      },
      {
        "start": 3197.81,
        "end": 3228.0,
        "text": "in the browser, even when we close the browser tab. In order to get our bot to run indefinitely, we need to create a web server in Repl.it and set up a service called Uptime Robot to continuously ping the web server. So this is"
      },
      {
        "start": 3227.97,
        "end": 3258.17,
        "text": "for the Python bot, and we create a new file called keep_alive.py. And we add the code for a web server like this. And in our main.py, we import that part. And down here in the main function, right before the bot runs, we ask"
      },
      {
        "start": 3258.14,
        "end": 3288.33,
        "text": "it to be kept alive. And we run it. When the code runs, we see a URL shown in this tab, and we copy this URL and bring it to our Uptime Robot service. So here is the Uptime Robot website, and I already have"
      },
      {
        "start": 3288.31,
        "end": 3318.5,
        "text": "an account, so I'll just go to my dashboard and add a new monitor. Monitor type is going to be HTTPS, friendly name Discord Python bot, the URL is the one we copied from here, and the monitoring level will be a ping every five"
      },
      {
        "start": 3318.48,
        "end": 3348.67,
        "text": "minutes. That should be sufficient. And finally, we create monitor. And close it. Now, let's see if our Python bot is capable of running indefinitely. All right. I'm going to close this tab containing my Python script. And it looks like our model is still"
      },
      {
        "start": 3348.65,
        "end": 3378.84,
        "text": "up. It's just that after some time, the model on Hugging Face backend will reload, but because the bot itself is responding, we know that our web server approach has worked. Now, let's repeat this process for the JavaScript bot. We create a new file"
      },
      {
        "start": 3378.81,
        "end": 3409.01,
        "text": "called server.js, and copy paste this code. Then we import this part from the file that we just created. Finally, right before the bot runs, we are going to call keep_alive. We stop the service and run it. All right. The server is now ready."
      },
      {
        "start": 3408.98,
        "end": 3439.17,
        "text": "We copy this URL, go to Uptime Robot, and add a new monitor. It's again an HTTP monitor, Discord JS bot, and the URL is like this, and we create a monitor. Now we can safely close this browser window and go back to our"
      },
      {
        "start": 3439.15,
        "end": 3469.34,
        "text": "Discord chat. And the bot is still running. Great. Now we're all done. We have a cool Python chatbot and a cool JavaScript chatbot that can run indefinitely. I hope you enjoyed this video. Please subscribe for more content like this, and I'll see you"
      },
      {
        "start": 3469.32,
        "end": 3472,
        "text": "in the next one."
      }
    ],
    "language": "en",
    "confidence": 0.95
  },
  "analysis": {
    "summary": "This tutorial demonstrates how to create a Discord chatbot using artificial intelligence to mimic the speech patterns of a chosen character. The instructor, Lynn, a software engineer and game developer, aims to provide a more comprehensive guide than previous versions.  The tutorial covers building the bot in both Python and JavaScript.\n\nThe first step involves finding data for the chosen character.  Lynn suggests Kaggle for pre-made dialogue datasets (demonstrated with Rick and Morty and Harry Potter examples). If a dataset isn't available, she recommends Transcript Wiki or a targeted Google search for raw transcripts.  The raw transcripts are then processed using Google Colab and regular expressions to create a two-column dataset (character name and line).  This is shown using a Peppa Pig example.\n\nNext, the model is trained using a pre-trained GPT model (Microsoft's GPT-small is used for demonstration; medium models are recommended for production). Hyperparameters like the number of training epochs are discussed; increasing epochs leads to smarter models but may increase training time.  The model is fine-tuned and tested using training and test datasets to prevent overfitting.  The resulting model is pushed to Hugging Face.\n\nFinally, the chatbot is integrated into Discord, with separate channels created for Python and JavaScript bots to prevent cross-talk.  The tutorial shows setting up the bot, handling API tokens (Hugging Face and Discord), and managing bot permissions to restrict channel access. A keep-alive web server is implemented (using Repl.it and Uptime Robot) to ensure the bot runs continuously, even when the browser tab is closed.  The final result is two functional Discord chatbots that can continuously interact with users.",
    "key_points": [
      {
        "timestamp": 7,
        "text": "Goal: Create a Discord bot that speaks like a chosen character (e.g., Rick and Morty, Harry Potter).",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 26,
        "text": "Introduction: Lynn, a software engineer, hobbyist game developer, and recent University of Chicago graduate, will guide the tutorial.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 46,
        "text": "Tutorial Goal: Build a Discord AI chatbot that speaks like your favorite character.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 58,
        "text": "Note: This tutorial is more comprehensive than a previous one.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 76,
        "text": "Origin Story: The project started as a joke during video games with friends and unexpectedly gained popularity.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 111,
        "text": "Tutorial Update: The tutorial is updated to include more characters and data acquisition methods.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 128,
        "text": "Topics Covered: Model training, deployment, common errors and solutions, Python and JavaScript bot building, bot deployment to Discord servers, and channel restriction.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 161,
        "text": "Data Acquisition: Preferred sources are Kaggle, Transcript Wiki, and fandom websites found via Google Search.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 186,
        "text": "Kaggle Data: Searching for \"Rick and Morty\" yields a dataset with character names and lines.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 215,
        "text": "Kaggle Data:  Searching for \"Harry Potter\" also provides a dataset with character names and lines.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 235,
        "text": "Dataset Requirements: Only character name and spoken line columns are needed for the chatbot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 251,
        "text": "Alternative Data Sources: If Kaggle lacks data for a character, use raw transcripts from sources like Transcript Wiki or via targeted Google searches (e.g., \"[media name] transcript\").",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 291,
        "text": "Transcript Wiki Example:  Shows how to find transcripts for various media (movies, shows, games, etc.).",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 319,
        "text": "Transcript Wiki Example: Found transcripts for Peppa Pig and Batman.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 334,
        "text": "Transcript Format: Shows an example transcript with character names and lines/actions.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 359,
        "text": "Converting Raw Transcripts: The tutorial will demonstrate how to convert a raw transcript into a Kaggle-like dataset.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 377,
        "text": "Google Search for Transcripts: If no transcript is available on Transcript Wiki, search Google using \"[Media Name] Transcript\".",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 399,
        "text": "Example: The instructor's first bot used data from a game with no Kaggle or Transcript Wiki data; a Google search found a fandom website containing the full game transcript.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 423,
        "text": "Real-life Character Data: For real-life figures, search for interview scripts.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 441,
        "text": "Personal Data: To create a chatbot that speaks like yourself or a friend, use text messages as dialogue data.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 459,
        "text": "Data Acquisition Summary: Be creative in finding data for your chosen character.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 472,
        "text": "Converting Raw Transcripts to Datasets:  Steps to process raw transcripts using Google Colab.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 486,
        "text": "Process: Upload transcript text file to Google Drive.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 502,
        "text": "Process: Create a Google Colab notebook.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 516,
        "text": "Process:  Use the notebook to parse the transcript.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 530,
        "text": "Process: Use regular expressions to parse the transcript and create a two-column (character, line) dataset.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 651,
        "text": "Regular Expression Pattern Explanation:  The provided regular expression pattern extracts the character name and spoken line.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 704,
        "text": "Regular Expression Output: Two match capture groups are identified: character's name and spoken line.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 736,
        "text": "Data Storage: Define a dictionary to store the parsed data, including columns 'name' and 'line'.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 791,
        "text": "Process: Open and read the transcript file.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 831,
        "text": "Process: Match each line with the regular expression pattern.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 862,
        "text": "Process: Extract the name and line from the regular expression match and append to the dictionary.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 897,
        "text": "Process: Convert the dictionary to a Pandas DataFrame.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 910,
        "text": "Process: Inspect the DataFrame to verify the data.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 928,
        "text": "Data Inspection: Example of data in the DataFrame showing character names and lines.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 951,
        "text": "Data Count: Peppa Pig has 38 lines in the total dataset.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 971,
        "text": "Dataset Size: Total DataFrame has over 100 lines, Peppa Pig having about one-third.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 986,
        "text": "Process: Export the DataFrame as a CSV file.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1006,
        "text": "Model Training: Download the `model_train_upload_workflow.ipynb` notebook from the GitHub repository (link in description).",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1049,
        "text": "Process: Unzip the downloaded content.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1066,
        "text": "Process: Upload the notebook to Google Drive and open it in Google Colab.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1089,
        "text": "Model Training: Use a GPT (Generative Pre-trained Transformer) model. Select GPU runtime for faster training.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1125,
        "text": "Process: Mount the Google Drive.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1143,
        "text": "Process: Install the Transformers module.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1160,
        "text": "Process: Change directory to the drive.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1177,
        "text": "Kaggle API Key: If using a Kaggle dataset, obtain the API key from your Kaggle profile.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1230,
        "text": "Process: Download the API key as `kaggle.json`.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1247,
        "text": "Process: Upload `kaggle.json` to Google Drive.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1266,
        "text": "Process: Download the Harry Potter dataset from Kaggle.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1310,
        "text": "Data File Issue: White spaces in the filename resulted in special characters. Inspect the file content.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1351,
        "text": "Data File Format: The CSV file uses semicolons instead of commas as separators. Modify the code to use semicolons.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1405,
        "text": "Data Inspection: Verify the character and sentence columns in the dataset.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1431,
        "text": "Column Renaming: Rename columns to 'name' and 'line'.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1484,
        "text": "Dataset Size:  The dataset contains approximately 1000 lines; Harry Potter has 155 lines.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1518,
        "text": "Context DataFrame: Create a context DataFrame that includes the current line and preceding lines.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1566,
        "text": "Context DataFrame Importance: Useful for conversational chatbots, providing context for response generation.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1595,
        "text": "Dataset Split: Split the dataset into training and testing sets to avoid overfitting.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1635,
        "text": "Overfitting Explanation: Overfitting causes the model to memorize lines instead of generating organic responses.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1674,
        "text": "Model Training Process: Train the model on the training set and evaluate it on the test set. (This process is shown in the notebook).",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1727,
        "text": "Model Choice:  Fine-tuning a Microsoft pre-trained GPT small model.  Medium model recommended for production, but small used for tutorial time constraints.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1789,
        "text": "Model Parameters:  Discussion on hyperparameters like number of training epochs and batch size.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1857,
        "text": "Training Epochs: Increasing epochs usually leads to a smarter model but may cause overfitting.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1916,
        "text": "Batch Size:  Changing the batch size is not recommended unless troubleshooting memory errors when training larger models.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 1986,
        "text": "Model Training Completion: After training, the perplexity is noted.  High perplexity can indicate a small dataset.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2050,
        "text": "Model Testing: Load and chat with the trained model.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2096,
        "text": "Bot Naming: Rename the bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2132,
        "text": "Bot Interaction: Test the bot's ability to maintain a conversation.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2184,
        "text": "Model Deployment: Push the model to Hugging Face.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2219,
        "text": "Process: Change directory to the content folder.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2237,
        "text": "Process: Install the Hugging Face command-line client using pip install hugginface-cli",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2271,
        "text": "Process: Log in using credentials.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2307,
        "text": "Process: Grab token after logging in.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2330,
        "text": "Repository Creation: Create a Hugging Face repository to store the model (example name: dialogue-gpt-small-harry-potter).",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2396,
        "text": "Git LFS: Install Git LFS (Large File Storage) for efficient model pushing and pulling.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2440,
        "text": "Process: Replace token in the code with the copied token.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2485,
        "text": "Process: Change directory to the dialogue-gpt-small-harry-potter directory.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2532,
        "text": "Process: Add, commit, and push the model using Git.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2580,
        "text": "Model Size:  Model size is approximately 400 MB.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2603,
        "text": "Model Push Completion: Verify the PyTorch model is uploaded.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2633,
        "text": "Model Tagging:  Add a model card to tag the model as \"conversational\" because it's a chatbot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2712,
        "text": "Process: Create and commit the model card.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2735,
        "text": "Model Verification: Verify the model is tagged correctly on the Hugging Face model page.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2762,
        "text": "Discord Bot Setup: Build the Discord bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2782,
        "text": "Discord Server Setup: Two channels are created, one for Python bot and one for JavaScript bot, to avoid bots interacting with each other.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2834,
        "text": "Discord Bot Permissions: Set permissions to restrict bots to their dedicated channels.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2864,
        "text": "Discord App Creation: Create a Discord application for each bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2902,
        "text": "Bot Creation: Create the bot in the Discord developer portal.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2957,
        "text": "API Token Usage: Use the API token for the Hugging Face model.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 2980,
        "text": "Repl.it Setup: Host the bot on Repl.it. Create a new Repl for the Python bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3033,
        "text": "Environment Variables: Store API tokens for Hugging Face and Discord as environment variables in Repl.it.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3113,
        "text": "Python Bot Code:  The instructor reviews the Python code line-by-line.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3162,
        "text": "Python Bot Code: Import necessary modules (os, transformers, discord).",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3220,
        "text": "Python Bot Code: Define API endpoint by combining API URL and model name.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3265,
        "text": "Python Bot Code: Retrieve the Hugging Face API token from the environment variables.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3296,
        "text": "Python Bot Code: Format the request headers for Hugging Face, including the authorization bearer token.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3338,
        "text": "Python Bot Code: Define the query method using the payload.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3376,
        "text": "Python Bot Code: Make HTTP POST request to the API endpoint using the headers and payload.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3457,
        "text": "Python Bot Code: Decode the UTF-8 response and return the generated text.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3508,
        "text": "Python Bot Code: Define asynchronous functions: `on_ready` and `on_message`.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3566,
        "text": "Python Bot Code: `on_ready` function: Print logged-in status, bot name, and ID.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3637,
        "text": "Python Bot Code: `on_message` function: Ignore messages from the bot itself. Otherwise, form a query payload and send to Hugging Face.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3722,
        "text": "Python Bot Code: Set bot status to 'typing' while waiting for the response.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3768,
        "text": "Python Bot Code: Make asynchronous call to query Hugging Face API and get the response.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3824,
        "text": "Python Bot Code: Handle valid responses by extracting the 'generated_text'.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3865,
        "text": "Python Bot Code: Handle errors and log error messages.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3900,
        "text": "Python Bot Code: Send the bot's response to the channel using `message.channel.send()`.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 3939,
        "text": "Python Bot Code: Main function creates the bot and runs it.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4004,
        "text": "Discord Bot Invitation: Invite the bot to the Discord server.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4047,
        "text": "Bot Status: The bot initially appears offline because it needs to be run on Repl.it.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4079,
        "text": "Repl.it Run: Run the Repl.it script to start the bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4123,
        "text": "Bot Logging: The bot logs in as 'harry-potter-bot-python' and its unique ID is shown.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4166,
        "text": "Permission Management: Remove the bot's permission to send messages in the general channel.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4234,
        "text": "Bot Functionality Test: Test the bot's functionality in the dedicated Python bot channel.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4308,
        "text": "Bot Typing Indicator: Observe the typing indicator while the bot generates responses.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4371,
        "text": "Python Bot Result: The Python bot is successfully built and functions as intended.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4414,
        "text": "Repl.it Exception: An exception is shown in Repl.it because permission to send messages in the general channel was removed.  This is expected behavior.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4478,
        "text": "Exception Handling: Use a try-except block to handle exceptions if desired.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4506,
        "text": "JavaScript Bot Setup: Repeat the process for the JavaScript bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4532,
        "text": "Discord App Creation: Create a new Discord application for the JavaScript bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4577,
        "text": "Repl.it Setup: Create a new Repl.it app for the JavaScript bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4627,
        "text": "Environment Variables: Add environment variables for Hugging Face and Discord tokens.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4722,
        "text": "JavaScript Bot Code: Review the JavaScript code line-by-line.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4751,
        "text": "JavaScript Bot Code: Import discord API and fetch for HTTP requests.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4809,
        "text": "JavaScript Bot Code: Initialize a Discord client, define model URL similarly to Python.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4879,
        "text": "JavaScript Bot Code: Define `on_ready` callback to print logged-in status.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 4930,
        "text": "JavaScript Bot Code: Define asynchronous `on_message` callback to handle messages; ignore messages from the bot itself.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5003,
        "text": "JavaScript Bot Code:  Form the payload and headers.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5065,
        "text": "JavaScript Bot Code: Set bot status to 'typing'.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5084,
        "text": "JavaScript Bot Code: Query the server using HTTP POST request.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5148,
        "text": "JavaScript Bot Code: Convert response to JSON, extract 'generated_text'.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5200,
        "text": "JavaScript Bot Code: Handle errors by checking for an 'error' field in the response.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5258,
        "text": "JavaScript Bot Code: Clear 'typing' status and send response.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5300,
        "text": "JavaScript Bot Code: Log in using Discord token.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5324,
        "text": "JavaScript Bot Invitation: Invite the JavaScript bot to the server.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5378,
        "text": "JavaScript Bot Permissions: Remove bot permission from general and Python channels.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5451,
        "text": "JavaScript Bot Run: Run the JavaScript bot on Repl.it.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5497,
        "text": "npm Install Error: Handle potential error related to Discord module version incompatibility.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5562,
        "text": "npm Install Error Solution: Manually change the Discord.js version in `package.json`.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5625,
        "text": "JavaScript Bot Logging: The bot logs in as 'chattybot-javascript' and its unique ID is shown.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5666,
        "text": "JavaScript Bot Online: Verify the bot is online in Discord.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5697,
        "text": "JavaScript Bot Loading: Error message indicating the model is still loading (allow 1-2 minutes).",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5768,
        "text": "JavaScript Bot Result: The JavaScript bot is responding to messages.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5837,
        "text": "Permission Management Success: Bots are responding only in their designated channels.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5908,
        "text": "Keeping Bots Running: Use a web server and uptime monitoring service to ensure bots run indefinitely.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 5965,
        "text": "Python Web Server: Create a `keep_alive.py` file with a web server for the Python bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6057,
        "text": "Python Bot Modification: Import the web server function in `main.py`.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6105,
        "text": "Python Bot Modification: Call the `keep_alive` function in `main.py` before the bot runs.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6171,
        "text": "Uptime Robot: Add the URL from the Repl.it web server to Uptime Robot for monitoring and keeping the bot alive.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6293,
        "text": "Uptime Robot Setup: Set up a new HTTP monitor in Uptime Robot; ping every 5 minutes.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6383,
        "text": "Python Bot Indefinite Run Test: Close the browser tab; the bot remains online and responsive.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6457,
        "text": "JavaScript Web Server: Create a `server.js` file with a web server for the Javascript bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6534,
        "text": "JavaScript Bot Modification: Import the web server from `server.js` and call `keep_alive` before running the bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6628,
        "text": "Uptime Robot Setup (JS Bot): Add the URL from the Repl.it web server to Uptime Robot for the Javascript bot.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6706,
        "text": "Browser Tab Closure: Close the browser tab. The bot remains online and responsive.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6755,
        "text": "Conclusion: Successfully created Discord chatbots (Python and JavaScript) that can run indefinitely.",
        "importance": 0.8,
        "context": null
      },
      {
        "timestamp": 6808,
        "text": "Call to Action: Subscribe for more content.",
        "importance": 0.8,
        "context": null
      }
    ],
    "entities": [
      {
        "name": "Harry Potter",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 75,
          "end_char": 87
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Transcript Wiki",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 1678,
          "end_char": 1693
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Google Colab",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 4524,
          "end_char": 4536
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Hugging Face",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 12866,
          "end_char": 12878
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Uptime Robot",
        "type": "SOFTWARE",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 26420,
          "end_char": 26432
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Discord",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 13,
          "end_char": 20
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Python",
        "type": "programming_language",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 1340,
          "end_char": 1346
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Kaggle",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 1670,
          "end_char": 1676
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Google",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 1750,
          "end_char": 1756
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Peppa Pig",
        "type": "CHARACTER",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 2566,
          "end_char": 2575
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Transformer",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 7220,
          "end_char": 7231
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Git",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 14206,
          "end_char": 14209
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "JavaScript",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 15535,
          "end_char": 15545
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "ChattyBot Python",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 15921,
          "end_char": 15937
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Harry Potter Bot Python",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 15992,
          "end_char": 16015
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Repl",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 20240,
          "end_char": 20244
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "ChattyBot",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 21516,
          "end_char": 21525
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "the Discord",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "FAC",
          "start_char": 18231,
          "end_char": 18242
        },
        "confidence": 0.8999999999999999,
        "timestamp": null
      },
      {
        "name": "Besides Transcript Wiki",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 3204,
          "end_char": 3227
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Google Drive",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "FAC",
          "start_char": 4637,
          "end_char": 4649
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Generative Pre-trained",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 7197,
          "end_char": 7219
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Git Large File Storage",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 13569,
          "end_char": 13591
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Python Repl",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 16188,
          "end_char": 16199
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Discord Python",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 27035,
          "end_char": 27049
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Wanna",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 0,
          "end_char": 5
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Rick",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 57,
          "end_char": 61
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Morty",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 66,
          "end_char": 71
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Lynn",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 167,
          "end_char": 171
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Pandas",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 4954,
          "end_char": 4960
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Account",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 7641,
          "end_char": 7648
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Red Rider",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 12664,
          "end_char": 12673
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "PyTorch",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 14557,
          "end_char": 14564
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "the University of Chicago",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 385,
          "end_char": 410
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "Batman on Transcript Wiki",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "WORK_OF_ART",
          "start_char": 2962,
          "end_char": 2987
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "The Word Ends With You",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "WORK_OF_ART",
          "start_char": 3356,
          "end_char": 3378
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "parse_script.ipynb",
        "type": "FILE",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 4479,
          "end_char": 4497
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "model_train_upload_workflow.ipynb",
        "type": "FILE",
        "properties": {
          "spacy_label": "PRODUCT",
          "start_char": 6884,
          "end_char": 6917
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "discord_bot.js",
        "type": "FILE",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 21958,
          "end_char": 21972
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "keep_alive.py",
        "type": "FILE",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 26533,
          "end_char": 26546
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "George",
        "type": "CHARACTER",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 6036,
          "end_char": 6042
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "Microsoft",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 10068,
          "end_char": 10077
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "Dev Lab",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 15466,
          "end_char": 15473
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "UTF-8",
        "type": "TECHNOLOGY",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 18066,
          "end_char": 18071
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "node",
        "type": "TECHNOLOGY",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 25179,
          "end_char": 25183
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "npm",
        "type": "TECHNOLOGY",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 25187,
          "end_char": 25190
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "message.content",
        "type": "VARIABLE",
        "properties": {
          "spacy_label": "PRODUCT",
          "start_char": 22938,
          "end_char": 22953
        },
        "confidence": 0.7499999999999999,
        "timestamp": null
      },
      {
        "name": "Rick and Morty",
        "type": "movie",
        "properties": {},
        "confidence": 0.8185796737670898,
        "timestamp": null
      },
      {
        "name": "University of Chicago",
        "type": "ORGANIZATION",
        "properties": {},
        "confidence": 0.71872478723526,
        "timestamp": null
      },
      {
        "name": "Discord bot",
        "type": "software",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "bot",
        "type": "SOFTWARE",
        "properties": {},
        "confidence": 0.7174870371818542,
        "timestamp": null
      },
      {
        "name": "favorite character",
        "type": "character",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "model",
        "type": "model",
        "properties": {},
        "confidence": 0.9518399238586426,
        "timestamp": null
      },
      {
        "name": "character",
        "type": "character",
        "properties": {},
        "confidence": 0.8723450899124146,
        "timestamp": null
      },
      {
        "name": "chatbot",
        "type": "api",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "video games",
        "type": "game",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "game",
        "type": "game",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "drive",
        "type": "TECHNOLOGY",
        "properties": {},
        "confidence": 0.936665415763855,
        "timestamp": null
      },
      {
        "name": "regular expression",
        "type": "TECHNOLOGY",
        "properties": {},
        "confidence": 0.7677367329597473,
        "timestamp": null
      },
      {
        "name": "Mama Pig",
        "type": "CHARACTER",
        "properties": {},
        "confidence": 0.9159917831420898,
        "timestamp": null
      },
      {
        "name": "peppapig",
        "type": "CHARACTER",
        "properties": {},
        "confidence": 0.9130569696426392,
        "timestamp": null
      },
      {
        "name": "GPT model",
        "type": "MODEL",
        "properties": {},
        "confidence": 0.7945997714996338,
        "timestamp": null
      },
      {
        "name": "Generative Pre-trained Transformer",
        "type": "MODEL",
        "properties": {},
        "confidence": 0.7191442251205444,
        "timestamp": null
      },
      {
        "name": "we",
        "type": "character",
        "properties": {},
        "confidence": 0.827878475189209,
        "timestamp": null
      },
      {
        "name": "our character",
        "type": "character",
        "properties": {},
        "confidence": 0.9631742238998413,
        "timestamp": null
      },
      {
        "name": "dataset",
        "type": "DATASET",
        "properties": {},
        "confidence": 0.7076377272605896,
        "timestamp": null
      },
      {
        "name": "username",
        "type": "PERSON",
        "properties": {},
        "confidence": 0.780322790145874,
        "timestamp": null
      },
      {
        "name": "get",
        "type": "OPERATION",
        "properties": {},
        "confidence": 0.7015755772590637,
        "timestamp": null
      },
      {
        "name": "add",
        "type": "OPERATION",
        "properties": {},
        "confidence": 0.7094175219535828,
        "timestamp": null
      },
      {
        "name": "user",
        "type": "person",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "API",
        "type": "API",
        "properties": {},
        "confidence": 0.78188157081604,
        "timestamp": null
      },
      {
        "name": "Hugging Face model",
        "type": "MODEL",
        "properties": {},
        "confidence": 0.8229730725288391,
        "timestamp": null
      },
      {
        "name": "HTTP",
        "type": "PROTOCOL",
        "properties": {},
        "confidence": 0.8089977502822876,
        "timestamp": null
      },
      {
        "name": "Hugging Face API",
        "type": "API",
        "properties": {},
        "confidence": 0.916340708732605,
        "timestamp": null
      },
      {
        "name": "Discord API",
        "type": "API",
        "properties": {},
        "confidence": 0.9315881729125977,
        "timestamp": null
      },
      {
        "name": "general channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.9596195220947266,
        "timestamp": null
      },
      {
        "name": "client",
        "type": "SOFTWARE",
        "properties": {},
        "confidence": 0.7063944935798645,
        "timestamp": null
      },
      {
        "name": "HTTP POST",
        "type": "PROTOCOL",
        "properties": {},
        "confidence": 0.8175955414772034,
        "timestamp": null
      },
      {
        "name": "Python channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.9560022354125977,
        "timestamp": null
      },
      {
        "name": "JS channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.8953447937965393,
        "timestamp": null
      },
      {
        "name": "JavaScript channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.8593723177909851,
        "timestamp": null
      },
      {
        "name": "Discord channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.854985237121582,
        "timestamp": null
      },
      {
        "name": "web server",
        "type": "SOFTWARE",
        "properties": {},
        "confidence": 0.7951722741127014,
        "timestamp": null
      },
      {
        "name": "HTTPS",
        "type": "PROTOCOL",
        "properties": {},
        "confidence": 0.9048122763633728,
        "timestamp": null
      },
      {
        "name": "Discord JS bot",
        "type": "SOFTWARE",
        "properties": {},
        "confidence": 0.8863077759742737,
        "timestamp": null
      }
    ],
    "topics": [
      {
        "name": "Creating a Discord bot that speaks like a chosen character using AI",
        "confidence": 0.85
      },
      {
        "name": "Finding data for the character (Kaggle, Transcript Wiki, Fandom websites)",
        "confidence": 0.85
      },
      {
        "name": "Data processing and transformation using regular expressions",
        "confidence": 0.85
      },
      {
        "name": "Model training using a pre-trained GPT model",
        "confidence": 0.85
      },
      {
        "name": "Deploying the bot to Discord (Python and Javascript versions)",
        "confidence": 0.85
      },
      {
        "name": "Setting bot permissions and channel access",
        "confidence": 0.85
      },
      {
        "name": "Keeping the bot running indefinitely using a web server and uptime robot",
        "confidence": 0.85
      }
    ],
    "sentiment": null
  },
  "processing": {
    "cost": 0.11573334220445834,
    "time": 406.004058,
    "processed_at": "2025-06-24T11:21:54.616142",
    "model": "gemini-1.5-flash",
    "extractor": "advanced_hybrid_v2.2"
  },
  "relationships": [
    {
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "use",
      "confidence": 0.9,
      "context": "Wanna make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you w"
    },
    {
      "subject": "Discord bot",
      "predicate": "instance of",
      "object": "artificial intelligence",
      "confidence": 0.9,
      "context": "Wanna make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you w"
    },
    {
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "uses",
      "confidence": 0.9,
      "context": "Wanna make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you w"
    },
    {
      "subject": "chatbot",
      "predicate": "AI",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago"
    },
    {
      "subject": "Discord",
      "predicate": "is a",
      "object": "chatbot",
      "confidence": 0.9,
      "context": "I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago"
    },
    {
      "subject": "Discord",
      "predicate": "is a",
      "object": "AI chatbot",
      "confidence": 0.9,
      "context": "I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago"
    },
    {
      "subject": "Discord bot",
      "predicate": "video game",
      "object": "use",
      "confidence": 0.9,
      "context": "The original tutorial and my first Discord bot started as a joke between me and my friends when we w"
    },
    {
      "subject": "Discord bot",
      "predicate": "video games",
      "object": "use",
      "confidence": 0.9,
      "context": "The original tutorial and my first Discord bot started as a joke between me and my friends when we w"
    },
    {
      "subject": "Discord",
      "predicate": "is a",
      "object": "video game",
      "confidence": 0.9,
      "context": "The original tutorial and my first Discord bot started as a joke between me and my friends when we w"
    },
    {
      "subject": "train the model",
      "predicate": "part of",
      "object": "model training and deployment pipeline",
      "confidence": 0.9,
      "context": "Therefore, I decided to update that tutorial to include more characters, as well as to show you how "
    },
    {
      "subject": "model training and deployment pipeline",
      "predicate": "has part",
      "object": "train the model",
      "confidence": 0.9,
      "context": "Therefore, I decided to update that tutorial to include more characters, as well as to show you how "
    },
    {
      "subject": "train the model",
      "predicate": "part of",
      "object": "deployment",
      "confidence": 0.9,
      "context": "Therefore, I decided to update that tutorial to include more characters, as well as to show you how "
    },
    {
      "subject": "Python",
      "predicate": "is influenced by",
      "object": "JavaScript",
      "confidence": 0.9,
      "context": "Therefore, I decided to update that tutorial to include more characters, as well as to show you how "
    },
    {
      "subject": "JavaScript",
      "predicate": "is influenced by",
      "object": "Python",
      "confidence": 0.9,
      "context": "Moreover, we will cover how to build the bot in Python, and how to build it in JavaScript.\n\nLastly, "
    },
    {
      "subject": "JavaScript",
      "predicate": "influenced by",
      "object": "Python",
      "confidence": 0.9,
      "context": "Moreover, we will cover how to build the bot in Python, and how to build it in JavaScript.\n\nLastly, "
    },
    {
      "subject": "Discord",
      "predicate": "uses",
      "object": "Python",
      "confidence": 0.9,
      "context": "Moreover, we will cover how to build the bot in Python, and how to build it in JavaScript.\n\nLastly, "
    },
    {
      "subject": "Rick and Morty",
      "predicate": "contains",
      "object": "lines of dialogue",
      "confidence": 0.9,
      "context": "And my research process goes like this: I first search on Kaggle to see if there are pre-made dialog"
    },
    {
      "subject": "lines of dialogue",
      "predicate": "are part of",
      "object": "Rick and Morty",
      "confidence": 0.9,
      "context": "And my research process goes like this: I first search on Kaggle to see if there are pre-made dialog"
    },
    {
      "subject": "Rick and Morty",
      "predicate": "features",
      "object": "characters",
      "confidence": 0.9,
      "context": "And my research process goes like this: I first search on Kaggle to see if there are pre-made dialog"
    },
    {
      "subject": "lines of dialogue",
      "predicate": "are present in",
      "object": "Rick and Morty",
      "confidence": 0.9,
      "context": "And my research process goes like this: I first search on Kaggle to see if there are pre-made dialog"
    },
    {
      "subject": "Rick and Morty",
      "predicate": "is a",
      "object": "notable work",
      "confidence": 0.9,
      "context": "And my research process goes like this: I first search on Kaggle to see if there are pre-made dialog"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "instance of",
      "object": "dataset",
      "confidence": 0.9,
      "context": "Since we're building a chatbot, we need only these two columns in our dataset: the character name an"
    },
    {
      "subject": "dataset",
      "predicate": "part of",
      "object": "model",
      "confidence": 0.9,
      "context": "Since we're building a chatbot, we need only these two columns in our dataset: the character name an"
    },
    {
      "subject": "model",
      "predicate": "has part",
      "object": "dataset",
      "confidence": 0.9,
      "context": "Since we're building a chatbot, we need only these two columns in our dataset: the character name an"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "instance of",
      "object": "cartoon",
      "confidence": 0.9,
      "context": "In this case, we may need to find the raw transcript of the media, be it a video game, a cartoon, or"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "cartoon",
      "object": "genre",
      "confidence": 0.9,
      "context": "In this case, we may need to find the raw transcript of the media, be it a video game, a cartoon, or"
    },
    {
      "subject": "Batman",
      "predicate": "instance of",
      "object": "video game",
      "confidence": 0.9,
      "context": "In this case, we may need to find the raw transcript of the media, be it a video game, a cartoon, or"
    },
    {
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "game",
      "confidence": 0.9,
      "context": "We will see shortly how to turn a raw transcript like this into a dataset like those we saw on Kaggl"
    },
    {
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "fandom website",
      "confidence": 0.9,
      "context": "We will see shortly how to turn a raw transcript like this into a dataset like those we saw on Kaggl"
    },
    {
      "subject": "Kaggle",
      "predicate": "instance of",
      "object": "dataset",
      "confidence": 0.9,
      "context": "We will see shortly how to turn a raw transcript like this into a dataset like those we saw on Kaggl"
    },
    {
      "subject": "chatbot",
      "predicate": "dialogues",
      "object": "uses",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "Google",
      "predicate": "is a",
      "object": "search engine",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "two-column",
      "predicate": "is a",
      "object": "character line",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "text messages",
      "predicate": "chatbot",
      "object": "used by",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "Google",
      "predicate": "instance of",
      "object": "search",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "dataset",
      "predicate": "is a type of",
      "object": "text file",
      "confidence": 0.9,
      "context": "And now we will look at how to turn raw transcript into a dataset.\n\nNow, suppose we have found our r"
    },
    {
      "subject": "Google Colab",
      "predicate": "uses",
      "object": "Google Drive",
      "confidence": 0.9,
      "context": "And now we will look at how to turn raw transcript into a dataset.\n\nNow, suppose we have found our r"
    },
    {
      "subject": "Google Drive",
      "predicate": "is used by",
      "object": "Google Colab",
      "confidence": 0.9,
      "context": "And now we will look at how to turn raw transcript into a dataset.\n\nNow, suppose we have found our r"
    },
    {
      "subject": "Google Colab",
      "predicate": "is part of",
      "object": "Google Drive",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive, and then call drive.mount content drive. This wi"
    },
    {
      "subject": "Google Drive",
      "predicate": "contains",
      "object": "Google Colab",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive, and then call drive.mount content drive. This wi"
    },
    {
      "subject": "Google Colab",
      "predicate": "runs on",
      "object": "operating system",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive, and then call drive.mount content drive. This wi"
    },
    {
      "subject": "Google Drive",
      "predicate": "runs on",
      "object": "operating system",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive, and then call drive.mount content drive. This wi"
    },
    {
      "subject": "CSV",
      "predicate": "is used by",
      "object": "Pandas",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive, and then call drive.mount content drive. This wi"
    },
    {
      "subject": "Pandas",
      "predicate": "uses",
      "object": "CSV",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive, and then call drive.mount content drive. This wi"
    },
    {
      "subject": "Pandas",
      "predicate": "uses",
      "object": "CSV",
      "confidence": 0.9,
      "context": "So here we are going to import regular expression to parse our transcript, put the parsed result int"
    },
    {
      "subject": "Pandas",
      "predicate": "CSV",
      "object": "use",
      "confidence": 0.9,
      "context": "So here we are going to import regular expression to parse our transcript, put the parsed result int"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "features",
      "object": "Mama Pig",
      "confidence": 0.9,
      "context": "So here we are going to import regular expression to parse our transcript, put the parsed result int"
    },
    {
      "subject": "Mama Pig",
      "predicate": "is featured in",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "If we take the pattern to this site, and our test string is Peppa Pig,\n\nyou will see that we have tw"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "is related to",
      "object": "Mama Pig",
      "confidence": 0.9,
      "context": "If we take the pattern to this site, and our test string is Peppa Pig,\n\nyou will see that we have tw"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "Mama Pig",
      "object": "sibling",
      "confidence": 0.9,
      "context": "If we take the pattern to this site, and our test string is Peppa Pig,\n\nyou will see that we have tw"
    },
    {
      "subject": "Mama Pig",
      "predicate": "Peppa Pig",
      "object": "sibling",
      "confidence": 0.9,
      "context": "If we take the pattern to this site, and our test string is Peppa Pig,\n\nyou will see that we have tw"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "Mama Pig",
      "object": "mother",
      "confidence": 0.9,
      "context": "If we take the pattern to this site, and our test string is Peppa Pig,\n\nyou will see that we have tw"
    },
    {
      "subject": "Mama Pig",
      "predicate": "Peppa Pig",
      "object": "child",
      "confidence": 0.9,
      "context": "If we take the pattern to this site, and our test string is Peppa Pig,\n\nyou will see that we have tw"
    },
    {
      "subject": "result data frame",
      "predicate": "data frame",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So we know that we need the column name and the column line in our result data frame.\n\nAnd now we op"
    },
    {
      "subject": "result data frame",
      "predicate": "instance of",
      "object": "data frame",
      "confidence": 0.9,
      "context": "So we know that we need the column name and the column line in our result data frame.\n\nAnd now we op"
    },
    {
      "subject": "parametric",
      "predicate": "regular expression",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So we know that we need the column name and the column line in our result data frame.\n\nAnd now we op"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "George",
      "object": "sibling",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "Mama Pig",
      "predicate": "sibling",
      "object": "George",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "sibling",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "sibling",
      "predicate": "Peppa Pig",
      "object": "sibling",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "Mama Pig",
      "predicate": "sibling",
      "object": "Mama Pig",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "sibling",
      "predicate": "George",
      "object": "sibling",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "George",
      "predicate": "sibling",
      "object": "Mama Pig",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "sibling",
      "predicate": "Mama Pig",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "George",
      "predicate": "sibling",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "So we have the name is Peppa Pig, saying that \"I'm Peppa Pig,\" and then George makes a sound, and Ma"
    },
    {
      "subject": "model training",
      "predicate": "train the model",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So df.to_csv, the name will be peppapig.csv, and and we will drop the index. Cool. Now we should hav"
    },
    {
      "subject": "peppapig",
      "predicate": "instance of",
      "object": "CSV",
      "confidence": 0.9,
      "context": "So df.to_csv, the name will be peppapig.csv, and and we will drop the index. Cool. Now we should hav"
    },
    {
      "subject": "train the model",
      "predicate": "model training",
      "object": "use",
      "confidence": 0.9,
      "context": "So df.to_csv, the name will be peppapig.csv, and and we will drop the index. Cool. Now we should hav"
    },
    {
      "subject": "Transformers",
      "predicate": "instance of",
      "object": "modules",
      "confidence": 0.9,
      "context": "So now here we mount the drive.\n\nWe install the Transformers module that we will be using, and we ch"
    },
    {
      "subject": "Transformers",
      "predicate": "part of",
      "object": "Google Drive",
      "confidence": 0.9,
      "context": "So now here we mount the drive.\n\nWe install the Transformers module that we will be using, and we ch"
    },
    {
      "subject": "Google Drive",
      "predicate": "has part",
      "object": "Transformers",
      "confidence": 0.9,
      "context": "So now here we mount the drive.\n\nWe install the Transformers module that we will be using, and we ch"
    },
    {
      "subject": "harry_potter_1",
      "predicate": "instance of",
      "object": "dataset",
      "confidence": 0.9,
      "context": "We're going to use the Harry Potter dataset as an example. So grab this username and the dataset nam"
    },
    {
      "subject": "harry_potter_1",
      "predicate": "Harry Potter",
      "object": "main subject",
      "confidence": 0.9,
      "context": "We're going to use the Harry Potter dataset as an example. So grab this username and the dataset nam"
    },
    {
      "subject": "harry_potter_1",
      "predicate": "instance of",
      "object": "CSV",
      "confidence": 0.9,
      "context": "We're going to use the Harry Potter dataset as an example. So grab this username and the dataset nam"
    },
    {
      "subject": "semicolon",
      "predicate": "comma",
      "object": "different from",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "comma",
      "predicate": "semicolon",
      "object": "different from",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "separation",
      "predicate": "comma",
      "object": "different from",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "comma",
      "predicate": "separation",
      "object": "different from",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "separation",
      "predicate": "has part",
      "object": "semicolon",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "semicolon",
      "predicate": "part of",
      "object": "separation",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "3772",
      "predicate": "3773",
      "object": "followed by",
      "confidence": 0.9,
      "context": "Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is."
    },
    {
      "subject": "3773",
      "predicate": "3772",
      "object": "follows",
      "confidence": 0.9,
      "context": "Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is."
    },
    {
      "subject": "3772",
      "predicate": "3771",
      "object": "followed by",
      "confidence": 0.9,
      "context": "Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is."
    },
    {
      "subject": "3771",
      "predicate": "3772",
      "object": "follows",
      "confidence": 0.9,
      "context": "Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is."
    },
    {
      "subject": "Harry",
      "predicate": "instance of",
      "object": "conversational chatbot",
      "confidence": 0.9,
      "context": "So here we change our character name to Harry, and we now run this cell to create a context data fra"
    },
    {
      "subject": "conversational",
      "predicate": "chatbot",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So here we change our character name to Harry, and we now run this cell to create a context data fra"
    },
    {
      "subject": "context data frame",
      "predicate": "conversational chatbot",
      "object": "use",
      "confidence": 0.9,
      "context": "So here we change our character name to Harry, and we now run this cell to create a context data fra"
    },
    {
      "subject": "training set",
      "predicate": "dataset",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So in the context of clearly something something, our character responds with \"Seems a pity not to a"
    },
    {
      "subject": "test set",
      "predicate": "dataset",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So in the context of clearly something something, our character responds with \"Seems a pity not to a"
    },
    {
      "subject": "GPT small",
      "predicate": "Microsoft",
      "object": "developer",
      "confidence": 0.9,
      "context": "So we're only training the model on the training set and evaluating the model on the test set.\n\nSo w"
    },
    {
      "subject": "small",
      "predicate": "parameters",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So we're only training the model on the training set and evaluating the model on the test set.\n\nSo w"
    },
    {
      "subject": "training",
      "predicate": "test set",
      "object": "followed by",
      "confidence": 0.9,
      "context": "So we're only training the model on the training set and evaluating the model on the test set.\n\nSo w"
    },
    {
      "subject": "num_train_epochs",
      "predicate": "instance of",
      "object": "hyperparameters",
      "confidence": 0.9,
      "context": "I would recommend training a medium model as it's pretty smart and not too hard to train. My product"
    },
    {
      "subject": "num_train_epochs",
      "predicate": "instance of",
      "object": "hyperparameter",
      "confidence": 0.9,
      "context": "I would recommend training a medium model as it's pretty smart and not too hard to train. My product"
    },
    {
      "subject": "epochs",
      "predicate": "hyperparameters",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "I would recommend training a medium model as it's pretty smart and not too hard to train. My product"
    },
    {
      "subject": "batch size",
      "predicate": "hyperparameter",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "This is defined to be four here, and this is the number of times that the model will cycle through t"
    },
    {
      "subject": "batch size",
      "predicate": "instance of",
      "object": "hyperparameter",
      "confidence": 0.9,
      "context": "This is defined to be four here, and this is the number of times that the model will cycle through t"
    },
    {
      "subject": "overfitting",
      "predicate": "gradient",
      "object": "has effect",
      "confidence": 0.9,
      "context": "This is defined to be four here, and this is the number of times that the model will cycle through t"
    },
    {
      "subject": "learning rate",
      "predicate": "hyperparameters",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "I wouldn't recommend changing this unless you know what you're doing since other hyperparameters lik"
    },
    {
      "subject": "learning rate",
      "predicate": "instance of",
      "object": "hyperparameters",
      "confidence": 0.9,
      "context": "I wouldn't recommend changing this unless you know what you're doing since other hyperparameters lik"
    },
    {
      "subject": "learning rate",
      "predicate": "hyperparameter",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "I wouldn't recommend changing this unless you know what you're doing since other hyperparameters lik"
    },
    {
      "subject": "perplexity",
      "predicate": "confused",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "Now let's run this main function.\n\nTraining will take some time. I trained my medium model for 12 ep"
    },
    {
      "subject": "confused",
      "predicate": "model",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "Now let's run this main function.\n\nTraining will take some time. I trained my medium model for 12 ep"
    },
    {
      "subject": "confused",
      "predicate": "confused",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "Now let's run this main function.\n\nTraining will take some time. I trained my medium model for 12 ep"
    },
    {
      "subject": "epoch",
      "predicate": "part of",
      "object": "dataset",
      "confidence": 0.9,
      "context": "If a model has a large perplexity, it means that the model is pretty confused as to which words to c"
    },
    {
      "subject": "perplexity",
      "predicate": "smart",
      "object": "facet of",
      "confidence": 0.9,
      "context": "If a model has a large perplexity, it means that the model is pretty confused as to which words to c"
    },
    {
      "subject": "epochs",
      "predicate": "part of",
      "object": "train",
      "confidence": 0.9,
      "context": "If a model has a large perplexity, it means that the model is pretty confused as to which words to c"
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "chatbot",
      "confidence": 0.9,
      "context": "Let's change the name of the bot.\n\nHello, fellow Red Rider. So let's ask how's it created?\n\nThere is"
    },
    {
      "subject": "pip",
      "predicate": "command-line",
      "object": "use",
      "confidence": 0.9,
      "context": "Now let's change directory just into the content folder because we'll be doing our push there, and w"
    },
    {
      "subject": "pip",
      "predicate": "command-line client",
      "object": "use",
      "confidence": 0.9,
      "context": "Now let's change directory just into the content folder because we'll be doing our push there, and w"
    },
    {
      "subject": "pip",
      "predicate": "command line",
      "object": "use",
      "confidence": 0.9,
      "context": "Now let's change directory just into the content folder because we'll be doing our push there, and w"
    },
    {
      "subject": "Git LFS",
      "predicate": "part of",
      "object": "Git",
      "confidence": 0.9,
      "context": "There is nothing except for the git attributes file, but we will be adding the model files soon.\n\nNo"
    },
    {
      "subject": "Git",
      "predicate": "has part",
      "object": "Git LFS",
      "confidence": 0.9,
      "context": "There is nothing except for the git attributes file, but we will be adding the model files soon.\n\nNo"
    },
    {
      "subject": "Git LFS",
      "predicate": "Git Large File Storage",
      "object": "use",
      "confidence": 0.9,
      "context": "There is nothing except for the git attributes file, but we will be adding the model files soon.\n\nNo"
    },
    {
      "subject": "Git Large File Storage",
      "predicate": "Git LFS",
      "object": "used by",
      "confidence": 0.9,
      "context": "There is nothing except for the git attributes file, but we will be adding the model files soon.\n\nNo"
    },
    {
      "subject": "Git LFS",
      "predicate": "instance of",
      "object": "Git Large File Storage",
      "confidence": 0.9,
      "context": "There is nothing except for the git attributes file, but we will be adding the model files soon.\n\nNo"
    },
    {
      "subject": "dialogue_gpt_small",
      "predicate": "has part",
      "object": "input_small",
      "confidence": 0.9,
      "context": "And we replace this token with the token we just copied from above.\n\nSo here's my username and my to"
    },
    {
      "subject": "output_small",
      "predicate": "has part",
      "object": "output_small",
      "confidence": 0.9,
      "context": "And we replace this token with the token we just copied from above.\n\nSo here's my username and my to"
    },
    {
      "subject": "dialogue_gpt_small",
      "predicate": "part of",
      "object": "input_small",
      "confidence": 0.9,
      "context": "And we replace this token with the token we just copied from above.\n\nSo here's my username and my to"
    },
    {
      "subject": "dialogue_gpt_small",
      "predicate": "part of",
      "object": "output_small",
      "confidence": 0.9,
      "context": "And we replace this token with the token we just copied from above.\n\nSo here's my username and my to"
    },
    {
      "subject": "output_small",
      "predicate": "has part",
      "object": "input_small",
      "confidence": 0.9,
      "context": "And we replace this token with the token we just copied from above.\n\nSo here's my username and my to"
    },
    {
      "subject": "Git LFS",
      "predicate": "Git",
      "object": "used by",
      "confidence": 0.9,
      "context": "We install the Git LFS, and inspect the content of our current directory, which should be dialogue_g"
    },
    {
      "subject": "Git",
      "predicate": "Git LFS",
      "object": "uses",
      "confidence": 0.9,
      "context": "We install the Git LFS, and inspect the content of our current directory, which should be dialogue_g"
    },
    {
      "subject": "Git LFS",
      "predicate": "Git",
      "object": "use",
      "confidence": 0.9,
      "context": "We install the Git LFS, and inspect the content of our current directory, which should be dialogue_g"
    },
    {
      "subject": "PyTorch",
      "predicate": "instance of",
      "object": "chatbot",
      "confidence": 0.9,
      "context": "And we commit with message \"Initial commit.\" And finally, we push the model. It's about 400 megabyte"
    },
    {
      "subject": "PyTorch",
      "predicate": "chatbot",
      "object": "use",
      "confidence": 0.9,
      "context": "And we commit with message \"Initial commit.\" And finally, we push the model. It's about 400 megabyte"
    },
    {
      "subject": "PyTorch",
      "predicate": "text generation",
      "object": "use",
      "confidence": 0.9,
      "context": "And we commit with message \"Initial commit.\" And finally, we push the model. It's about 400 megabyte"
    },
    {
      "subject": "Hugging Face",
      "predicate": "chatbot",
      "object": "use",
      "confidence": 0.9,
      "context": "For that purpose, we need to add a model card.\n\nSo we create a model card here, and we're putting in"
    },
    {
      "subject": "Hugging Face",
      "predicate": "part of",
      "object": "Discord",
      "confidence": 0.9,
      "context": "For that purpose, we need to add a model card.\n\nSo we create a model card here, and we're putting in"
    },
    {
      "subject": "Lynn's Dev Lab",
      "predicate": "part of",
      "object": "Discord",
      "confidence": 0.9,
      "context": "Here, on Discord, I have my server, Lynn's Dev Lab. I have two channels: one for the Python bot and "
    },
    {
      "subject": "ChattyBot Python",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So our name will be ChattyBot Python.\n\nSo here we create a bot, and I'm going to name this Harry Pot"
    },
    {
      "subject": "ChattyBot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So our name will be ChattyBot Python.\n\nSo here we create a bot, and I'm going to name this Harry Pot"
    },
    {
      "subject": "Harry Potter Bot Python",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So our name will be ChattyBot Python.\n\nSo here we create a bot, and I'm going to name this Harry Pot"
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "API tokens",
      "confidence": 0.9,
      "context": "So here is a tab for the secrets for the environment variables. So the first one will be huggingface"
    },
    {
      "subject": "Hugging Face",
      "predicate": "Discord",
      "object": "used by",
      "confidence": 0.9,
      "context": "So here is a tab for the secrets for the environment variables. So the first one will be huggingface"
    },
    {
      "subject": "discord_bot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We add the token here, and our environment variables are all set.\n\nNext, I have the Python file in m"
    },
    {
      "subject": "github",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We add the token here, and our environment variables are all set.\n\nNext, I have the Python file in m"
    },
    {
      "subject": "API endpoint",
      "predicate": "part of",
      "object": "API",
      "confidence": 0.9,
      "context": "And here I have my API URL pointing to my username.\n\nAnd we define a bot as follows. In the on_ready"
    },
    {
      "subject": "Hugging Face",
      "predicate": "API",
      "object": "use",
      "confidence": 0.9,
      "context": "And here I have my API URL pointing to my username.\n\nAnd we define a bot as follows. In the on_ready"
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "API",
      "confidence": 0.9,
      "context": "And here I have my API URL pointing to my username.\n\nAnd we define a bot as follows. In the on_ready"
    },
    {
      "subject": "HTTP POST",
      "predicate": "part of",
      "object": "HTTP",
      "confidence": 0.9,
      "context": "For the authorization part, we put in bearer and the Hugging Face token. Next, we define a query met"
    },
    {
      "subject": "HTTP POST",
      "predicate": "request",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "For the authorization part, we put in bearer and the Hugging Face token. Next, we define a query met"
    },
    {
      "subject": "HTTP POST",
      "predicate": "API endpoint",
      "object": "uses",
      "confidence": 0.9,
      "context": "For the authorization part, we put in bearer and the Hugging Face token. Next, we define a query met"
    },
    {
      "subject": "on_ready",
      "predicate": "instance of",
      "object": "asynchronous function",
      "confidence": 0.9,
      "context": "Next, we define an asynchronous function named on_ready. The next two function definitions are based"
    },
    {
      "subject": "on_ready",
      "predicate": "instance of",
      "object": "API",
      "confidence": 0.9,
      "context": "Next, we define an asynchronous function named on_ready. The next two function definitions are based"
    },
    {
      "subject": "on_ready",
      "predicate": "asynchronous function",
      "object": "use",
      "confidence": 0.9,
      "context": "Next, we define an asynchronous function named on_ready. The next two function definitions are based"
    },
    {
      "subject": "on_message",
      "predicate": "instance of",
      "object": "method",
      "confidence": 0.9,
      "context": "So on_message is a method that will be called each time the bot sees a message in the channel. So gi"
    },
    {
      "subject": "on_message",
      "predicate": "method",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So on_message is a method that will be called each time the bot sees a message in the channel. So gi"
    },
    {
      "subject": "generated_text",
      "predicate": "payload",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So this is an asynchronous call with message.channel.typing. We call self.query using the payload an"
    },
    {
      "subject": "generated_text",
      "predicate": "response",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So this is an asynchronous call with message.channel.typing. We call self.query using the payload an"
    },
    {
      "subject": "generated_text field",
      "predicate": "part of",
      "object": "response",
      "confidence": 0.9,
      "context": "So this is an asynchronous call with message.channel.typing. We call self.query using the payload an"
    },
    {
      "subject": "debug",
      "predicate": "error message",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "We just log out the error message so that we can debug the bot later on.\n\nFinally, we use another as"
    },
    {
      "subject": "debug",
      "predicate": "error message",
      "object": "uses",
      "confidence": 0.9,
      "context": "We just log out the error message so that we can debug the bot later on.\n\nFinally, we use another as"
    },
    {
      "subject": "message.send",
      "predicate": "instance of",
      "object": "asynchronous method",
      "confidence": 0.9,
      "context": "We just log out the error message so that we can debug the bot later on.\n\nFinally, we use another as"
    },
    {
      "subject": "Repl.it",
      "predicate": "OAuth2",
      "object": "uses",
      "confidence": 0.9,
      "context": "Now that our bot should be all set up, let's invite the bot to our channel.\n\nIn the OAuth2 tab, we a"
    },
    {
      "subject": "Repl.it",
      "predicate": "OAuth2",
      "object": "use",
      "confidence": 0.9,
      "context": "Now that our bot should be all set up, let's invite the bot to our channel.\n\nIn the OAuth2 tab, we a"
    },
    {
      "subject": "Repl.it",
      "predicate": "Repl",
      "object": "use",
      "confidence": 0.9,
      "context": "Now that our bot should be all set up, let's invite the bot to our channel.\n\nIn the OAuth2 tab, we a"
    },
    {
      "subject": "Harry Potter Bot Python",
      "predicate": "instance of",
      "object": "bot",
      "confidence": 0.9,
      "context": "Now that our bot has logged in as Harry Potter Bot Python, and this is its unique ID, let's go to th"
    },
    {
      "subject": "Harry Potter Bot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Now that our bot has logged in as Harry Potter Bot Python, and this is its unique ID, let's go to th"
    },
    {
      "subject": "Repl.it",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Nothing happens, although the bot is online. And now this bot should work in this Python bot channel"
    },
    {
      "subject": "Repl",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Nothing happens, although the bot is online. And now this bot should work in this Python bot channel"
    },
    {
      "subject": "Python bot channel",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Nothing happens, although the bot is online. And now this bot should work in this Python bot channel"
    },
    {
      "subject": "ChattyBot",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "If you don't like seeing this exception, you can use a try except block and log out this exception.\n"
    },
    {
      "subject": "ChattyBot JavaScript",
      "predicate": "instance of",
      "object": "bot",
      "confidence": 0.9,
      "context": "If you don't like seeing this exception, you can use a try except block and log out this exception.\n"
    },
    {
      "subject": "ChattyBot",
      "predicate": "instance of",
      "object": "bot",
      "confidence": 0.9,
      "context": "If you don't like seeing this exception, you can use a try except block and log out this exception.\n"
    },
    {
      "subject": "Discord bot",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "The first one is huggingface_token.\n\nCopying my API token from my profile, edit profile, putting her"
    },
    {
      "subject": "huggingface_token",
      "predicate": "instance of",
      "object": "API token",
      "confidence": 0.9,
      "context": "The first one is huggingface_token.\n\nCopying my API token from my profile, edit profile, putting her"
    },
    {
      "subject": "huggingface_token",
      "predicate": "Discord bot",
      "object": "used by",
      "confidence": 0.9,
      "context": "The first one is huggingface_token.\n\nCopying my API token from my profile, edit profile, putting her"
    },
    {
      "subject": "fetch",
      "predicate": "part of",
      "object": "HTTP",
      "confidence": 0.9,
      "context": "So first we import the Discord API for the JavaScript module, and we import fetch for making HTTP re"
    },
    {
      "subject": "Discord",
      "predicate": "instance of",
      "object": "API",
      "confidence": 0.9,
      "context": "So first we import the Discord API for the JavaScript module, and we import fetch for making HTTP re"
    },
    {
      "subject": "HTTP",
      "predicate": "API",
      "object": "uses",
      "confidence": 0.9,
      "context": "So first we import the Discord API for the JavaScript module, and we import fetch for making HTTP re"
    },
    {
      "subject": "on_message",
      "predicate": "instance of",
      "object": "callback",
      "confidence": 0.9,
      "context": "So when the bot is ready and logged in, we print out \"Logged in as\" client.user.tag.\n\nAnd here is an"
    },
    {
      "subject": "on_message",
      "predicate": "callback",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So when the bot is ready and logged in, we print out \"Logged in as\" client.user.tag.\n\nAnd here is an"
    },
    {
      "subject": "Python script",
      "predicate": "callback",
      "object": "uses",
      "confidence": 0.9,
      "context": "So when the bot is ready and logged in, we print out \"Logged in as\" client.user.tag.\n\nAnd here is an"
    },
    {
      "subject": "HTTP POST",
      "predicate": "HTTP",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "And we form the request headers by again using the Hugging Face API key. So we read the Hugging Face"
    },
    {
      "subject": "HTTP POST",
      "predicate": "HTTP",
      "object": "uses",
      "confidence": 0.9,
      "context": "And we form the request headers by again using the Hugging Face API key. So we read the Hugging Face"
    },
    {
      "subject": "error field",
      "predicate": "debugging",
      "object": "use",
      "confidence": 0.9,
      "context": "And we convert the response into JSON format and extract out the generated_text field.\n\nIf there isn"
    },
    {
      "subject": "JSON",
      "predicate": "instance of",
      "object": "format",
      "confidence": 0.9,
      "context": "And we convert the response into JSON format and extract out the generated_text field.\n\nIf there isn"
    },
    {
      "subject": "JSON",
      "predicate": "instance of",
      "object": "formatted",
      "confidence": 0.9,
      "context": "And we convert the response into JSON format and extract out the generated_text field.\n\nIf there isn"
    },
    {
      "subject": "Repl",
      "predicate": "OAuth",
      "object": "uses",
      "confidence": 0.9,
      "context": "Down here, we log in using the Discord token. Now let's invite the bot to our server. So we go to OA"
    },
    {
      "subject": "Repl",
      "predicate": "OAuth",
      "object": "use",
      "confidence": 0.9,
      "context": "Down here, we log in using the Discord token. Now let's invite the bot to our server. So we go to OA"
    },
    {
      "subject": "Repl",
      "predicate": "instance of",
      "object": "server",
      "confidence": 0.9,
      "context": "Down here, we log in using the Discord token. Now let's invite the bot to our server. So we go to OA"
    },
    {
      "subject": "Python bot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "But before we run our Repl, let's make sure that the bot doesn't have access to the general channel,"
    },
    {
      "subject": "node",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So this Python bot shouldn't be able to send messages to this JavaScript channel.\n\nNow we go back to"
    },
    {
      "subject": "npm",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So this Python bot shouldn't be able to send messages to this JavaScript channel.\n\nNow we go back to"
    },
    {
      "subject": "ChattyBot JavaScript 1048",
      "predicate": "ChattyBot",
      "object": "use",
      "confidence": 0.9,
      "context": "So here, we just use the older version and rerun it.\n\nNow that we are logged in as ChattyBot JavaScr"
    },
    {
      "subject": "ChattyBot",
      "predicate": "ChattyBot JavaScript 1048",
      "object": "uses",
      "confidence": 0.9,
      "context": "So here, we just use the older version and rerun it.\n\nNow that we are logged in as ChattyBot JavaScr"
    },
    {
      "subject": "Python bot",
      "predicate": "JavaScript bot",
      "object": "different from",
      "confidence": 0.9,
      "context": "Looks like our bot is responding to us.\n\nAnd because we have set the bot's permissions correctly, th"
    },
    {
      "subject": "JavaScript bot",
      "predicate": "Python bot",
      "object": "different from",
      "confidence": 0.9,
      "context": "Looks like our bot is responding to us.\n\nAnd because we have set the bot's permissions correctly, th"
    },
    {
      "subject": "Uptime Robot",
      "predicate": "web server",
      "object": "use",
      "confidence": 0.9,
      "context": "So in the next part, we're going to look at how to keep the bot running indefinitely in the browser,"
    },
    {
      "subject": "Uptime Robot",
      "predicate": "instance of",
      "object": "web server",
      "confidence": 0.9,
      "context": "So in the next part, we're going to look at how to keep the bot running indefinitely in the browser,"
    },
    {
      "subject": "browser tab",
      "predicate": "part of",
      "object": "browser",
      "confidence": 0.9,
      "context": "So in the next part, we're going to look at how to keep the bot running indefinitely in the browser,"
    },
    {
      "subject": "keep_alive",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So this is for the Python bot, and we create a new file called keep_alive.py.\n\nAnd we add the code f"
    },
    {
      "subject": "Uptime Robot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So this is for the Python bot, and we create a new file called keep_alive.py.\n\nAnd we add the code f"
    },
    {
      "subject": "Uptime Robot",
      "predicate": "instance of",
      "object": "Python bot",
      "confidence": 0.9,
      "context": "So here is the Uptime Robot website, and I already have an account, so I'll just go to my dashboard "
    },
    {
      "subject": "Python script",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "I'm going to close this tab containing my Python script.\n\nAnd it looks like our model is still up."
    },
    {
      "subject": "Python script",
      "predicate": "model",
      "object": "use",
      "confidence": 0.9,
      "context": "I'm going to close this tab containing my Python script.\n\nAnd it looks like our model is still up."
    },
    {
      "subject": "Python",
      "predicate": "model",
      "object": "use",
      "confidence": 0.9,
      "context": "I'm going to close this tab containing my Python script.\n\nAnd it looks like our model is still up."
    },
    {
      "subject": "Hugging Face",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "It's just that after some time, the model on Hugging Face backend will reload, but because the bot i"
    },
    {
      "subject": "keep_alive",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "It's just that after some time, the model on Hugging Face backend will reload, but because the bot i"
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "JavaScript bot",
      "confidence": 0.9,
      "context": "It's just that after some time, the model on Hugging Face backend will reload, but because the bot i"
    },
    {
      "subject": "Discord JS bot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We copy this URL, go to Uptime Robot, and add a new monitor. It's again an HTTP monitor, Discord JS "
    },
    {
      "subject": "chatbot",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We copy this URL, go to Uptime Robot, and add a new monitor. It's again an HTTP monitor, Discord JS "
    }
  ],
  "knowledge_graph": {
    "nodes": [
      {
        "id": "Harry Potter",
        "type": "PERSON",
        "confidence": 1.0
      },
      {
        "id": "Transcript Wiki",
        "type": "ORGANIZATION",
        "confidence": 1.0
      },
      {
        "id": "Google Colab",
        "type": "ORGANIZATION",
        "confidence": 1.0
      },
      {
        "id": "Hugging Face",
        "type": "ORGANIZATION",
        "confidence": 1.0
      },
      {
        "id": "Uptime Robot",
        "type": "SOFTWARE",
        "confidence": 1.0
      },
      {
        "id": "Discord",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Python",
        "type": "programming_language",
        "confidence": 0.9
      },
      {
        "id": "Kaggle",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Google",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Peppa Pig",
        "type": "CHARACTER",
        "confidence": 0.9
      },
      {
        "id": "Transformer",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Git",
        "type": "PERSON",
        "confidence": 0.9
      },
      {
        "id": "JavaScript",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "ChattyBot Python",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Harry Potter Bot Python",
        "type": "PERSON",
        "confidence": 0.9
      },
      {
        "id": "Repl",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "ChattyBot",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "the Discord",
        "type": "ORGANIZATION",
        "confidence": 0.8999999999999999
      },
      {
        "id": "Besides Transcript Wiki",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Google Drive",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Generative Pre-trained",
        "type": "PERSON",
        "confidence": 0.85
      },
      {
        "id": "Git Large File Storage",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Python Repl",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Discord Python",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Wanna",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "Rick",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "Morty",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "Lynn",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "Pandas",
        "type": "ORGANIZATION",
        "confidence": 0.8
      },
      {
        "id": "Account",
        "type": "ORGANIZATION",
        "confidence": 0.8
      },
      {
        "id": "Red Rider",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "PyTorch",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "the University of Chicago",
        "type": "ORGANIZATION",
        "confidence": 0.7999999999999999
      },
      {
        "id": "Batman on Transcript Wiki",
        "type": "PRODUCT",
        "confidence": 0.7999999999999999
      },
      {
        "id": "The Word Ends With You",
        "type": "PRODUCT",
        "confidence": 0.7999999999999999
      },
      {
        "id": "parse_script.ipynb",
        "type": "FILE",
        "confidence": 0.7999999999999999
      },
      {
        "id": "model_train_upload_workflow.ipynb",
        "type": "FILE",
        "confidence": 0.7999999999999999
      },
      {
        "id": "discord_bot.js",
        "type": "FILE",
        "confidence": 0.7999999999999999
      },
      {
        "id": "keep_alive.py",
        "type": "FILE",
        "confidence": 0.7999999999999999
      },
      {
        "id": "George",
        "type": "CHARACTER",
        "confidence": 0.75
      },
      {
        "id": "Microsoft",
        "type": "ORGANIZATION",
        "confidence": 0.75
      },
      {
        "id": "Dev Lab",
        "type": "PERSON",
        "confidence": 0.75
      },
      {
        "id": "UTF-8",
        "type": "TECHNOLOGY",
        "confidence": 0.75
      },
      {
        "id": "node",
        "type": "TECHNOLOGY",
        "confidence": 0.75
      },
      {
        "id": "npm",
        "type": "TECHNOLOGY",
        "confidence": 0.75
      },
      {
        "id": "message.content",
        "type": "VARIABLE",
        "confidence": 0.7499999999999999
      },
      {
        "id": "Rick and Morty",
        "type": "movie",
        "confidence": 0.8185796737670898
      },
      {
        "id": "University of Chicago",
        "type": "ORGANIZATION",
        "confidence": 0.71872478723526
      },
      {
        "id": "Discord bot",
        "type": "software",
        "confidence": 0.95
      },
      {
        "id": "bot",
        "type": "SOFTWARE",
        "confidence": 0.7174870371818542
      },
      {
        "id": "favorite character",
        "type": "character",
        "confidence": 0.95
      },
      {
        "id": "model",
        "type": "model",
        "confidence": 0.9518399238586426
      },
      {
        "id": "character",
        "type": "character",
        "confidence": 0.8723450899124146
      },
      {
        "id": "chatbot",
        "type": "api",
        "confidence": 0.95
      },
      {
        "id": "video games",
        "type": "game",
        "confidence": 0.95
      },
      {
        "id": "game",
        "type": "game",
        "confidence": 0.95
      },
      {
        "id": "drive",
        "type": "TECHNOLOGY",
        "confidence": 0.936665415763855
      },
      {
        "id": "regular expression",
        "type": "TECHNOLOGY",
        "confidence": 0.7677367329597473
      },
      {
        "id": "Mama Pig",
        "type": "CHARACTER",
        "confidence": 0.9159917831420898
      },
      {
        "id": "peppapig",
        "type": "CHARACTER",
        "confidence": 0.9130569696426392
      },
      {
        "id": "GPT model",
        "type": "MODEL",
        "confidence": 0.7945997714996338
      },
      {
        "id": "Generative Pre-trained Transformer",
        "type": "MODEL",
        "confidence": 0.7191442251205444
      },
      {
        "id": "we",
        "type": "character",
        "confidence": 0.827878475189209
      },
      {
        "id": "our character",
        "type": "character",
        "confidence": 0.9631742238998413
      },
      {
        "id": "dataset",
        "type": "DATASET",
        "confidence": 0.7076377272605896
      },
      {
        "id": "username",
        "type": "PERSON",
        "confidence": 0.780322790145874
      },
      {
        "id": "get",
        "type": "OPERATION",
        "confidence": 0.7015755772590637
      },
      {
        "id": "add",
        "type": "OPERATION",
        "confidence": 0.7094175219535828
      },
      {
        "id": "user",
        "type": "person",
        "confidence": 0.95
      },
      {
        "id": "API",
        "type": "API",
        "confidence": 0.78188157081604
      },
      {
        "id": "Hugging Face model",
        "type": "MODEL",
        "confidence": 0.8229730725288391
      },
      {
        "id": "HTTP",
        "type": "PROTOCOL",
        "confidence": 0.8089977502822876
      },
      {
        "id": "Hugging Face API",
        "type": "API",
        "confidence": 0.916340708732605
      },
      {
        "id": "Discord API",
        "type": "API",
        "confidence": 0.9315881729125977
      },
      {
        "id": "general channel",
        "type": "channel",
        "confidence": 0.9596195220947266
      },
      {
        "id": "client",
        "type": "SOFTWARE",
        "confidence": 0.7063944935798645
      },
      {
        "id": "HTTP POST",
        "type": "PROTOCOL",
        "confidence": 0.8175955414772034
      },
      {
        "id": "Python channel",
        "type": "channel",
        "confidence": 0.9560022354125977
      },
      {
        "id": "JS channel",
        "type": "channel",
        "confidence": 0.8953447937965393
      },
      {
        "id": "JavaScript channel",
        "type": "channel",
        "confidence": 0.8593723177909851
      },
      {
        "id": "Discord channel",
        "type": "channel",
        "confidence": 0.854985237121582
      },
      {
        "id": "web server",
        "type": "SOFTWARE",
        "confidence": 0.7951722741127014
      },
      {
        "id": "HTTPS",
        "type": "PROTOCOL",
        "confidence": 0.9048122763633728
      },
      {
        "id": "Discord JS bot",
        "type": "SOFTWARE",
        "confidence": 0.8863077759742737
      },
      {
        "id": "use",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "artificial intelligence",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "uses",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "subclass of",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "AI chatbot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "video game",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "train the model",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "model training and deployment pipeline",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "deployment",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "lines of dialogue",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "characters",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "notable work",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "cartoon",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "genre",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Batman",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "fandom website",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "search engine",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "two-column",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "character line",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "text messages",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "used by",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "search",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "text file",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "operating system",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "CSV",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "sibling",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "mother",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "child",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "result data frame",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "data frame",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "parametric",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "model training",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Transformers",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "modules",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "harry_potter_1",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "main subject",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "semicolon",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "different from",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "comma",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "separation",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "3772",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "followed by",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "3773",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "follows",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "3771",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Harry",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "conversational chatbot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "conversational",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "context data frame",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "training set",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "test set",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "GPT small",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "developer",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "small",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "training",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "num_train_epochs",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "hyperparameters",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "hyperparameter",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "epochs",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "batch size",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "overfitting",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "has effect",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "learning rate",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "perplexity",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "confused",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "epoch",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "facet of",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "train",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "pip",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Git LFS",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "dialogue_gpt_small",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "input_small",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "output_small",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Lynn's Dev Lab",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "programming language",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "API tokens",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "discord_bot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "github",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "API endpoint",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "on_ready",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "asynchronous function",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "on_message",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "method",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "generated_text",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "generated_text field",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "response",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "debug",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "message.send",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "asynchronous method",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Repl.it",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Harry Potter Bot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Python bot channel",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "ChattyBot JavaScript",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "huggingface_token",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "API token",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "fetch",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "callback",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Python script",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "error field",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "JSON",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "format",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "formatted",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "server",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Python bot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "ChattyBot JavaScript 1048",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "JavaScript bot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "browser tab",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "browser",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "keep_alive",
        "type": "unknown",
        "confidence": 0.9
      }
    ],
    "edges": [
      {
        "source": "Google Colab",
        "target": "Google Drive",
        "predicate": "is part of",
        "confidence": 0.9
      },
      {
        "source": "Google Colab",
        "target": "operating system",
        "predicate": "runs on",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "use",
        "predicate": "API",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "Discord",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "API tokens",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "used by",
        "predicate": "Discord",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "API",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "JavaScript bot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Uptime Robot",
        "target": "use",
        "predicate": "web server",
        "confidence": 0.9
      },
      {
        "source": "Uptime Robot",
        "target": "web server",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Uptime Robot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Uptime Robot",
        "target": "Python bot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "chatbot",
        "predicate": "is a",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "AI chatbot",
        "predicate": "is a",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "video game",
        "predicate": "is a",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "Python",
        "predicate": "uses",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "API",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Python",
        "target": "JavaScript",
        "predicate": "is influenced by",
        "confidence": 0.9
      },
      {
        "source": "Python",
        "target": "use",
        "predicate": "model",
        "confidence": 0.9
      },
      {
        "source": "Kaggle",
        "target": "dataset",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Google",
        "target": "search engine",
        "predicate": "is a",
        "confidence": 0.9
      },
      {
        "source": "Google",
        "target": "search",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "dataset",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "cartoon",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "genre",
        "predicate": "cartoon",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "Mama Pig",
        "predicate": "is related to",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "sibling",
        "predicate": "George",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "mother",
        "predicate": "Mama Pig",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "Peppa Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "Git",
        "target": "Git LFS",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Git",
        "target": "uses",
        "predicate": "Git LFS",
        "confidence": 0.9
      },
      {
        "source": "JavaScript",
        "target": "Python",
        "predicate": "influenced by",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot Python",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter Bot Python",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter Bot Python",
        "target": "bot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Repl",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Repl",
        "target": "uses",
        "predicate": "OAuth",
        "confidence": 0.9
      },
      {
        "source": "Repl",
        "target": "use",
        "predicate": "OAuth",
        "confidence": 0.9
      },
      {
        "source": "Repl",
        "target": "server",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot",
        "target": "bot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot",
        "target": "uses",
        "predicate": "ChattyBot JavaScript 1048",
        "confidence": 0.9
      },
      {
        "source": "Google Drive",
        "target": "Google Colab",
        "predicate": "contains",
        "confidence": 0.9
      },
      {
        "source": "Google Drive",
        "target": "operating system",
        "predicate": "runs on",
        "confidence": 0.9
      },
      {
        "source": "Google Drive",
        "target": "Transformers",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Git Large File Storage",
        "target": "used by",
        "predicate": "Git LFS",
        "confidence": 0.9
      },
      {
        "source": "Pandas",
        "target": "CSV",
        "predicate": "uses",
        "confidence": 0.9
      },
      {
        "source": "Pandas",
        "target": "use",
        "predicate": "CSV",
        "confidence": 0.9
      },
      {
        "source": "PyTorch",
        "target": "chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "PyTorch",
        "target": "use",
        "predicate": "text generation",
        "confidence": 0.9
      },
      {
        "source": "The Word Ends With You",
        "target": "game",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "The Word Ends With You",
        "target": "fandom website",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "George",
        "target": "Mama Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "George",
        "target": "Peppa Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "node",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "npm",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "Rick and Morty",
        "target": "lines of dialogue",
        "predicate": "contains",
        "confidence": 0.9
      },
      {
        "source": "Rick and Morty",
        "target": "characters",
        "predicate": "features",
        "confidence": 0.9
      },
      {
        "source": "Rick and Morty",
        "target": "notable work",
        "predicate": "is a",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "use",
        "predicate": "video games",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "artificial intelligence",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "uses",
        "predicate": "artificial intelligence",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "model",
        "target": "dataset",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "chatbot",
        "target": "subclass of",
        "predicate": "AI",
        "confidence": 0.9
      },
      {
        "source": "chatbot",
        "target": "uses",
        "predicate": "dialogues",
        "confidence": 0.9
      },
      {
        "source": "chatbot",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "Peppa Pig",
        "predicate": "is featured in",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "sibling",
        "predicate": "Peppa Pig",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "child",
        "predicate": "Peppa Pig",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "George",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "Mama Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "peppapig",
        "target": "CSV",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "dataset",
        "target": "model",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "dataset",
        "target": "text file",
        "predicate": "is a type of",
        "confidence": 0.9
      },
      {
        "source": "HTTP",
        "target": "uses",
        "predicate": "API",
        "confidence": 0.9
      },
      {
        "source": "HTTP POST",
        "target": "HTTP",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "HTTP POST",
        "target": "subclass of",
        "predicate": "HTTP",
        "confidence": 0.9
      },
      {
        "source": "HTTP POST",
        "target": "uses",
        "predicate": "HTTP",
        "confidence": 0.9
      },
      {
        "source": "Discord JS bot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "train the model",
        "target": "model training and deployment pipeline",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "train the model",
        "target": "deployment",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "train the model",
        "target": "use",
        "predicate": "model training",
        "confidence": 0.9
      },
      {
        "source": "model training and deployment pipeline",
        "target": "train the model",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "lines of dialogue",
        "target": "Rick and Morty",
        "predicate": "are present in",
        "confidence": 0.9
      },
      {
        "source": "Batman",
        "target": "video game",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "two-column",
        "target": "character line",
        "predicate": "is a",
        "confidence": 0.9
      },
      {
        "source": "text messages",
        "target": "used by",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "CSV",
        "target": "Pandas",
        "predicate": "is used by",
        "confidence": 0.9
      },
      {
        "source": "sibling",
        "target": "sibling",
        "predicate": "George",
        "confidence": 0.9
      },
      {
        "source": "sibling",
        "target": "Peppa Pig",
        "predicate": "Mama Pig",
        "confidence": 0.9
      },
      {
        "source": "result data frame",
        "target": "subclass of",
        "predicate": "data frame",
        "confidence": 0.9
      },
      {
        "source": "result data frame",
        "target": "data frame",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "parametric",
        "target": "subclass of",
        "predicate": "regular expression",
        "confidence": 0.9
      },
      {
        "source": "model training",
        "target": "subclass of",
        "predicate": "train the model",
        "confidence": 0.9
      },
      {
        "source": "Transformers",
        "target": "modules",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Transformers",
        "target": "Google Drive",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "harry_potter_1",
        "target": "dataset",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "harry_potter_1",
        "target": "main subject",
        "predicate": "Harry Potter",
        "confidence": 0.9
      },
      {
        "source": "harry_potter_1",
        "target": "CSV",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "semicolon",
        "target": "different from",
        "predicate": "comma",
        "confidence": 0.9
      },
      {
        "source": "semicolon",
        "target": "separation",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "comma",
        "target": "different from",
        "predicate": "separation",
        "confidence": 0.9
      },
      {
        "source": "separation",
        "target": "different from",
        "predicate": "comma",
        "confidence": 0.9
      },
      {
        "source": "separation",
        "target": "semicolon",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "3772",
        "target": "followed by",
        "predicate": "3771",
        "confidence": 0.9
      },
      {
        "source": "3773",
        "target": "follows",
        "predicate": "3772",
        "confidence": 0.9
      },
      {
        "source": "3771",
        "target": "follows",
        "predicate": "3772",
        "confidence": 0.9
      },
      {
        "source": "Harry",
        "target": "conversational chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "conversational",
        "target": "subclass of",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "context data frame",
        "target": "use",
        "predicate": "conversational chatbot",
        "confidence": 0.9
      },
      {
        "source": "training set",
        "target": "subclass of",
        "predicate": "dataset",
        "confidence": 0.9
      },
      {
        "source": "test set",
        "target": "subclass of",
        "predicate": "dataset",
        "confidence": 0.9
      },
      {
        "source": "GPT small",
        "target": "developer",
        "predicate": "Microsoft",
        "confidence": 0.9
      },
      {
        "source": "small",
        "target": "subclass of",
        "predicate": "parameters",
        "confidence": 0.9
      },
      {
        "source": "training",
        "target": "followed by",
        "predicate": "test set",
        "confidence": 0.9
      },
      {
        "source": "num_train_epochs",
        "target": "hyperparameters",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "num_train_epochs",
        "target": "hyperparameter",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "epochs",
        "target": "subclass of",
        "predicate": "hyperparameters",
        "confidence": 0.9
      },
      {
        "source": "epochs",
        "target": "train",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "batch size",
        "target": "subclass of",
        "predicate": "hyperparameter",
        "confidence": 0.9
      },
      {
        "source": "batch size",
        "target": "hyperparameter",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "overfitting",
        "target": "has effect",
        "predicate": "gradient",
        "confidence": 0.9
      },
      {
        "source": "learning rate",
        "target": "subclass of",
        "predicate": "hyperparameter",
        "confidence": 0.9
      },
      {
        "source": "learning rate",
        "target": "hyperparameters",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "perplexity",
        "target": "subclass of",
        "predicate": "confused",
        "confidence": 0.9
      },
      {
        "source": "perplexity",
        "target": "facet of",
        "predicate": "smart",
        "confidence": 0.9
      },
      {
        "source": "confused",
        "target": "subclass of",
        "predicate": "confused",
        "confidence": 0.9
      },
      {
        "source": "epoch",
        "target": "dataset",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "pip",
        "target": "use",
        "predicate": "command line",
        "confidence": 0.9
      },
      {
        "source": "Git LFS",
        "target": "Git",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Git LFS",
        "target": "use",
        "predicate": "Git",
        "confidence": 0.9
      },
      {
        "source": "Git LFS",
        "target": "Git Large File Storage",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Git LFS",
        "target": "used by",
        "predicate": "Git",
        "confidence": 0.9
      },
      {
        "source": "dialogue_gpt_small",
        "target": "input_small",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "dialogue_gpt_small",
        "target": "output_small",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "output_small",
        "target": "output_small",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "output_small",
        "target": "input_small",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Lynn's Dev Lab",
        "target": "Discord",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "discord_bot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "github",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "API endpoint",
        "target": "API",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "on_ready",
        "target": "asynchronous function",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "on_ready",
        "target": "API",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "on_ready",
        "target": "use",
        "predicate": "asynchronous function",
        "confidence": 0.9
      },
      {
        "source": "on_message",
        "target": "method",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "on_message",
        "target": "subclass of",
        "predicate": "callback",
        "confidence": 0.9
      },
      {
        "source": "on_message",
        "target": "callback",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "generated_text",
        "target": "subclass of",
        "predicate": "response",
        "confidence": 0.9
      },
      {
        "source": "generated_text field",
        "target": "response",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "debug",
        "target": "subclass of",
        "predicate": "error message",
        "confidence": 0.9
      },
      {
        "source": "debug",
        "target": "uses",
        "predicate": "error message",
        "confidence": 0.9
      },
      {
        "source": "message.send",
        "target": "asynchronous method",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Repl.it",
        "target": "uses",
        "predicate": "OAuth2",
        "confidence": 0.9
      },
      {
        "source": "Repl.it",
        "target": "use",
        "predicate": "Repl",
        "confidence": 0.9
      },
      {
        "source": "Repl.it",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter Bot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Python bot channel",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot JavaScript",
        "target": "bot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "huggingface_token",
        "target": "API token",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "huggingface_token",
        "target": "used by",
        "predicate": "Discord bot",
        "confidence": 0.9
      },
      {
        "source": "fetch",
        "target": "HTTP",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Python script",
        "target": "uses",
        "predicate": "callback",
        "confidence": 0.9
      },
      {
        "source": "Python script",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Python script",
        "target": "use",
        "predicate": "model",
        "confidence": 0.9
      },
      {
        "source": "error field",
        "target": "use",
        "predicate": "debugging",
        "confidence": 0.9
      },
      {
        "source": "JSON",
        "target": "format",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "JSON",
        "target": "formatted",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Python bot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Python bot",
        "target": "different from",
        "predicate": "JavaScript bot",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot JavaScript 1048",
        "target": "use",
        "predicate": "ChattyBot",
        "confidence": 0.9
      },
      {
        "source": "JavaScript bot",
        "target": "different from",
        "predicate": "Python bot",
        "confidence": 0.9
      },
      {
        "source": "browser tab",
        "target": "browser",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "keep_alive",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      }
    ],
    "node_count": 193,
    "edge_count": 176,
    "cleaned": true
  },
  "key_facts": [
    {
      "fact": "Discord bot artificial intelligence use",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "use",
      "type": "relationship"
    },
    {
      "fact": "Goal: Create a Discord bot that speaks like a chosen character (e.g., Rick and Morty, Harry Potter).",
      "confidence": 0.9,
      "timestamp": 7,
      "type": "key_point"
    },
    {
      "fact": "Harry Potter has spacy_label: PERSON",
      "confidence": 1.0,
      "subject": "Harry Potter",
      "type": "entity_property"
    },
    {
      "fact": "Discord bot instance of artificial intelligence",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "instance of",
      "object": "artificial intelligence",
      "type": "relationship"
    },
    {
      "fact": "Introduction: Lynn, a software engineer, hobbyist game developer, and recent University of Chicago graduate, will guide the tutorial.",
      "confidence": 0.9,
      "timestamp": 26,
      "type": "key_point"
    },
    {
      "fact": "Harry Potter has start_char: 75",
      "confidence": 1.0,
      "subject": "Harry Potter",
      "type": "entity_property"
    },
    {
      "fact": "Discord bot artificial intelligence uses",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Tutorial Goal: Build a Discord AI chatbot that speaks like your favorite character.",
      "confidence": 0.9,
      "timestamp": 46,
      "type": "key_point"
    },
    {
      "fact": "Harry Potter has end_char: 87",
      "confidence": 1.0,
      "subject": "Harry Potter",
      "type": "entity_property"
    },
    {
      "fact": "chatbot AI subclass of",
      "confidence": 0.9,
      "subject": "chatbot",
      "predicate": "AI",
      "object": "subclass of",
      "type": "relationship"
    },
    {
      "fact": "Note: This tutorial is more comprehensive than a previous one.",
      "confidence": 0.9,
      "timestamp": 58,
      "type": "key_point"
    },
    {
      "fact": "Transcript Wiki has spacy_label: PERSON",
      "confidence": 1.0,
      "subject": "Transcript Wiki",
      "type": "entity_property"
    },
    {
      "fact": "Discord instance of chatbot",
      "confidence": 0.9,
      "subject": "Discord",
      "predicate": "instance of",
      "object": "chatbot",
      "type": "relationship"
    },
    {
      "fact": "Origin Story: The project started as a joke during video games with friends and unexpectedly gained popularity.",
      "confidence": 0.9,
      "timestamp": 76,
      "type": "key_point"
    },
    {
      "fact": "Transcript Wiki has start_char: 1678",
      "confidence": 1.0,
      "subject": "Transcript Wiki",
      "type": "entity_property"
    },
    {
      "fact": "Discord instance of AI chatbot",
      "confidence": 0.9,
      "subject": "Discord",
      "predicate": "instance of",
      "object": "AI chatbot",
      "type": "relationship"
    },
    {
      "fact": "Tutorial Update: The tutorial is updated to include more characters and data acquisition methods.",
      "confidence": 0.9,
      "timestamp": 111,
      "type": "key_point"
    },
    {
      "fact": "Transcript Wiki has end_char: 1693",
      "confidence": 1.0,
      "subject": "Transcript Wiki",
      "type": "entity_property"
    },
    {
      "fact": "Discord bot video game use",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "video game",
      "object": "use",
      "type": "relationship"
    },
    {
      "fact": "Topics Covered: Model training, deployment, common errors and solutions, Python and JavaScript bot building, bot deployment to Discord servers, and channel restriction.",
      "confidence": 0.9,
      "timestamp": 128,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has spacy_label: ORG",
      "confidence": 1.0,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Discord bot video games use",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "video games",
      "object": "use",
      "type": "relationship"
    },
    {
      "fact": "Data Acquisition: Preferred sources are Kaggle, Transcript Wiki, and fandom websites found via Google Search.",
      "confidence": 0.9,
      "timestamp": 161,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has start_char: 4524",
      "confidence": 1.0,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Discord instance of video game",
      "confidence": 0.9,
      "subject": "Discord",
      "predicate": "instance of",
      "object": "video game",
      "type": "relationship"
    },
    {
      "fact": "Kaggle Data: Searching for \"Rick and Morty\" yields a dataset with character names and lines.",
      "confidence": 0.9,
      "timestamp": 186,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has end_char: 4536",
      "confidence": 1.0,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "train the model part of model training and deployment pipeline",
      "confidence": 0.9,
      "subject": "train the model",
      "predicate": "part of",
      "object": "model training and deployment pipeline",
      "type": "relationship"
    },
    {
      "fact": "Kaggle Data:  Searching for \"Harry Potter\" also provides a dataset with character names and lines.",
      "confidence": 0.9,
      "timestamp": 215,
      "type": "key_point"
    },
    {
      "fact": "Hugging Face has spacy_label: ORG",
      "confidence": 1.0,
      "subject": "Hugging Face",
      "type": "entity_property"
    },
    {
      "fact": "model training and deployment pipeline has part train the model",
      "confidence": 0.9,
      "subject": "model training and deployment pipeline",
      "predicate": "has part",
      "object": "train the model",
      "type": "relationship"
    },
    {
      "fact": "Dataset Requirements: Only character name and spoken line columns are needed for the chatbot.",
      "confidence": 0.9,
      "timestamp": 235,
      "type": "key_point"
    },
    {
      "fact": "Hugging Face has start_char: 12866",
      "confidence": 1.0,
      "subject": "Hugging Face",
      "type": "entity_property"
    },
    {
      "fact": "train the model part of deployment",
      "confidence": 0.9,
      "subject": "train the model",
      "predicate": "part of",
      "object": "deployment",
      "type": "relationship"
    },
    {
      "fact": "Alternative Data Sources: If Kaggle lacks data for a character, use raw transcripts from sources like Transcript Wiki or via targeted Google searches (e.g., \"[media name] transcript\").",
      "confidence": 0.9,
      "timestamp": 251,
      "type": "key_point"
    },
    {
      "fact": "Hugging Face has end_char: 12878",
      "confidence": 1.0,
      "subject": "Hugging Face",
      "type": "entity_property"
    },
    {
      "fact": "deploy has part train the model",
      "confidence": 0.9,
      "subject": "deploy",
      "predicate": "has part",
      "object": "train the model",
      "type": "relationship"
    },
    {
      "fact": "Transcript Wiki Example:  Shows how to find transcripts for various media (movies, shows, games, etc.).",
      "confidence": 0.9,
      "timestamp": 291,
      "type": "key_point"
    },
    {
      "fact": "Uptime Robot has spacy_label: ORG",
      "confidence": 1.0,
      "subject": "Uptime Robot",
      "type": "entity_property"
    },
    {
      "fact": "Python influenced by JavaScript",
      "confidence": 0.9,
      "subject": "Python",
      "predicate": "influenced by",
      "object": "JavaScript",
      "type": "relationship"
    },
    {
      "fact": "Transcript Wiki Example: Found transcripts for Peppa Pig and Batman.",
      "confidence": 0.9,
      "timestamp": 319,
      "type": "key_point"
    },
    {
      "fact": "Uptime Robot has start_char: 26420",
      "confidence": 1.0,
      "subject": "Uptime Robot",
      "type": "entity_property"
    },
    {
      "fact": "JavaScript influenced by Python",
      "confidence": 0.9,
      "subject": "JavaScript",
      "predicate": "influenced by",
      "object": "Python",
      "type": "relationship"
    },
    {
      "fact": "Transcript Format: Shows an example transcript with character names and lines/actions.",
      "confidence": 0.9,
      "timestamp": 334,
      "type": "key_point"
    },
    {
      "fact": "Uptime Robot has end_char: 26432",
      "confidence": 1.0,
      "subject": "Uptime Robot",
      "type": "entity_property"
    },
    {
      "fact": "Discord Python programming language",
      "confidence": 0.9,
      "subject": "Discord",
      "predicate": "Python",
      "object": "programming language",
      "type": "relationship"
    },
    {
      "fact": "Converting Raw Transcripts: The tutorial will demonstrate how to convert a raw transcript into a Kaggle-like dataset.",
      "confidence": 0.9,
      "timestamp": 359,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has spacy_label: FAC",
      "confidence": 0.95,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Rick and Morty has part line they're speaking",
      "confidence": 0.9,
      "subject": "Rick and Morty",
      "predicate": "has part",
      "object": "line they're speaking",
      "type": "relationship"
    },
    {
      "fact": "Google Search for Transcripts: If no transcript is available on Transcript Wiki, search Google using \"[Media Name] Transcript\".",
      "confidence": 0.9,
      "timestamp": 377,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has start_char: 4339",
      "confidence": 0.95,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "line they're speaking part of Rick and Morty",
      "confidence": 0.9,
      "subject": "line they're speaking",
      "predicate": "part of",
      "object": "Rick and Morty",
      "type": "relationship"
    },
    {
      "fact": "Example: The instructor's first bot used data from a game with no Kaggle or Transcript Wiki data; a Google search found a fandom website containing the full game transcript.",
      "confidence": 0.9,
      "timestamp": 399,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has end_char: 4351",
      "confidence": 0.95,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Rick and Morty line they're speaking characters",
      "confidence": 0.9,
      "subject": "Rick and Morty",
      "predicate": "line they're speaking",
      "object": "characters",
      "type": "relationship"
    },
    {
      "fact": "Real-life Character Data: For real-life figures, search for interview scripts.",
      "confidence": 0.9,
      "timestamp": 423,
      "type": "key_point"
    },
    {
      "fact": "Discord has spacy_label: ORG",
      "confidence": 0.9,
      "subject": "Discord",
      "type": "entity_property"
    },
    {
      "fact": "line they're speaking Rick and Morty present in work",
      "confidence": 0.9,
      "subject": "line they're speaking",
      "predicate": "Rick and Morty",
      "object": "present in work",
      "type": "relationship"
    },
    {
      "fact": "Personal Data: To create a chatbot that speaks like yourself or a friend, use text messages as dialogue data.",
      "confidence": 0.9,
      "timestamp": 441,
      "type": "key_point"
    },
    {
      "fact": "Discord has start_char: 13",
      "confidence": 0.9,
      "subject": "Discord",
      "type": "entity_property"
    },
    {
      "fact": "Rick and Morty line they're speaking notable work",
      "confidence": 0.9,
      "subject": "Rick and Morty",
      "predicate": "line they're speaking",
      "object": "notable work",
      "type": "relationship"
    },
    {
      "fact": "Data Acquisition Summary: Be creative in finding data for your chosen character.",
      "confidence": 0.9,
      "timestamp": 459,
      "type": "key_point"
    },
    {
      "fact": "Discord has end_char: 20",
      "confidence": 0.9,
      "subject": "Discord",
      "type": "entity_property"
    },
    {
      "fact": "Peppa Pig instance of dataset",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "predicate": "instance of",
      "object": "dataset",
      "type": "relationship"
    },
    {
      "fact": "Converting Raw Transcripts to Datasets:  Steps to process raw transcripts using Google Colab.",
      "confidence": 0.9,
      "timestamp": 472,
      "type": "key_point"
    },
    {
      "fact": "Python has spacy_label: GPE",
      "confidence": 0.9,
      "subject": "Python",
      "type": "entity_property"
    },
    {
      "fact": "dataset part of model",
      "confidence": 0.9,
      "subject": "dataset",
      "predicate": "part of",
      "object": "model",
      "type": "relationship"
    },
    {
      "fact": "Process: Upload transcript text file to Google Drive.",
      "confidence": 0.9,
      "timestamp": 486,
      "type": "key_point"
    },
    {
      "fact": "Python has start_char: 1340",
      "confidence": 0.9,
      "subject": "Python",
      "type": "entity_property"
    },
    {
      "fact": "model has part dataset",
      "confidence": 0.9,
      "subject": "model",
      "predicate": "has part",
      "object": "dataset",
      "type": "relationship"
    },
    {
      "fact": "Process: Create a Google Colab notebook.",
      "confidence": 0.9,
      "timestamp": 502,
      "type": "key_point"
    },
    {
      "fact": "Python has end_char: 1346",
      "confidence": 0.9,
      "subject": "Python",
      "type": "entity_property"
    },
    {
      "fact": "Peppa Pig instance of cartoon",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "predicate": "instance of",
      "object": "cartoon",
      "type": "relationship"
    },
    {
      "fact": "Process:  Use the notebook to parse the transcript.",
      "confidence": 0.9,
      "timestamp": 516,
      "type": "key_point"
    },
    {
      "fact": "Kaggle has spacy_label: PERSON",
      "confidence": 0.9,
      "subject": "Kaggle",
      "type": "entity_property"
    },
    {
      "fact": "Peppa Pig cartoon genre",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "predicate": "cartoon",
      "object": "genre",
      "type": "relationship"
    },
    {
      "fact": "Process: Use regular expressions to parse the transcript and create a two-column (character, line) dataset.",
      "confidence": 0.9,
      "timestamp": 530,
      "type": "key_point"
    },
    {
      "fact": "Kaggle has start_char: 1670",
      "confidence": 0.9,
      "subject": "Kaggle",
      "type": "entity_property"
    },
    {
      "fact": "Batman instance of video game",
      "confidence": 0.9,
      "subject": "Batman",
      "predicate": "instance of",
      "object": "video game",
      "type": "relationship"
    },
    {
      "fact": "Regular Expression Pattern Explanation:  The provided regular expression pattern extracts the character name and spoken line.",
      "confidence": 0.9,
      "timestamp": 651,
      "type": "key_point"
    },
    {
      "fact": "Kaggle has end_char: 1676",
      "confidence": 0.9,
      "subject": "Kaggle",
      "type": "entity_property"
    },
    {
      "fact": "The Word Ends With You instance of game",
      "confidence": 0.9,
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "game",
      "type": "relationship"
    },
    {
      "fact": "Regular Expression Output: Two match capture groups are identified: character's name and spoken line.",
      "confidence": 0.9,
      "timestamp": 704,
      "type": "key_point"
    },
    {
      "fact": "Google has spacy_label: ORG",
      "confidence": 0.9,
      "subject": "Google",
      "type": "entity_property"
    },
    {
      "fact": "The Word Ends With You instance of fandom website",
      "confidence": 0.9,
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "fandom website",
      "type": "relationship"
    },
    {
      "fact": "Data Storage: Define a dictionary to store the parsed data, including columns 'name' and 'line'.",
      "confidence": 0.9,
      "timestamp": 736,
      "type": "key_point"
    },
    {
      "fact": "Google has start_char: 1750",
      "confidence": 0.9,
      "subject": "Google",
      "type": "entity_property"
    },
    {
      "fact": "Kaggle instance of dataset",
      "confidence": 0.9,
      "subject": "Kaggle",
      "predicate": "instance of",
      "object": "dataset",
      "type": "relationship"
    },
    {
      "fact": "Process: Open and read the transcript file.",
      "confidence": 0.9,
      "timestamp": 791,
      "type": "key_point"
    },
    {
      "fact": "Google has end_char: 1756",
      "confidence": 0.9,
      "subject": "Google",
      "type": "entity_property"
    },
    {
      "fact": "chatbot dialogues uses",
      "confidence": 0.9,
      "subject": "chatbot",
      "predicate": "dialogues",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Process: Match each line with the regular expression pattern.",
      "confidence": 0.9,
      "timestamp": 831,
      "type": "key_point"
    },
    {
      "fact": "Peppa Pig has spacy_label: ORG",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "type": "entity_property"
    },
    {
      "fact": "dialogues chatbot used by",
      "confidence": 0.9,
      "subject": "dialogues",
      "predicate": "chatbot",
      "object": "used by",
      "type": "relationship"
    },
    {
      "fact": "Process: Extract the name and line from the regular expression match and append to the dictionary.",
      "confidence": 0.9,
      "timestamp": 862,
      "type": "key_point"
    },
    {
      "fact": "Peppa Pig has start_char: 2566",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "type": "entity_property"
    },
    {
      "fact": "chatbot text messages uses",
      "confidence": 0.9,
      "subject": "chatbot",
      "predicate": "text messages",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Process: Convert the dictionary to a Pandas DataFrame.",
      "confidence": 0.9,
      "timestamp": 897,
      "type": "key_point"
    },
    {
      "fact": "Peppa Pig has end_char: 2575",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "type": "entity_property"
    },
    {
      "fact": "text messages chatbot used by",
      "confidence": 0.9,
      "subject": "text messages",
      "predicate": "chatbot",
      "object": "used by",
      "type": "relationship"
    }
  ],
  "extraction_stats": {
    "spacy_entities": 54,
    "gliner_entities": 112,
    "llm_validated": 114,
    "relationships": 203,
    "graph_nodes": 195,
    "graph_edges": 179
  }
}