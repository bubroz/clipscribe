#!/usr/bin/env python3
"""
ClipScribe Demo Script - Showcase features with REAL data
"""

import os
import sys
import asyncio
from pathlib import Path

# Add src to path for imports
sys.path.insert(0, str(Path(__file__).parent / "src"))

# Test URLs for demo - PBS two-part video
DEMO_VIDEO_URLS = [
    "https://www.youtube.com/watch?v=6ZVj1_SE4Mo",  # Part 1
    "https://www.youtube.com/watch?v=xYMWTXIkANM"   # Part 2
]

async def run_demo():
    """Run the ClipScribe demo with REAL data - TWO-PART PBS VIDEO."""
    print("ğŸš€ ClipScribe Demo - Two-Part PBS Video Intelligence")
    print("=" * 55)
    
    # Check for API key
    if not os.getenv("GOOGLE_API_KEY"):
        print("âŒ GOOGLE_API_KEY not found!")
        print("\nğŸ”‘ You need a FREE Google API key to run ClipScribe:")
        print("   1. Get FREE key: https://makersuite.google.com/app/apikey")
        print("   2. export GOOGLE_API_KEY='your_key_here'")
        print("   3. Run this demo again")
        print(f"\nğŸ¬ This demo will process TWO PBS videos:")
        for i, url in enumerate(DEMO_VIDEO_URLS, 1):
            print(f"   Part {i}: {url}")
        return
    
    print("âœ… Google API key detected!")
    print(f"ğŸ¬ Processing TWO-PART PBS video series:")
    for i, url in enumerate(DEMO_VIDEO_URLS, 1):
        print(f"   Part {i}: {url}")
    
    # Create output directory
    output_dir = Path("demo_output")
    output_dir.mkdir(exist_ok=True)
    
    print("\nğŸ“¹ Running ClipScribe batch processing...")
    
    try:
        # Import ClipScribe after checking API key
        from clipscribe.retrievers.video_retriever import VideoIntelligenceRetriever
        
        # Process both videos
        retriever = VideoIntelligenceRetriever()
        
        total_entities = 0
        total_relationships = 0
        
        for i, url in enumerate(DEMO_VIDEO_URLS, 1):
            print(f"\nğŸ¬ Processing Part {i}/{len(DEMO_VIDEO_URLS)}: {url}")
            print("   â³ Downloading and transcribing...")
            print("   â³ Extracting entities and relationships...")
            print("   â³ Generating knowledge graph...")
            
            # Process each video and save all formats
            video_intelligence = await retriever.retrieve_and_process(
                url=url,
                output_dir=output_dir,
                save_formats=['json', 'csv', 'gexf', 'srt']
            )
            
            entities_count = len(video_intelligence.entities)
            relationships_count = len(video_intelligence.relationships)
            
            print(f"   âœ… Part {i} completed!")
            print(f"   ğŸ“Š Found {entities_count} entities")
            print(f"   ğŸ”— Found {relationships_count} relationships")
            
            total_entities += entities_count
            total_relationships += relationships_count
        
        print(f"\nğŸ‰ All videos processed!")
        print(f"ğŸ“Š Total entities across both parts: {total_entities}")
        print(f"ğŸ”— Total relationships across both parts: {total_relationships}")
        
        # Run entity source analysis on the real data from both videos
        print("\nğŸ“ˆ Running Entity Source Analysis on TWO-PART data...")
        
        import subprocess
        result = subprocess.run([
            "python", str(Path.cwd() / "scripts" / "analyze_entity_sources.py"),
            "--output-dir", str(output_dir),
            "--create-visualizations",
            "--save-excel",
            "--save-csv",
            "--save-markdown"
        ], capture_output=True, text=True, cwd=Path.cwd())
        
        if result.returncode == 0:
            print("âœ… Batch entity source analysis completed!")
            print("ğŸ“Š Interactive visualizations created for both videos!")
            print("ğŸ“ˆ Cross-video comparison charts generated!")
        else:
            print(f"âš ï¸  Analysis output: {result.stderr}")
            
    except Exception as e:
        print(f"âŒ Error during processing: {e}")
        print("ğŸ’¡ Make sure you have a valid Google API key and internet connection")
        return
    
    # Show what files were created
    print(f"\nğŸ“ Real demo files created:")
    file_count = 0
    for file_path in output_dir.rglob("*"):
        if file_path.is_file() and file_count < 15:  # Limit output
            print(f"   ğŸ“„ {file_path.relative_to(output_dir)}")
            file_count += 1
    
    if file_count >= 15:
        print("   ... and more files!")
    
    print("\nğŸ¯ TWO-PART REAL Demo Features Showcased:")
    print("   â€¢ Batch processing of multiple videos")
    print("   â€¢ Real video transcription with Gemini (2 videos)")
    print("   â€¢ Cross-video entity extraction comparison")
    print("   â€¢ Multi-video relationship mapping")
    print("   â€¢ Batch performance analytics")
    print("   â€¢ Interactive Plotly visualizations across videos")
    print("   â€¢ Multi-format exports (JSON, CSV, GEXF, SRT)")
    print("   â€¢ Excel reports with cross-video analysis")
    print("   â€¢ Video comparison charts and insights")
    
    print(f"\nğŸ” Next Steps:")
    print("   1. Check the REAL batch files in demo_output/")
    print("   2. Run: streamlit run app.py")
    print("   3. Upload the multi-video data to Streamlit")
    print("   4. Explore the video comparison features")
    print("   5. Try the research tab for more batch processing")
    
    print(f"\nğŸ‰ TWO-PART Demo complete! You now have REAL batch ClipScribe data.")
    print(f"ğŸ“º Source videos:")
    for i, url in enumerate(DEMO_VIDEO_URLS, 1):
        print(f"   Part {i}: {url}")

def main():
    """Main entry point."""
    try:
        asyncio.run(run_demo())
    except KeyboardInterrupt:
        print("\nâ¹ï¸  Demo cancelled by user")
    except Exception as e:
        print(f"\nâŒ Demo failed: {e}")

if __name__ == "__main__":
    main() 