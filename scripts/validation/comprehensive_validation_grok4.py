#!/usr/bin/env python3
"""
COMPLETE COMPREHENSIVE VALIDATION - Grok-4 Fast Reasoning

Tests ALL intelligence features:
1. Entity extraction (18 spaCy types)
2. Relationship mapping
3. Topics extraction (NEW!)
4. Key moments extraction (NEW!)
5. Sentiment analysis (NEW!)
6. Evidence quotes (NEW!)

With ACCURATE cost tracking using official xAI pricing:
- Input tokens: $3.00/M
- Cached input: $0.75/M  
- Output tokens: $15.00/M
"""

import asyncio
from pathlib import Path
import json
from datetime import datetime
import sys
from typing import Dict, List
import time

project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Helper for timestamped progress
def log_progress(msg: str):
    """Print timestamped progress message."""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {msg}")

# Test videos from MASTER_TEST_VIDEO_TABLE.md
COMPREHENSIVE_TEST_VIDEOS = [
    {
        "id": "P-2",
        "name": "All-In Podcast",
        "local_path": "test_videos/IbnrclsPGPQ_Trump Brokers Gaza Peace Deal, National Guard in C.mp3",
        "duration_min": 88,
        "speakers": 4,
        "type": "Tech/politics panel",
        "expected_entity_types": ["PERSON", "ORG", "GPE", "EVENT", "PRODUCT"]
    },
    {
        "id": "View-1",
        "name": "The View Oct 14",
        "local_path": "test_videos/U3w93r5QRb8_The View Full Broadcast â€“ October 14, 2025.mp3",
        "duration_min": 36,
        "speakers": 5,
        "type": "Daily panel",
        "expected_entity_types": ["PERSON", "ORG", "GPE", "EVENT"]
    },
    {
        "id": "P-1",
        "name": "MTG Interview",
        "local_path": "test_videos/wlONOh_iUXY_Marjorie Taylor Greene Emergency Podcast ï½œ The Tim.mp3",
        "duration_min": 71,
        "speakers": 2,
        "type": "Political podcast",
        "expected_entity_types": ["PERSON", "ORG", "GPE", "NORP", "LAW"]
    },
]


async def process_video_with_modal(audio_path: Path, video_info: dict):
    """Process local video through Modal with Grok-4."""
    import modal
    from google.cloud import storage
    
    print(f"\n{'='*80}")
    log_progress(f"Processing {video_info['name']} ({video_info['duration_min']} min, {video_info['speakers']} speakers)")
    print(f"{'='*80}\n")
    
    if not audio_path.exists():
        log_progress(f"ERROR: File not found: {audio_path}")
        return None
    
    # Upload to GCS
    file_size_mb = audio_path.stat().st_size / (1024 * 1024)
    log_progress(f"Uploading to GCS ({file_size_mb:.0f}MB)...")
    
    upload_start = time.time()
    client = storage.Client()
    bucket = client.bucket("clipscribe-validation")
    
    gcs_path = f"validation/grok4_full/{audio_path.name}"
    blob = bucket.blob(gcs_path)
    blob.upload_from_filename(str(audio_path))
    
    upload_time = time.time() - upload_start
    gcs_url = f"gs://clipscribe-validation/{gcs_path}"
    log_progress(f"Upload complete ({upload_time:.1f}s)")
    
    # Call Modal
    log_progress("Modal processing with Grok-4 Fast Reasoning...")
    
    try:
        modal_start = time.time()
        Station10Transcriber = modal.Cls.from_name("station10-transcription", "Station10Transcriber")
        result_dict = Station10Transcriber().transcribe_from_gcs.remote(
            gcs_input=gcs_url,
            gcs_output=f"gs://clipscribe-validation/validation/grok4_results/{video_info['id']}/"
        )
        
        modal_time = time.time() - modal_start
        
        # Download full transcript from GCS
        gcs_output = result_dict.get('gcs_output', '')
        if gcs_output:
            possible_paths = [
                f"validation/grok4_results/{video_info['id']}//transcript.json",
            ]
            
            transcript_json = None
            for path in possible_paths:
                transcript_blob = bucket.blob(path)
                
                if transcript_blob.exists():
                    log_progress("Downloading full transcript from GCS...")
                    transcript_json = json.loads(transcript_blob.download_as_text())
                    result_dict.update(transcript_json)
                    break
            
            if transcript_json is None:
                log_progress("WARNING: Transcript not found")
        
        log_progress(f"Modal complete: {result_dict.get('speakers', 0)} speakers, {len(result_dict.get('entities', []))} entities ({modal_time:.1f}s)")
        
        return result_dict
        
    except Exception as e:
        log_progress(f"ERROR: Modal processing failed: {e}")
        import traceback
        traceback.print_exc()
        return None


def analyze_full_intelligence(result: dict, video_info: dict) -> dict:
    """Analyze ALL intelligence fields - COMPLETE validation."""
    print(f"\n{'='*80}")
    print(f"COMPLETE INTELLIGENCE ANALYSIS: {video_info['name']}")
    print(f"{'='*80}\n")
    
    if not result:
        return {'status': 'failed'}
    
    # Extract ALL data
    segments = result.get('segments', [])
    entities = result.get('entities', [])
    relationships = result.get('relationships', [])
    topics = result.get('topics', [])
    key_moments = result.get('key_moments', [])
    sentiment = result.get('sentiment', {})
    speakers = len(set(s.get('speaker') for s in segments if s.get('speaker')))
    
    # Basic metrics
    print(f"BASIC METRICS:")
    print(f"  Segments: {len(segments)}")
    print(f"  Speakers: {speakers} (expected: {video_info['speakers']})")
    print(f"  Duration: {video_info['duration_min']}min")
    
    # Entity analysis
    print(f"\nENTITY EXTRACTION:")
    print(f"  Total entities: {len(entities)}")
    print(f"  Total relationships: {len(relationships)}")
    
    if entities:
        entity_types = {}
        entities_with_evidence = 0
        
        for e in entities:
            etype = e.get('type', 'UNKNOWN')
            entity_types[etype] = entity_types.get(etype, 0) + 1
            if e.get('evidence'):
                entities_with_evidence += 1
        
        print(f"  Entity types: {len(entity_types)}")
        print(f"  Entities with evidence: {entities_with_evidence} ({entities_with_evidence/len(entities)*100:.1f}%)")
        
        print(f"\n  Type distribution:")
        for etype, count in sorted(entity_types.items(), key=lambda x: x[1], reverse=True)[:10]:
            print(f"    {etype}: {count}")
        
        print(f"\n  Sample entities:")
        for i, e in enumerate(entities[:5]):
            name = e.get('name', 'N/A')
            etype = e.get('type', 'N/A')
            conf = e.get('confidence', 0)
            evidence = e.get('evidence', '')
            evidence_preview = f" - \"{evidence[:40]}...\"" if evidence else ""
            print(f"    {i+1}. {name} ({etype}, {conf:.2f}){evidence_preview}")
    
    # Relationship analysis
    if relationships:
        rels_with_evidence = sum(1 for r in relationships if r.get('evidence'))
        print(f"\n  Relationships with evidence: {rels_with_evidence} ({rels_with_evidence/len(relationships)*100:.1f}%)")
        print(f"  Sample relationships:")
        for i, r in enumerate(relationships[:3]):
            subj = r.get('subject', 'N/A')
            pred = r.get('predicate', 'N/A')
            obj = r.get('object', 'N/A')
            print(f"    {i+1}. {subj} -> {pred} -> {obj}")
    
    # Topics analysis (NEW!)
    print(f"\nTOPICS EXTRACTION (NEW!):")
    print(f"  Total topics: {len(topics)}")
    
    if topics:
        print(f"  Topics extracted:")
        for i, topic in enumerate(topics[:5]):
            if isinstance(topic, dict):
                name = topic.get('name', 'N/A')
                relevance = topic.get('relevance', 'N/A')
                time_range = topic.get('time_range', 'N/A')
                print(f"    {i+1}. {name} (relevance: {relevance}, time: {time_range})")
            else:
                print(f"    {i+1}. {topic}")
    else:
        print(f"  âš ï¸  NO TOPICS EXTRACTED (may be chunked video)")
    
    # Key moments analysis (NEW!)
    print(f"\nKEY MOMENTS EXTRACTION (NEW!):")
    print(f"  Total moments: {len(key_moments)}")
    
    if key_moments:
        print(f"  Key moments:")
        for i, moment in enumerate(key_moments[:5]):
            timestamp = moment.get('timestamp', 'N/A')
            description = moment.get('description', 'N/A')
            significance = moment.get('significance', 'N/A')
            print(f"    {i+1}. [{timestamp}] {description} (sig: {significance})")
    else:
        print(f"  âš ï¸  NO KEY MOMENTS EXTRACTED (may be chunked video)")
    
    # Sentiment analysis (NEW!)
    print(f"\nSENTIMENT ANALYSIS (NEW!):")
    if sentiment:
        overall = sentiment.get('overall', 'N/A')
        confidence = sentiment.get('confidence', 'N/A')
        per_topic = sentiment.get('per_topic', {})
        
        print(f"  Overall: {overall} (confidence: {confidence})")
        if per_topic:
            print(f"  Per-topic sentiment:")
            for topic, sent in list(per_topic.items())[:3]:
                print(f"    - {topic}: {sent}")
    else:
        print(f"  âš ï¸  NO SENTIMENT DATA (may be chunked video)")
    
    # Cost calculation (ACCURATE from official docs)
    print(f"\nCOST ANALYSIS (Official xAI Pricing):")
    
    # Estimate tokens (rough)
    transcript_chars = sum(len(s.get('text', '')) for s in segments)
    estimated_input_tokens = transcript_chars / 4  # ~4 chars per token
    estimated_output_tokens = (len(entities) + len(relationships)) * 20  # ~20 tokens per entity/rel
    
    # Official Grok-4 Fast Reasoning pricing (from docs.x.ai)
    input_cost = (estimated_input_tokens / 1_000_000) * 0.20
    output_cost = (estimated_output_tokens / 1_000_000) * 0.50
    grok_cost = input_cost + output_cost
    whisperx_cost = result.get('cost', 0)
    total_cost = whisperx_cost + grok_cost
    
    print(f"  WhisperX (GPU): ${whisperx_cost:.4f}")
    print(f"  Grok-4 (estimated): ${grok_cost:.4f}")
    print(f"    Input tokens: ~{estimated_input_tokens:.0f} @ $3.00/M = ${input_cost:.4f}")
    print(f"    Output tokens: ~{estimated_output_tokens:.0f} @ $15.00/M = ${output_cost:.4f}")
    print(f"  TOTAL COST: ${total_cost:.4f}")
    
    # Validation scoring
    print(f"\nVALIDATION CHECKS:")
    
    has_entities = len(entities) >= 10
    has_relationships = len(relationships) >= 5
    has_topics = len(topics) >= 1
    has_moments = len(key_moments) >= 1
    has_sentiment = bool(sentiment)
    has_diversity = len(entity_types) >= 10 if entities else False
    
    print(f"  Entities extracted: {'âœ… PASS' if has_entities else 'âŒ FAIL'} ({len(entities)} >= 10)")
    print(f"  Relationships: {'âœ… PASS' if has_relationships else 'âŒ FAIL'} ({len(relationships)} >= 5)")
    print(f"  Topics: {'âœ… PASS' if has_topics else 'âŒ FAIL'} ({len(topics)} >= 1)")
    print(f"  Key moments: {'âœ… PASS' if has_moments else 'âŒ FAIL'} ({len(key_moments)} >= 1)")
    print(f"  Sentiment: {'âœ… PASS' if has_sentiment else 'âŒ FAIL'} (exists: {has_sentiment})")
    print(f"  Type diversity: {'âœ… PASS' if has_diversity else 'âŒ FAIL'} ({len(entity_types) if entities else 0} >= 10)")
    
    validation_score = sum([has_entities, has_relationships, has_topics, has_moments, has_sentiment, has_diversity]) / 6.0
    
    print(f"\nğŸ“Š VALIDATION SCORE: {validation_score*100:.0f}%")
    
    return {
        'status': 'success',
        'video': video_info['name'],
        'video_id': video_info['id'],
        'speakers': speakers,
        'segments': len(segments),
        'entities': len(entities),
        'relationships': len(relationships),
        'topics': len(topics),
        'key_moments': len(key_moments),
        'has_sentiment': bool(sentiment),
        'sentiment_overall': sentiment.get('overall', 'N/A') if sentiment else 'N/A',
        'entity_types': len(entity_types) if entities else 0,
        'entities_with_evidence': entities_with_evidence if entities else 0,
        'whisperx_cost': whisperx_cost,
        'grok_cost_estimated': grok_cost,
        'total_cost': total_cost,
        'validation_score': validation_score,
        'full_intelligence_working': has_topics and has_moments and has_sentiment
    }


async def main():
    start_time = time.time()
    
    print("=" * 80)
    log_progress("STARTING COMPLETE COMPREHENSIVE VALIDATION - Grok-4 Fast Reasoning")
    print("=" * 80)
    print(f"\nTesting {len(COMPREHENSIVE_TEST_VIDEOS)} videos with FULL intelligence extraction:")
    for v in COMPREHENSIVE_TEST_VIDEOS:
        print(f"  - {v['name']} ({v['duration_min']} min, {v['speakers']} speakers)")
    
    print(f"\nFEATURES TO VALIDATE:")
    print(f"  1. Entity extraction (18 spaCy types)")
    print(f"  2. Relationship mapping")
    print(f"  3. Topics extraction (NEW!)")
    print(f"  4. Key moments extraction (NEW!)")
    print(f"  5. Sentiment analysis (NEW!)")
    print(f"  6. Evidence quotes (NEW!)")
    print(f"  7. Accurate cost tracking (official xAI pricing)")
    
    print("=" * 80)
    
    results = []
    
    for i, video_info in enumerate(COMPREHENSIVE_TEST_VIDEOS, 1):
        log_progress(f"Video {i}/{len(COMPREHENSIVE_TEST_VIDEOS)}: {video_info['name']}")
        
        audio_path = project_root / video_info['local_path']
        
        # Process with Modal
        result = await process_video_with_modal(audio_path, video_info)
        
        # Analyze COMPLETELY
        analysis = analyze_full_intelligence(result, video_info)
        results.append(analysis)
        
        elapsed = time.time() - start_time
        log_progress(f"Completed {i}/{len(COMPREHENSIVE_TEST_VIDEOS)} videos (elapsed: {elapsed/60:.1f}m)")
    
    # COMPLETE Summary
    total_time = time.time() - start_time
    
    print("\n" + "=" * 80)
    log_progress(f"VALIDATION COMPLETE ({total_time/60:.1f}m total)")
    print("=" * 80)
    
    total_videos = len(results)
    working = sum(1 for r in results if r.get('full_intelligence_working', False))
    avg_score = sum(r.get('validation_score', 0) for r in results) / total_videos if results else 0
    total_entities = sum(r.get('entities', 0) for r in results)
    total_topics = sum(r.get('topics', 0) for r in results)
    total_moments = sum(r.get('key_moments', 0) for r in results)
    total_cost = sum(r.get('total_cost', 0) for r in results)
    
    print(f"\nTOTAL METRICS:")
    print(f"  Videos tested: {total_videos}")
    print(f"  Full intelligence working: {working}/{total_videos}")
    print(f"  Total entities: {total_entities}")
    print(f"  Total topics: {total_topics}")
    print(f"  Total key moments: {total_moments}")
    print(f"  Total cost: ${total_cost:.4f}")
    print(f"  Average validation score: {avg_score*100:.0f}%")
    
    if avg_score >= 0.75 and working >= 2:
        log_progress("VALIDATION PASSED - Full intelligence extraction working!")
    else:
        log_progress("VALIDATION FAILED - Check issues above")
    
    # Save results
    output_path = project_root / "validation_data" / "grok4_complete_validation.json"
    output_path.parent.mkdir(exist_ok=True)
    
    with open(output_path, 'w') as f:
        json.dump({
            'timestamp': datetime.now().isoformat(),
            'model': 'grok-4-fast-reasoning',
            'chunk_limit': '200k chars',
            'total_videos': total_videos,
            'full_intelligence_working': working,
            'average_score': avg_score,
            'total_entities': total_entities,
            'total_topics': total_topics,
            'total_moments': total_moments,
            'total_cost': total_cost,
            'videos': results,
            'overall_assessment': 'READY' if avg_score >= 0.75 and working >= 2 else 'NEEDS_FIXES'
        }, f, indent=2)
    
    print(f"\nğŸ“„ Results saved: {output_path}")


if __name__ == "__main__":
    asyncio.run(main())

