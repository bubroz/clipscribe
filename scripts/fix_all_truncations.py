#!/usr/bin/env python3
"""
Fix All Truncations in ClipScribe

This script identifies and fixes all arbitrary transcript truncations across the codebase.

Usage:
    poetry run python scripts/fix_all_truncations.py
"""

import os
import re
from pathlib import Path

def find_truncations():
    """Find all truncation patterns in the codebase."""
    
    truncations = []
    
    # Pattern to find array slicing with numeric limits
    patterns = [
        (r'\[:(\d+)\]', 'array_slice'),
        (r'truncat', 'truncate_mention'),
        (r'max_length\s*=\s*(\d+)', 'max_length'),
        (r'[:.]slice\(.*?(\d+)', 'slice_method'),
        (r'[:.]substring\(.*?(\d+)', 'substring_method')
    ]
    
    src_dir = Path("src/clipscribe")
    
    for py_file in src_dir.rglob("*.py"):
        with open(py_file, 'r') as f:
            lines = f.readlines()
            
        for i, line in enumerate(lines, 1):
            for pattern, pattern_type in patterns:
                matches = re.finditer(pattern, line, re.IGNORECASE)
                for match in matches:
                    # Filter out legitimate uses (like list limits for display)
                    if pattern_type == 'array_slice' and match.group(1):
                        limit = int(match.group(1))
                        # Ignore small display limits (< 100) and hash truncations
                        if limit < 100 or 'hash' in line.lower() or 'sha' in line.lower():
                            continue
                        # Ignore if it's just limiting displayed items
                        if 'for display' in line or 'Show top' in line or '# Limit' in line:
                            continue
                    
                    truncations.append({
                        'file': str(py_file),
                        'line': i,
                        'content': line.strip(),
                        'type': pattern_type,
                        'limit': match.group(1) if len(match.groups()) > 0 else None
                    })
    
    return truncations

def main():
    """Main entry point."""
    
    print("=" * 80)
    print("FINDING ALL TRUNCATIONS IN CLIPSCRIBE")
    print("=" * 80)
    
    truncations = find_truncations()
    
    # Group by file
    by_file = {}
    for t in truncations:
        if t['file'] not in by_file:
            by_file[t['file']] = []
        by_file[t['file']].append(t)
    
    # Critical truncations that affect transcript analysis
    critical_files = [
        'src/clipscribe/retrievers/transcriber.py',
        'src/clipscribe/extractors/hybrid_extractor.py',
        'src/clipscribe/extractors/streaming_extractor.py'
    ]
    
    print("\nüî¥ CRITICAL TRUNCATIONS (affecting analysis quality):")
    print("-" * 60)
    
    for file in critical_files:
        if file in by_file:
            print(f"\nüìÅ {file}:")
            for t in by_file[file]:
                if t['limit'] and int(t['limit']) > 100:
                    print(f"  Line {t['line']:4}: {t['content'][:80]}")
                    if t['limit']:
                        print(f"           Limit: {t['limit']} chars")
    
    print("\n" + "=" * 80)
    print("FIXES TO APPLY")
    print("=" * 80)
    
    fixes = [
        {
            'file': 'src/clipscribe/retrievers/transcriber.py',
            'line': 240,
            'old': '{transcript_text[:12000]}',
            'new': '{transcript_text}',
            'reason': 'Second pass should analyze full transcript'
        },
        {
            'file': 'src/clipscribe/retrievers/transcriber.py',
            'line': 498,
            'old': '{transcript_text[:24000]}',
            'new': '{transcript_text}',
            'reason': 'Main analysis should use full transcript'
        },
        {
            'file': 'src/clipscribe/extractors/hybrid_extractor.py',
            'line': 265,
            'old': 'Text: {text[:3000]}...',
            'new': 'Text: {text}',
            'reason': 'Entity extraction needs full context'
        }
    ]
    
    print("\nüìù Required fixes:\n")
    for i, fix in enumerate(fixes, 1):
        print(f"{i}. {fix['file']}:{fix['line']}")
        print(f"   OLD: {fix['old']}")
        print(f"   NEW: {fix['new']}")
        print(f"   WHY: {fix['reason']}")
        print()
    
    # Generate fix commands
    print("\n" + "=" * 80)
    print("AUTOMATED FIX COMMANDS")
    print("=" * 80)
    
    print("\n# Run these commands to fix all truncations:\n")
    
    for fix in fixes:
        # Escape special characters for sed
        old_escaped = fix['old'].replace('[', '\\[').replace(']', '\\]').replace('/', '\\/')
        new_escaped = fix['new'].replace('[', '\\[').replace(']', '\\]').replace('/', '\\/')
        
        print(f"# Fix in {fix['file']}:")
        print(f"sed -i '' 's/{old_escaped}/{new_escaped}/g' {fix['file']}")
        print()
    
    # Also need to add safety settings and max_output_tokens
    print("\n# Additional configuration fixes needed:")
    print("# 1. Add safety_settings to GeminiFlashTranscriber.__init__")
    print("# 2. Add max_output_tokens=8192 to all generation_config dicts")
    print("# 3. Test with a full-length video to verify improvements")
    
    print("\n" + "=" * 80)
    print("IMPACT ANALYSIS")
    print("=" * 80)
    
    print("\nüìä Expected improvements after fixes:")
    print("- Transcript analysis: 24k chars ‚Üí Full transcript (up to 1M chars)")
    print("- Entity extraction: ~20 ‚Üí 200+ entities for long videos")
    print("- Relationship mapping: ~10 ‚Üí 300+ relationships")
    print("- Processing coverage: 8.8% ‚Üí 100% of video content")
    print("- Cost: No change (already paying for full transcription)")


if __name__ == "__main__":
    main()
