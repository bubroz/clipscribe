{
  "metadata": {
    "video_id": "jNQXAC9IVRw",
    "url": "https://www.youtube.com/watch?v=jNQXAC9IVRw",
    "title": "Me at the zoo",
    "channel": "jawed",
    "channel_id": "UC4QobU6STFB0P71PMvOGN5A",
    "published_at": "2005-04-23 20:31:52",
    "duration": 19,
    "view_count": 367786239,
    "like_count": null,
    "comment_count": null,
    "description": "Microplastics are accumulating in human brains at an alarming rate\nhttps://www.youtube.com/watch?v=0PT5c1z3LL8\n\n\u201cNanoplastics and Human Health\u201d with Matthew J Campen, PhD, MSPH\nhttps://www.youtube.com/watch?v=RRBN_4L09Mg\n\n00:00 Intro\n00:05 The cool thing\n00:17 End",
    "tags": [
      "me at the zoo",
      "jawed karim",
      "first youtube video"
    ],
    "entities": [],
    "relationships": []
  },
  "transcript": {
    "full_text": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information.\n\n**1. COMPLETE TRANSCRIPTION**\n[00:00-00:03] Alright, so here we are in front of the, uh, elephants.\n[00:05-00:13] The cool thing about these guys is that, is that they have really, really, really long, um, trunks. And that's, that's cool.\n[00:16-00:18] And that's pretty much all there is to say.\n\n**2. VISUAL TEMPORAL CUES**\nThere are no visual temporal cues such as timelines, charts, on-screen calendars, or progress indicators present in this video. The video consists of a single, continuous shot with no graphical overlays containing temporal data.\n\n**3. VISUAL DATE EXTRACTION**\nThere are no dates, years, or time periods visually displayed at any point in the video.\n\n**4. TEMPORAL CONTEXT**\nThe video's temporal context is immediate and contained entirely within its short duration. The speaker uses the present tense (\"here we are,\" \"they have\"), indicating he is describing the scene as it happens. The sequence of events is linear and unfolds in real-time: an introduction to the location, a key observation about the subject (the elephants), and a concluding remark.\n\n**5. VISUAL ANNOTATIONS**\n*   [VISUAL: 00:00-00:19] A young man stands in the foreground, speaking directly to the camera. He has dark, somewhat messy hair and is wearing a grey and red jacket over a blue t-shirt.\n*   [VISUAL: 00:00-00:19] The setting is a zoo enclosure for elephants. In the background, behind a series of metal posts and cables, two elephants are visible.\n*   [VISUAL: 00:03-00:05] One of the elephants in the background uses its long trunk to pull hay from a raised feeder.\n*   [VISUAL: 00:10-00:11] The speaker gestures with his right hand to emphasize his point about the elephants' long trunks.\n*   [VISUAL: 00:14-00:16] The speaker briefly turns his head to the right to look at the elephants before turning back to the camera to deliver his final line.",
    "segments": [
      {
        "start": 0.0,
        "end": 19,
        "text": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we are in front of the, uh, elephants. [00:05-00:13] The cool thing about these guys is that, is that they have really, really, really long, um, trunks. And that's, that's cool. [00:16-00:18] And that's pretty much all there is to say. **2. VISUAL TEMPORAL CUES** There are no visual temporal cues such as timelines, charts, on-screen calendars, or progress indicators present in this video. The video consists of a single, continuous shot with no graphical overlays containing temporal data. **3. VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video. **4. TEMPORAL CONTEXT** The video's temporal context is immediate and contained entirely within its short duration. The speaker uses the present tense (\"here we are,\" \"they have\"), indicating he is describing the scene as it happens. The sequence of events is linear and unfolds in real-time: an introduction to the location, a key observation about the subject (the elephants), and a concluding remark. **5. VISUAL ANNOTATIONS** * [VISUAL: 00:00-00:19] A young man stands in the foreground, speaking directly to the camera. He has dark, somewhat messy hair and is wearing a grey and red jacket over a blue t-shirt. * [VISUAL: 00:00-00:19] The setting is a zoo enclosure for elephants. In the background, behind a series of metal posts and cables, two elephants are visible. * [VISUAL: 00:03-00:05] One of the elephants in the background uses its long trunk to pull hay from a raised feeder. * [VISUAL: 00:10-00:11] The speaker gestures with his right hand to emphasize his point about the elephants' long trunks. * [VISUAL: 00:14-00:16] The speaker briefly turns his head to the right to look at the elephants before turning back to the camera to deliver his final line."
      }
    ],
    "language": "en",
    "raw_transcript": null
  },
  "entities": [
    {
      "entity": "Elephant enclosure",
      "type": "LOCATION",
      "start_char": null,
      "end_char": null,
      "source": null,
      "properties": {},
      "extraction_sources": [
        "gemini"
      ],
      "mention_count": 1,
      "context_windows": [],
      "aliases": [],
      "canonical_form": "Elephant enclosure",
      "temporal_distribution": []
    },
    {
      "entity": "The speaker",
      "type": "PERSON",
      "start_char": null,
      "end_char": null,
      "source": null,
      "properties": {},
      "extraction_sources": [
        "gemini"
      ],
      "mention_count": 1,
      "context_windows": [
        {
          "text": "and contained entirely within its short duration. The speaker uses the present tense (\"here we are,\" \"they have",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_present": false
        }
      ],
      "aliases": [],
      "canonical_form": "The speaker",
      "temporal_distribution": [
        {
          "timestamp": "00:00:00",
          "duration": 5.0,
          "context_type": "spoken"
        }
      ]
    },
    {
      "entity": "Zoo",
      "type": "ORGANIZATION",
      "start_char": null,
      "end_char": null,
      "source": null,
      "properties": {},
      "extraction_sources": [
        "gemini"
      ],
      "mention_count": 1,
      "context_windows": [
        {
          "text": "t-shirt. * [VISUAL: 00:00-00:19] The setting is a zoo enclosure for elephants. In the background, behin",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_present": false
        }
      ],
      "aliases": [],
      "canonical_form": "Zoo",
      "temporal_distribution": [
        {
          "timestamp": "00:00:00",
          "duration": 5.0,
          "context_type": "spoken"
        }
      ]
    }
  ],
  "relationships": [
    {
      "subject": "The speaker",
      "predicate": "is located at",
      "object": "Elephant enclosure",
      "source": "gemini",
      "evidence_chain": [
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "s pretty much all there is to say. **2. VISUAL TEMPORAL CUES** There are no visual temporal cues such as timelines, charts, on-screen calendars, or progress indicators present in this video. The video consists of a single, continuous shot with no graphical overlays containing temporal data. **3. VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video. **4. TEMPORAL CONTEXT** The video",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        }
      ],
      "supporting_mentions": 1,
      "contradictions": [
        "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE..."
      ],
      "visual_correlation": true,
      "properties": {}
    },
    {
      "subject": "The speaker",
      "predicate": "observes",
      "object": "Elephants",
      "source": "gemini",
      "evidence_chain": [
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "s pretty much all there is to say. **2. VISUAL TEMPORAL CUES** There are no visual temporal cues such as timelines, charts, on-screen calendars, or progress indicators present in this video. The video consists of a single, continuous shot with no graphical overlays containing temporal data. **3. VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video. **4. TEMPORAL CONTEXT** The video",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        }
      ],
      "supporting_mentions": 1,
      "contradictions": [
        "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE..."
      ],
      "visual_correlation": true,
      "properties": {}
    },
    {
      "subject": "The speaker",
      "predicate": "states feature of Elephants",
      "object": "Long trunks",
      "source": "gemini",
      "evidence_chain": [
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "s pretty much all there is to say. **2. VISUAL TEMPORAL CUES** There are no visual temporal cues such as timelines, charts, on-screen calendars, or progress indicators present in this video. The video consists of a single, continuous shot with no graphical overlays containing temporal data. **3. VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video. **4. TEMPORAL CONTEXT** The video",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        }
      ],
      "supporting_mentions": 1,
      "contradictions": [
        "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE..."
      ],
      "visual_correlation": true,
      "properties": {}
    },
    {
      "subject": "Two elephants",
      "predicate": "are located in",
      "object": "Elephant enclosure",
      "source": "gemini",
      "evidence_chain": [
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "s pretty much all there is to say. **2. VISUAL TEMPORAL CUES** There are no visual temporal cues such as timelines, charts, on-screen calendars, or progress indicators present in this video. The video consists of a single, continuous shot with no graphical overlays containing temporal data. **3. VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video. **4. TEMPORAL CONTEXT** The video",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        }
      ],
      "supporting_mentions": 1,
      "contradictions": [
        "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE..."
      ],
      "visual_correlation": true,
      "properties": {}
    },
    {
      "subject": "One elephant",
      "predicate": "retrieves with trunk",
      "object": "Hay",
      "source": "gemini",
      "evidence_chain": [
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "here we are,",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        },
        {
          "direct_quote": "s pretty much all there is to say. **2. VISUAL TEMPORAL CUES** There are no visual temporal cues such as timelines, charts, on-screen calendars, or progress indicators present in this video. The video consists of a single, continuous shot with no graphical overlays containing temporal data. **3. VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video. **4. TEMPORAL CONTEXT** The video",
          "timestamp": "00:00:00",
          "speaker": null,
          "visual_context": "VISUAL DATE EXTRACTION** There are no dates, years, or time periods visually displayed at any point in the video",
          "context_window": "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE TRANSCRIPTION** [00:00-00:03] Alright, so here we",
          "evidence_type": "visual"
        }
      ],
      "supporting_mentions": 1,
      "contradictions": [
        "The following is a complete analysis of the video, including a full transcription and extraction of all visual and temporal information. **1. COMPLETE..."
      ],
      "visual_correlation": true,
      "properties": {}
    }
  ],
  "key_points": [
    {
      "text": "An unidentified young male speaker was documented providing commentary in front of a zoo's elephant enclosure.",
      "importance": 0.9,
      "context": null
    },
    {
      "text": "The speaker's primary observation is that elephants possess 'really, really, really long trunks'.",
      "importance": 0.9,
      "context": null
    },
    {
      "text": "The video's temporal context is immediate, confirmed by the speaker's use of present tense ('here we are', 'they have').",
      "importance": 0.85,
      "context": null
    },
    {
      "text": "Visual analysis confirms the presence of two elephants in the background of the shot.",
      "importance": 0.9,
      "context": null
    },
    {
      "text": "One of the elephants is observed actively using its trunk to pull hay from a raised feeder.",
      "importance": 0.85,
      "context": null
    },
    {
      "text": "The speaker concludes his observation by stating, 'that's pretty much all there is to say', indicating a lack of further information to convey.",
      "importance": 0.8,
      "context": null
    },
    {
      "text": "No visual temporal cues, such as on-screen dates, calendars, or timelines, were detected in the footage.",
      "importance": 0.9,
      "context": null
    },
    {
      "text": "The video was captured in a single, continuous shot without any edits or graphical overlays.",
      "importance": 0.8,
      "context": null
    },
    {
      "text": "The speaker is wearing a grey and red jacket over a blue t-shirt.",
      "importance": 0.75,
      "context": null
    },
    {
      "text": "The elephant habitat is secured by a barrier consisting of metal posts and cables.",
      "importance": 0.75,
      "context": null
    },
    {
      "text": "The entire recorded event unfolds in real-time within the video's short duration.",
      "importance": 0.8,
      "context": null
    },
    {
      "text": "The speaker gestures with his right hand at 00:10 to emphasize his point about the trunks.",
      "importance": 0.7,
      "context": null
    },
    {
      "text": "The speaker briefly turns his head to look at the elephants before delivering his final remark.",
      "importance": 0.7,
      "context": null
    },
    {
      "text": "The speaker's position is in the foreground, addressing the camera directly in a vlog-style format.",
      "importance": 0.8,
      "context": null
    },
    {
      "text": "The speaker characterizes the elephants' long trunks as 'cool'.",
      "importance": 0.7,
      "context": null
    },
    {
      "text": "Analysis confirms the setting is a zoo.",
      "importance": 0.9,
      "context": null
    },
    {
      "text": "Visual evidence of the elephant's trunk functionality (retrieving hay) corroborates the speaker's verbal statements.",
      "importance": 0.85,
      "context": null
    },
    {
      "text": "The speaker initiates the video with a direct statement of location: 'Alright, so here we are in front of the, uh, elephants'.",
      "importance": 0.8,
      "context": null
    }
  ],
  "topics": [
    {
      "name": "Wildlife Observation",
      "confidence": 0.8
    },
    {
      "name": "Zoo Visit",
      "confidence": 0.8
    },
    {
      "name": "Real-time Commentary",
      "confidence": 0.8
    },
    {
      "name": "Elephants",
      "confidence": 0.8
    }
  ],
  "summary": "This intelligence briefing details the analysis of a short video segment featuring a young male speaker delivering commentary from what is identified as a zoo's elephant enclosure. The video's temporal context is immediate and unfolds in real-time, with the speaker narrating his observations in the present tense. The footage consists of a single, continuous shot, devoid of any graphical overlays, edits, or explicit temporal markers such as dates or timestamps, thereby containing the event entirely within its brief duration.\n\nThe speaker is positioned in the foreground, addressing the camera directly. In the background, two elephants are visible within their habitat, which is separated from the public area by a barrier of metal posts and cables. The central point of the speaker's monologue is a direct observation about the elephants' anatomy. He specifically highlights their 'really, really, really long trunks,' a feature he subjectively describes as 'cool.' This commentary is brief and concludes with his assertion that there is little else to report on the matter.\n\nVisual evidence corroborates the speaker's statements, as one of the elephants is observed using its trunk to manipulate its environment, specifically to pull hay from a raised feeding station. This action provides a practical demonstration of the feature the speaker chose to focus on. Beyond this singular observation, the video offers no further strategic, tactical, or informational content. The analysis confirms the location, the presence of the speaker and subjects, and the simple, real-time nature of the recorded event.",
  "sentiment": null,
  "knowledge_graph": {
    "nodes": [
      {
        "id": "Elephant enclosure",
        "type": "LOCATION",
        "confidence": 0.9
      },
      {
        "id": "The speaker",
        "type": "PERSON",
        "confidence": 0.9
      },
      {
        "id": "Zoo",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Elephants",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Long trunks",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Two elephants",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "One elephant",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Hay",
        "type": "unknown",
        "confidence": 0.9
      }
    ],
    "edges": [
      {
        "source": "The speaker",
        "target": "Elephant enclosure",
        "predicate": "is located at",
        "confidence": 0.9
      },
      {
        "source": "The speaker",
        "target": "Elephants",
        "predicate": "observes",
        "confidence": 0.9
      },
      {
        "source": "The speaker",
        "target": "Long trunks",
        "predicate": "states feature of Elephants",
        "confidence": 0.9
      },
      {
        "source": "Two elephants",
        "target": "Elephant enclosure",
        "predicate": "are located in",
        "confidence": 0.9
      },
      {
        "source": "One elephant",
        "target": "Hay",
        "predicate": "retrieves with trunk",
        "confidence": 0.9
      }
    ],
    "node_count": 8,
    "edge_count": 5
  },
  "dates": [],
  "temporal_references": [],
  "processing_stats": {
    "gemini_entities": [
      {
        "confidence": 0.98,
        "name": "The speaker",
        "type": "PERSON"
      },
      {
        "confidence": 0.9,
        "name": "Zoo",
        "type": "ORGANIZATION"
      },
      {
        "confidence": 0.95,
        "name": "Elephant enclosure",
        "type": "LOCATION"
      }
    ],
    "gemini_relationships": [
      {
        "confidence": 0.98,
        "object": "Elephant enclosure",
        "predicate": "is located at",
        "subject": "The speaker"
      },
      {
        "confidence": 0.95,
        "object": "Elephants",
        "predicate": "observes",
        "subject": "The speaker"
      },
      {
        "confidence": 0.99,
        "object": "Long trunks",
        "predicate": "states feature of Elephants",
        "subject": "The speaker"
      },
      {
        "confidence": 0.9,
        "object": "Elephant enclosure",
        "predicate": "are located in",
        "subject": "Two elephants"
      },
      {
        "confidence": 0.9,
        "object": "Hay",
        "predicate": "retrieves with trunk",
        "subject": "One elephant"
      }
    ],
    "timeline_events": [],
    "visual_temporal_cues": [],
    "temporal_patterns": [],
    "dates": [],
    "visual_dates": [],
    "retention_decision": {
      "action": "deleted",
      "video_path": "cache/Me at the zoo-jNQXAC9IVRw.mp4",
      "video_hash": "21c3d5f82235b21178ae303c5281b839",
      "reason": "Policy: Always delete source videos",
      "cost_savings": {
        "storage_cost_avoided": 0.00020341695472598075,
        "reprocessing_cost": 0.0011942390625
      },
      "timestamp": "2025-07-30T21:07:22.749952"
    }
  },
  "processing_cost": 0.0010856718749999998,
  "processing_time": 0.0,
  "timeline_v2": {
    "events": [],
    "chapters": [],
    "quality_metrics": {
      "total_events_extracted": 0,
      "events_after_deduplication": 0,
      "events_with_content_dates": 0,
      "final_high_quality_events": 0,
      "chapters_created": 0,
      "quality_improvement_ratio": 0
    },
    "status": "discontinued",
    "message": "Timeline features discontinued - focusing on core intelligence extraction"
  }
}