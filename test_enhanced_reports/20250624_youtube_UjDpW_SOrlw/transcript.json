{
  "metadata": {
    "title": "Code a Discord Chat Bot That Talks Like Your Favorite Character - Tutorial",
    "url": "https://www.youtube.com/watch?v=UjDpW_SOrlw",
    "channel": "freeCodeCamp.org",
    "duration": 3472,
    "published_at": "2021-08-26T06:30:35",
    "view_count": 210967,
    "description": "Use AI to create a Discord chat bot that talks like your favorite characters. Learn how to code it in Python and JavaScript.\n\n\u270f\ufe0f This course was developed by Lynn Zheng. Check out Lynn's YouTube channel, Lynn's DevLab: https://www.youtube.com/channel/UCZ2MeG5jTIqgzEMiByrIzsw\n\n\ud83d\udcbb Lynn's GitHub resource for this video: https://github.com/RuolinZheng08/twewy-discord-chatbot\n\n\ud83d\udd17 Lynn's personal website: https://ruolinzheng08.github.io/\n\nfreeCodeCamp tutorials referenced in this video:\n\ud83d\udd17 https://www.freecodecamp.org/news/create-a-discord-bot-with-python/\n\ud83d\udd17 https://www.freecodecamp.org/news/create-a-discord-bot-with-javascript-nodejs/\n\n\u2b50\ufe0f Course Contents \u2b50\ufe0f\n\u2328\ufe0f (00:00) Intro\n\u2328\ufe0f (01:38) Gather data\n\u2328\ufe0f (12:27) Train the model\n\u2328\ufe0f (24:27) Deploy the model\n\u2328\ufe0f (29:42) Build the Discord bot in Python\n\u2328\ufe0f (41:17) Build the Discord bot in JavaScript\n\u2328\ufe0f (51:35) Keep the bots online\n\n\ud83c\udf89 Thanks to our Champion and Sponsor supporters:\n\ud83d\udc7e Wong Voon jinq\n\ud83d\udc7e hexploitation\n\ud83d\udc7e Katia Moran\n\ud83d\udc7e BlckPhantom\n\ud83d\udc7e Nick Raker\n\ud83d\udc7e Otis Morgan\n\ud83d\udc7e DeezMaster\n\ud83d\udc7e AppWrite\n\n--\n\nLearn to code for free and get a developer job: https://www.freecodecamp.org\n\nRead hundreds of articles on programming: https://freecodecamp.org/news \n\n\u2764\ufe0f Support for this channel comes from our friends at Scrimba \u2013 the coding platform that's reinvented interactive learning: https://scrimba.com/freecodecamp"
  },
  "transcript": {
    "full_text": "Want to make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you want to make it talk like another favorite character. In this course, Lynn will show you how to create a Discord bot that uses artificial intelligence to talk like a character of your choice.\n\nHi there. I'm Lynn. I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago.\n\nIn this tutorial, we're going to build a Discord AI chatbot that can speak like your favorite character.\n\nBefore we start, if you have seen that video by any chance, know that this video is something different and more comprehensive. So keep watching till the end.\n\nThe original tutorial and my first Discord bot started as a joke between me and my friends when we were playing video games, and it really surprised me how popular it became, and a lot of people wanted to build their own bot based on that tutorial.\n\nTherefore, I decided to update that tutorial to include more characters, as well as to show you how to find data for your favorite character.\n\nOther topics that we will cover here include, but are not limited to, how to train the model, how to deploy the model, common errors you might see during this model training and deployment pipeline, and how to solve them.\n\nMoreover, we will cover how to build the bot in Python and how to build it in JavaScript.\n\nLastly, we will cover how to properly deploy the bot to a Discord server and limit it to certain channels and how to keep the bot running indefinitely. I hope you're excited and let's jump into the tutorial.\n\nFirst, we are going to find data for our character.\n\nMy favorite sources are Kaggle, Transcript Wiki, and just random fandom websites that came out from the Google search. And my research process goes like this. I first search on Kaggle to see if there are pre-made dialogue data sets.\n\nFor example, if we search for Rick and Morty,\n\nwe get this nicely formatted data set that includes the name of the character and the line they're speaking.\n\nIf we search for Harry Potter,\n\nhere is another data set that includes the character and the sentence they're speaking.\n\nSince we're building a chatbot, we need only these two columns in our data set, the character name and the line they're speaking. So these dialogue data sets on Kaggle are perfect for our requirement.\n\nAll right, if we succeeded in finding our data on Kaggle, we can move on to the model training step. But what if we cannot find a data set for our character on Kaggle? For example, if I want to find a data set for Peppa Pig,\n\nit looks like there is no data set for the character.\n\nIn this case, we may need to find the raw transcript of the media, be it a video game, a cartoon, or a show, and I've found that Transcript Wiki has some great resources.\n\nSo here we have a list of movies, shows, video games, musicals, commercials.\n\nFor example, I was able to find a transcript for Peppa Pig and also movies like Batman on Transcript Wiki.\n\nThe transcript looks like this.\n\nSo we have the character name and their actions or the lines they're speaking. We will see shortly how to turn a raw transcript like this into a data set like those we saw on Kaggle.\n\nBesides Transcript Wiki, you may also just Google the name of your media with the keyword transcript. For example, my first bot was based on the game, The Word Ends With You, and it has no results either on Kaggle or Transcript Wiki. So what I did was to just Google the name of the game and game transcript.\n\nAnd it just happened that this fandom website has the full game transcript. So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fictional character, you are more interested in real-life character, you may search for interview scripts as your data source. If you want to create a chatbot that speaks like yourself or your friends, you can treat text messages between you and your friends as dialogues and handcraft your data set.\n\nThere are tons of ways to get data for your character, so be creative. And now we will look at how to turn raw transcript into data set.\n\nNow, suppose we have found our raw transcript, let's see how we can turn it into a two-column character line data set. Suppose we take this Peppa Pig transcript and copy them into a text file.\n\nNow we go to Google Colab and upload our data file.\n\nThen we create a Google Colab notebook\n\nand use this to parse our script. So I'm going to name this parse script.ipynb. And we are going to from Google Colab import drive and then call drive.mount content drive.\n\nThis will allow us to read the data from our Google Drive.\n\nAll right, now that our drive has been mounted, let's import OS and then OS change directory into content drive my drive.\n\nAnd now we see if there is anything in it. Yeah, we have our PeppaPig.txt. So here we are going to import regular expression to parse our transcript, put the parsed result into a Pandas data frame, and export it as a CSV file, just like those we saw on Kaggle.\n\nThis is going to be our regular expression pattern.\n\nYou don't have to be a pro in regular expression to understand this part. If we take the pattern to this site,\n\nand our test string is Peppa Pig,\n\nyou will see that we have two match capture groups, the first being the character's name, the second being the line spoken, and also for the second line, Mama Pig, we have the character name and the line being spoken.\n\nGreat, so that's our regular expression. Now, let's define a dictionary that will store our data. So we know that we need the column name and the column line in our result data frame.\n\nAnd now we open and read the file.\n\nFor each line, we match it with our regular expression pattern.\n\nIf there is a match, we extract name and line from this regular expression match, and then append it to our dictionary here.\n\nAnd then we convert this dictionary into a data frame.\n\nNow we can inspect the data frame. Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and Mama Pig makes a sound. Great.\n\nWe can also count the number of lines that belong to our character. So we do sum DF name is equal to Peppa Pig,\n\nand we saw that Peppa Pig has 38 lines in our entire data frame.\n\nSo the length of our data frame is over 100 and Peppa Pig has one-third of the lines. Great. The last step will be to export the data frame. So DF.to_csv, the name will be PeppaPig.csv, and and we will drop the index. Cool. Now we should have a PeppaPig.csv in our drive.\n\nAnd here it is, name and line. This is how we parse those raw transcripts into a file that could be used in our model training. So next, let's proceed on to the exciting step, model training.\n\nNow we are going to train the model. Go to my GitHub repository linked to in the description below and download the content.\n\nWe are going to use this model train upload workflow.ipynb, which looks like this.\n\nAll right, now our file has been downloaded. We unzip the content.\n\nAnd in here, we have a model train upload workflow.ipynb.\n\nWe upload this notebook file to Google Drive and open it in Google Colab.\n\nWe're going to train a GPT model, which is short for Generative Pre-trained Transformer. In the runtime, change runtime type. Make sure to select GPU because this will accelerate our model training.\n\nSo now here, we mount the drive.\n\nWe install the Transformers module that we will be using,\n\nand we change directory into my drive.\n\nHere are all the modules that we are importing.\n\nIf we're using the data set from Kaggle, we need to obtain our API key from Kaggle.\n\nSo go to our Kaggle profile, go to account,\n\nscroll down to the API key section, create a new API token, and download this file as kaggle.json.\n\nWe will go back to Google Drive and upload kaggle.json.\n\nNow we can download our data set from Kaggle. We're going to use the Harry Potter data set as an example.\n\nSo grab this username and the data set name, and our file is Harry Potter 1.csv.\n\nNote that because there are white spaces in our file name, we got special characters in the file name. So let's inspect the content of our data file.\n\nWell, CSV files are usually separated by commas, has the name CSV. However, this one looks like it's separated by semicolons. So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. So separation is semicolon instead of a comma. Cool. So let's sample our data to see what's inside.\n\nAll right, so we have character and sentence.\n\nNotice that these two column names aren't exactly what we need. We want the two columns of our data frame to be named as name and line, as used down here in this cell. So we need to change the name of our columns.\n\nAll right, let's resample our data. Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is.\n\nSo it only has a thousand or so lines, and let's see how many lines our character has.\n\nOur character has 155 lines. So here, we change our character name to Harry,\n\nand we now run this cell to create a context data frame that includes the current line our character is speaking and several lines directly preceding the line.\n\nA context data frame is useful here because we are creating a conversational chatbot, and we want to generate a response based on the conversation context.\n\nSo let's sample our context data frame. So in the context of clearly something something, our character responds with seems a pity not to ask her.\n\nGreat. Now we have our data set. We split the data set into a training set and a test set. This is because we don't want to overfit the model. In the case of overfitting, the model will just memorize lines from the data set and talk back to us using the exact lines. We don't want that. We want the conversation to be more organic.\n\nSo we're only training the model on the training set and evaluating the model on the test set.\n\nSo we continue running these cells to build data sets, caching checkpoints, and down here we build the model. We will build our model by fine-tuning Microsoft's pre-trained GPT small.\n\nSmall here refers to the number of parameters in the model. There are also a medium and a large model. Generally, the larger the model, the longer it takes to train, but the smarter the model can get.\n\nI would recommend training a medium model as it's pretty smart and not too hard to train. My production chatbot that is currently running on a server with a thousand plus users is also a medium model. For this tutorial, for the sake of time, I'm training just a small model.\n\nYou can see here it's downloading the model, and this may take some time because it's essentially 300 MB.\n\nHere are some hyperparameters that you may find useful. For example, num train epochs is the number of training epochs. This is defined to be four here, and this is the number of times that the model will cycle through the training set. As long as the model is not overfitting, increasing the number of training epochs usually results in smarter models because the model has more time to cycle through the data set and pick up the nitty-gritty details.\n\nThere is another hyperparameter called the batch size. This is the number of training examples that the model will see in a batch before it updates its gradient. I wouldn't recommend changing this unless you know what you're doing since other hyperparameters like learning rate and temperature might be sensitive to this change in batch size. However, if you're training a larger model on a larger data set and are running into memory errors, to make the error go away, it might help to decrease the batch size.\n\nThe remaining cells have been configured to take in this context data frame we created, train the model, and save it to a folder called output small.\n\nNow let's run this main function.\n\nTraining will take some time. I trained my medium model for 12 epochs, and it took around two hours. So do sit back and grab a snack while the model is training.\n\nYou can see the progress in the progress bars above.\n\nAll right, here we get back a perplexity answer. This usually refers to how confused the model is. If a model has a large perplexity, it means that the model is pretty confused as to which words to choose to respond to a given situation, and the model might not be very smart. In our case, our data set is pretty small and only has 150 plus lines, so it makes sense that the perplexity is high. To decrease the perplexity, we might need to train for more epochs. Cool. But now that the training is complete, we can load and chat with the model here.\n\nAll right, let's change the name of the bot.\n\nHello, fellow red writer. So let's ask,\n\nHow's\n\ncreated?\n\nThere is no such thing as a bad red writer.\n\nGreat. It looks like our chatbot is capable of making and maintaining a conversation.\n\nNow we can push the model to Hugging Face and start building our Discord chatbot.\n\nAll right, now let's change directory just into the content folder because we'll be doing our push there, and we do pip install Hugging Face command line client, and then we log in using our credentials.\n\nAll right, after logging, we're assigned this token. We need to grab this token for the cell that we need to do afterwards. So we can create a repository to store our model from the command line. Mine is going to be called dialogue GPT small Harry Potter.\n\nAnd our empty model repository is right here. There is nothing except for the Git attributes file, but we will be adding the model files soon.\n\nNow we install Git LFS, which stands for Git Large File Storage. This will allows us to push and pull our models, and we replace this token with the token we just copied from above.\n\nSo here's my username and my token.\n\nAnd we call that our training result is stored in this output small directory.\n\nAnd now we change directory into our dialogue GPT small directory because we need to do Git add and commit from there. We install the Git LFS,\n\nand inspect the content of our current directory, which should be dialogue GPT small Harry Potter, and also just print out the working directory we are in to make sure that we are inside content. Cool. Now we check the file status on Git. So these files that we need to add to Git.\n\nSo we do Git add. This will take some time because the PyTorch model.bin is pretty large, and we configure the global username and user email. These are just my Hugging Face credentials,\n\nand we commit with message initial commit, and finally we push the model.\n\nIt's about 400 MB because the PyTorch model is itself about 400 MB.\n\nAll right, looks like the push is complete.\n\nNow we see our PyTorch model here. However, there's one more thing that we need to do before we can converse with the model on Hugging Face. That is, you see here, it's tagged as text generation. However, we know that we are training a chatbot model, and we want our model to be conversational. For that purpose, we need to add a model card.\n\nSo we create a model card here, and we're putting in our desired model tags. So our tag is conversational.\n\nAnd we commit our model card. And now our model is correctly tagged as conversational. If we go to the main model page, we can start chatting with the model here.\n\nAll right. Now that we have pushed our model to Hugging Face, we're ready to use it in our Discord chatbot.\n\nNow we have our model. Let's build the Discord bot. Here, on Discord, I have my server, Lynn's Dev Lab. I have two channels, one for the Python bot and one for the JavaScript bot.\n\nThe reason why we have separate channel for the bots is because we don't want the bots to be talking to each other.\n\nSo after we build the bot, we will learn how to set their permissions correctly so that they don't go outside of their dedicated channel.\n\nSo we go to Discord's developers page, create an application. We need one application per bot.\n\nSo our name will be ChattyBot Python.\n\nSo here we create a bot,\n\nand I'm going to name this Harry Potter bot Python and upload an icon.\n\nWe will be using this API token here when we create our bot in Python. We're going to host our bot on Repl.it. So sign up for Repl.it and create a new Python Repl here. Going to name this ChattyBot Python.\n\nAnd in here, we will need to store our API tokens for Hugging Face and Discord as environmental variables. So here is a tab for the secrets for the environment variables. So the first one will be Hugging Face token,\n\nand for the value, we will go to our Hugging Face profile, edit profile, API tokens, copy the API token, come back here,\n\nand fill in the value. Next, we'll create a Discord token,\n\nand for this value, we go to this Discord developers portal and copy the token. We add the token here,\n\nand our environment variables are all set.\n\nNext, I have the Python file in my GitHub repository called Discord bot.py.\n\nSo we grab the code from here, and I will explain the code line by line.\n\nStarting from line one, we first import the OS module that will help us reading our environment variables.\n\nNext, we import modules that are useful for querying the Hugging Face model.\n\nFinally, we import the Discord module, and here I have my API URL pointing to my username,\n\nand we define a bot as follows. In the on ready function,\n\nit takes in a model name, which for me will be dialogue GPT small Harry Potter.\n\nThen we store this API endpoint by concatenating this API URL, which is my profile link, with the model name. Then we retrieve the secret API token from the system environment by looking up OS.environment Hugging Face token.\n\nNext, we format the header in our request to Hugging Face. For the authorization part, we put in bearer and the Hugging Face token.\n\nNext, we define a query method that takes in the payload. We dump the payload as a JSON string,\n\nand use the request module to make an HTTP post request to the API endpoint using our defined request headers, which contains our Hugging Face API key and passing in the data.\n\nOnce the request finishes, it should give us a response object, and we decode it from UTF-8 and load the result as a string and return the string.\n\nNext, we define an asynchronous function named on ready. The next two function definitions are based on the Discord API. Both are asynchronous function. The first one is on ready. This function will be called when the bot is logging in.\n\nSo when the bot is logging in, we will print out logged in as, print out the bot's name and the bot's ID so that we know that the bot is functioning.\n\nNext, because our bot is a chatbot, it needs to respond to messages. So on message is a method that will be called each time the bot sees a message in the channel. So given the message, if the message is coming from the bot itself, the bot ignores the message and does not reply to it.\n\nOtherwise, it will form a query payload with the content of the message. And to make the bot more user-friendly, while the bot is waiting for the HTTP response from the model, we set its status as typing so that the user will know that the bot is generating its response.\n\nSo this is an asynchronous call with message.channel.typing. We call self.query using the payload and get back the response.\n\nIf there is a valid generated response, there will be a generated text field in this response, and we'll be able to get that out as the bot's response. Otherwise, there might be an error in the response. We just log out the error message so that we can debug the bot later on.\n\nFinally, we use another asynchronous method to send the bot's response to the channel using message.channel.send.\n\nAnd that's it about our bot definition. In the main function, we just create a bot and pass in the model name. So for me, this is dialogue GPT small Harry Potter,\n\nand use client.run looking up the Discord token from the environment variables. Great. Now that our bot should be all set up, let's invite the bot to our channel.\n\nIn the OAuth2 tab, we are going to select the bot,\n\nand for the bot permissions,\n\nthe only thing it needs is to send messages.\n\nSo we copy this URL, paste it in a new browser window,\n\nand invite it to my server.\n\nAll right. Now that we see that our bot has appeared. However, it shows as offline. So we need to run the Repl.\n\nSo we hit run here,\n\nand Repl.it is installing all our dependencies and imports.\n\nGreat. Now that our bot has logged in as Harry Potter bot Python, and this is its unique ID. Let's go to the server, and now that the bot is online.\n\nI don't want the bot to appear in the general channel, so we go to the channel setting, permissions, advanced permissions, add the bot,\n\nand we remove its permission to send messages and save the changes.\n\nNow, let's see what happens if I type something in the general channel. Nothing should happen because the bot shouldn't be able to send a message.\n\nNothing happens although the bot is online. And now this bot should work in this Python bot channel, so let's do hello.\n\nAnd we briefly saw that there's a typing prompt.\n\nCool. So yeah, this is how we built a bot in Python. One thing to know in our Repl.it is that because we took away the bot's permission to send messages in the general channel, it is showing an exception, and this is totally okay. If you don't like seeing this exception, you can use a try except block and log out this exception.\n\nGreat. So now we're going to repeat the process for the JavaScript bot. So we go back to the Discord developer portal,\n\nand create new application. This time, I'm going to call it ChattyBot JavaScript.\n\nAnd we'll create a bot.\n\nBack to Repl.it, we create a Node.js app. Going to call it ChattyBot.js.\n\nWe again create two environmental variables. The first one is Hugging Face token,\n\ncopying my API token from my profile, edit profile, putting here,\n\nand copy my Discord bot token. Call this one Discord token, and adding the value.\n\nGreat. Now we have our environment variables set up. Go to my GitHub repository. There is a Discord bot.js file that contains the code that we will use for this JavaScript chatbot. Let's copy paste, and I will go through the code line by line.\n\nSo first, we import the Discord API for the JavaScript module, and we import fetch for making HTTP requests, just like we did in Python, and we initialize a new Discord client and define the model URL just as my username and the model name. So this guy is dialogue GPT small Harry Potter.\n\nAnd this is the same callback that is called when the bot is ready, just like the on ready function we saw in Python. So when the bot is ready and logged in, we print out logged in as client.user.tag.\n\nAnd here is another callback, this time on message. We use an asynchronous callback because we are making HTTP requests.\n\nLike in the Python script, we ignore the message if the message is from the bot itself by checking if message.author is the bot.\n\nNow we form the payload. So the payload is a dictionary containing inputs with text message.content, which is the message that the bot has received,\n\nand we form the request headers by again using the Hugging Face API key. So we read the Hugging Face token from the environment, process.env.HuggingFaceToken,\n\nand form the headers. Right before we start making the HTTP request, we set the bot status to typing.\n\nNow we query the server. So the response is the result from this call to fetch using HTTP post, given the payload as the body and the headers using the Hugging Face token,\n\nand we convert the response into JSON format and extract out the generated text field. If there isn't a generated text field in the response, but instead the response contains an error field, this means that the bot has encountered some errors, and we may want to print out the error for further debugging.\n\nNow that we have the bot's response, we can clear out its typing status and send the message to the channel as a reply.\n\nThis ends the definition of our client.on message call. Down here, we log in using the Discord token.\n\nNow let's invite the bot to our server. So we go to OAuth,\n\ncheck the bot. It's only permission is to send messages. We copy this,\n\npaste in a new browser window, and invite it to our server.\n\nGreat. Looks like we have another bot.\n\nRemember to click on save changes. Otherwise, the bot's icon wouldn't be showing. Now that we have our bot, however, it's not logged in.\n\nSo we need to go back to Repl to run our script. But before we run our Repl, let's make sure that the bot doesn't have access to the general channel, nor does it have access to the Python channel because it's not supposed to go there.\n\nSo in permissions,\n\nwe find this ChattyBot JavaScript,\n\nremove its permission to send messages, and always remember to save the changes. We do the same thing for it on the Python channel.\n\nAnd go to the JS channel. This time, the one we need to remove is the Python bot.\n\nSo this Python bot shouldn't be able to send messages to this JavaScript channel.\n\nNow we go back to run our Repl.it.\n\nIf you see this error, this means that the Discord version.npm is trying to install is wrong. You can see that there are those warnings that the newest Discord module is not compatible with Repl.it's version of Node or npm. So we need to manually change something in package.json.\n\nSo here, we just use the older version and rerun it.\n\nNow that we are logged in as ChattyBot JavaScript 1048, let's go back to our Discord channel. Cool. The ChattyBot is also online. Let's see if it responds to our messages.\n\nAll right, so this is now an error message telling us that the model is still loading. The model will usually take one or two minutes to load, so let's give it some time.\n\nGreat. Looks like our bot is responding to us.\n\nAnd because we have set the bot's permissions correctly, the Python bot is not responding to any messages here, and the JavaScript bot shouldn't be able to talk here.\n\nAnd in our general channel, no bot is ever allowed to talk here. Cool. So now we have successfully built the bot both in Python and in JavaScript.\n\nOne thing to note is that if I close the browser tab\n\nfor the Python bot,\n\nthe bot is no longer responding, although it still shows that the bot is online.\n\nSo in the next part, we're going to look at how to keep the bot running indefinitely in the browser, even when we close the browser tab.\n\nIn order to get our bot to run indefinitely, we need to create a web server in Repl.it and set up a service called Uptime Robot to continuously ping the web server.\n\nSo this is for the Python bot, and we create a new file called keep alive.py.\n\nAnd we add the code for a web server like this,\n\nand in our main.py, we import that part.\n\nAnd down here in the main function, right before the bot runs,\n\nwe ask it to be kept alive,\n\nand we run it.\n\nWhen the code runs, we see a URL shown in this tab, and we copy this URL and bring it to our Uptime Robot service.\n\nSo here is the Uptime Robot website, and I already have an account, so I'll just go to my dashboard and add a new monitor. Monitor type is going to be HTTPS, friendly name Discord Python bot, the URL is the one we copied from here,\n\nand the monitoring level will be a ping every five minutes. That should be sufficient, and finally we create monitor.\n\nAnd close it. Now let's see if our Python bot is capable of running indefinitely.\n\nAll right, I'm going to close this tab containing my Python script.\n\nAnd it looks like our model is still up. It's just that after some time, the model on Hugging Face backend will reload. But because the bot itself is responding, we know that our web server approach has worked.\n\nNow let's repeat this process for the JavaScript bot.\n\nWe create a new file called server.js,\n\nand copy paste this code.\n\nThen we import this part from the file that we just created.\n\nFinally, right before the bot runs, we are going to call keep alive. We stop the service,\n\nand run it. All right, the server is now ready. We copy this URL, go to Uptime Robot,\n\nand add a new monitor. It's again an HTTP monitor, Discord JS bot, and the URL is like this,\n\nand we create a monitor.\n\nNow we can safely close this browser window and go back to our Discord chat.\n\nAnd the bot is still running.\n\nGreat. Now we're all done. We have a cool Python chatbot and a cool JavaScript chatbot that can run indefinitely.\n\nI hope you enjoyed this video. Please subscribe for more content like this, and I'll see you in the next one.",
    "segments": [
      {
        "start": 0.0,
        "end": 30.19,
        "text": "Want to make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you want to make it talk like another favorite character. In this course, Lynn will show you how to create a Discord bot that uses artificial intelligence"
      },
      {
        "start": 29.71,
        "end": 59.91,
        "text": "to talk like a character of your choice. Hi there. I'm Lynn. I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago. In this tutorial, we're going to build a Discord AI chatbot that can speak like your favorite character."
      },
      {
        "start": 59.43,
        "end": 89.62,
        "text": "Before we start, if you have seen that video by any chance, know that this video is something different and more comprehensive. So keep watching till the end. The original tutorial and my first Discord bot started as a joke between me and my friends"
      },
      {
        "start": 89.14,
        "end": 119.34,
        "text": "when we were playing video games, and it really surprised me how popular it became, and a lot of people wanted to build their own bot based on that tutorial. Therefore, I decided to update that tutorial to include more characters, as well as to"
      },
      {
        "start": 118.86,
        "end": 149.05,
        "text": "show you how to find data for your favorite character. Other topics that we will cover here include, but are not limited to, how to train the model, how to deploy the model, common errors you might see during this model training and deployment pipeline,"
      },
      {
        "start": 148.57,
        "end": 178.76,
        "text": "and how to solve them. Moreover, we will cover how to build the bot in Python and how to build it in JavaScript. Lastly, we will cover how to properly deploy the bot to a Discord server and limit it to certain channels and how"
      },
      {
        "start": 178.29,
        "end": 208.48,
        "text": "to keep the bot running indefinitely. I hope you're excited and let's jump into the tutorial. First, we are going to find data for our character. My favorite sources are Kaggle, Transcript Wiki, and just random fandom websites that came out from the Google search."
      },
      {
        "start": 208.0,
        "end": 238.19,
        "text": "And my research process goes like this. I first search on Kaggle to see if there are pre-made dialogue data sets. For example, if we search for Rick and Morty, we get this nicely formatted data set that includes the name of the character and"
      },
      {
        "start": 237.72,
        "end": 267.91,
        "text": "the line they're speaking. If we search for Harry Potter, here is another data set that includes the character and the sentence they're speaking. Since we're building a chatbot, we need only these two columns in our data set, the character name and the line"
      },
      {
        "start": 267.43,
        "end": 297.62,
        "text": "they're speaking. So these dialogue data sets on Kaggle are perfect for our requirement. All right, if we succeeded in finding our data on Kaggle, we can move on to the model training step. But what if we cannot find a data set for our"
      },
      {
        "start": 297.15,
        "end": 327.34,
        "text": "character on Kaggle? For example, if I want to find a data set for Peppa Pig, it looks like there is no data set for the character. In this case, we may need to find the raw transcript of the media, be it a video"
      },
      {
        "start": 326.86,
        "end": 357.05,
        "text": "game, a cartoon, or a show, and I've found that Transcript Wiki has some great resources. So here we have a list of movies, shows, video games, musicals, commercials. For example, I was able to find a transcript for Peppa Pig and also movies like"
      },
      {
        "start": 356.58,
        "end": 386.77,
        "text": "Batman on Transcript Wiki. The transcript looks like this. So we have the character name and their actions or the lines they're speaking. We will see shortly how to turn a raw transcript like this into a data set like those we saw on Kaggle."
      },
      {
        "start": 386.29,
        "end": 416.48,
        "text": "Besides Transcript Wiki, you may also just Google the name of your media with the keyword transcript. For example, my first bot was based on the game, The Word Ends With You, and it has no results either on Kaggle or Transcript Wiki. So what"
      },
      {
        "start": 416.01,
        "end": 446.2,
        "text": "I did was to just Google the name of the game and game transcript. And it just happened that this fandom website has the full game transcript. So be sure to utilize your Google search skills to find data for your character. If, rather than"
      },
      {
        "start": 445.72,
        "end": 475.91,
        "text": "fictional character, you are more interested in real-life character, you may search for interview scripts as your data source. If you want to create a chatbot that speaks like yourself or your friends, you can treat text messages between you and your friends as dialogues"
      },
      {
        "start": 475.44,
        "end": 505.63,
        "text": "and handcraft your data set. There are tons of ways to get data for your character, so be creative. And now we will look at how to turn raw transcript into data set. Now, suppose we have found our raw transcript, let's see how we"
      },
      {
        "start": 505.15,
        "end": 535.34,
        "text": "can turn it into a two-column character line data set. Suppose we take this Peppa Pig transcript and copy them into a text file. Now we go to Google Colab and upload our data file. Then we create a Google Colab notebook and use this"
      },
      {
        "start": 534.86,
        "end": 565.06,
        "text": "to parse our script. So I'm going to name this parse script.ipynb. And we are going to from Google Colab import drive and then call drive.mount content drive. This will allow us to read the data from our Google Drive. All right, now that our"
      },
      {
        "start": 564.58,
        "end": 594.77,
        "text": "drive has been mounted, let's import OS and then OS change directory into content drive my drive. And now we see if there is anything in it. Yeah, we have our PeppaPig.txt. So here we are going to import regular expression to parse our transcript,"
      },
      {
        "start": 594.29,
        "end": 624.49,
        "text": "put the parsed result into a Pandas data frame, and export it as a CSV file, just like those we saw on Kaggle. This is going to be our regular expression pattern. You don't have to be a pro in regular expression to understand this"
      },
      {
        "start": 624.01,
        "end": 654.2,
        "text": "part. If we take the pattern to this site, and our test string is Peppa Pig, you will see that we have two match capture groups, the first being the character's name, the second being the line spoken, and also for the second line, Mama"
      },
      {
        "start": 653.72,
        "end": 683.92,
        "text": "Pig, we have the character name and the line being spoken. Great, so that's our regular expression. Now, let's define a dictionary that will store our data. So we know that we need the column name and the column line in our result data frame."
      },
      {
        "start": 683.44,
        "end": 713.63,
        "text": "And now we open and read the file. For each line, we match it with our regular expression pattern. If there is a match, we extract name and line from this regular expression match, and then append it to our dictionary here. And then we"
      },
      {
        "start": 713.15,
        "end": 743.34,
        "text": "convert this dictionary into a data frame. Now we can inspect the data frame. Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and Mama Pig makes a sound. Great. We can also count"
      },
      {
        "start": 742.87,
        "end": 773.06,
        "text": "the number of lines that belong to our character. So we do sum DF name is equal to Peppa Pig, and we saw that Peppa Pig has 38 lines in our entire data frame. So the length of our data frame is over 100 and"
      },
      {
        "start": 772.58,
        "end": 802.77,
        "text": "Peppa Pig has one-third of the lines. Great. The last step will be to export the data frame. So DF.to_csv, the name will be PeppaPig.csv, and and we will drop the index. Cool. Now we should have a PeppaPig.csv in our drive. And here it"
      },
      {
        "start": 802.3,
        "end": 832.49,
        "text": "is, name and line. This is how we parse those raw transcripts into a file that could be used in our model training. So next, let's proceed on to the exciting step, model training. Now we are going to train the model. Go to my"
      },
      {
        "start": 832.01,
        "end": 862.2,
        "text": "GitHub repository linked to in the description below and download the content. We are going to use this model train upload workflow.ipynb, which looks like this. All right, now our file has been downloaded. We unzip the content. And in here, we have a model"
      },
      {
        "start": 861.73,
        "end": 891.92,
        "text": "train upload workflow.ipynb. We upload this notebook file to Google Drive and open it in Google Colab. We're going to train a GPT model, which is short for Generative Pre-trained Transformer. In the runtime, change runtime type. Make sure to select GPU because this will"
      },
      {
        "start": 891.44,
        "end": 921.63,
        "text": "accelerate our model training. So now here, we mount the drive. We install the Transformers module that we will be using, and we change directory into my drive. Here are all the modules that we are importing. If we're using the data set from Kaggle,"
      },
      {
        "start": 921.16,
        "end": 951.35,
        "text": "we need to obtain our API key from Kaggle. So go to our Kaggle profile, go to account, scroll down to the API key section, create a new API token, and download this file as kaggle.json. We will go back to Google Drive and upload"
      },
      {
        "start": 950.87,
        "end": 981.06,
        "text": "kaggle.json. Now we can download our data set from Kaggle. We're going to use the Harry Potter data set as an example. So grab this username and the data set name, and our file is Harry Potter 1.csv. Note that because there are white spaces"
      },
      {
        "start": 980.59,
        "end": 1010.78,
        "text": "in our file name, we got special characters in the file name. So let's inspect the content of our data file. Well, CSV files are usually separated by commas, has the name CSV. However, this one looks like it's separated by semicolons. So we need"
      },
      {
        "start": 1010.3,
        "end": 1040.49,
        "text": "to take care of the semicolons when we are reading in the data into a Pandas data frame. So separation is semicolon instead of a comma. Cool. So let's sample our data to see what's inside. All right, so we have character and sentence. Notice"
      },
      {
        "start": 1040.02,
        "end": 1070.21,
        "text": "that these two column names aren't exactly what we need. We want the two columns of our data frame to be named as name and line, as used down here in this cell. So we need to change the name of our columns. All right,"
      },
      {
        "start": 1069.73,
        "end": 1099.92,
        "text": "let's resample our data. Looks like we have successfully changed the name of our columns. Now let's see how big our data is. So it only has a thousand or so lines, and let's see how many lines our character has. Our character has 155"
      },
      {
        "start": 1099.44,
        "end": 1129.64,
        "text": "lines. So here, we change our character name to Harry, and we now run this cell to create a context data frame that includes the current line our character is speaking and several lines directly preceding the line. A context data frame is useful here"
      },
      {
        "start": 1129.16,
        "end": 1159.35,
        "text": "because we are creating a conversational chatbot, and we want to generate a response based on the conversation context. So let's sample our context data frame. So in the context of clearly something something, our character responds with seems a pity not to ask her."
      },
      {
        "start": 1158.87,
        "end": 1189.07,
        "text": "Great. Now we have our data set. We split the data set into a training set and a test set. This is because we don't want to overfit the model. In the case of overfitting, the model will just memorize lines from the data set"
      },
      {
        "start": 1188.59,
        "end": 1218.78,
        "text": "and talk back to us using the exact lines. We don't want that. We want the conversation to be more organic. So we're only training the model on the training set and evaluating the model on the test set. So we continue running these cells"
      },
      {
        "start": 1218.3,
        "end": 1248.49,
        "text": "to build data sets, caching checkpoints, and down here we build the model. We will build our model by fine-tuning Microsoft's pre-trained GPT small. Small here refers to the number of parameters in the model. There are also a medium and a large model. Generally,"
      },
      {
        "start": 1248.02,
        "end": 1278.21,
        "text": "the larger the model, the longer it takes to train, but the smarter the model can get. I would recommend training a medium model as it's pretty smart and not too hard to train. My production chatbot that is currently running on a server with"
      },
      {
        "start": 1277.73,
        "end": 1307.92,
        "text": "a thousand plus users is also a medium model. For this tutorial, for the sake of time, I'm training just a small model. You can see here it's downloading the model, and this may take some time because it's essentially 300 MB. Here are some"
      },
      {
        "start": 1307.45,
        "end": 1337.64,
        "text": "hyperparameters that you may find useful. For example, num train epochs is the number of training epochs. This is defined to be four here, and this is the number of times that the model will cycle through the training set. As long as the model"
      },
      {
        "start": 1337.16,
        "end": 1367.35,
        "text": "is not overfitting, increasing the number of training epochs usually results in smarter models because the model has more time to cycle through the data set and pick up the nitty-gritty details. There is another hyperparameter called the batch size. This is the number of"
      },
      {
        "start": 1366.88,
        "end": 1397.07,
        "text": "training examples that the model will see in a batch before it updates its gradient. I wouldn't recommend changing this unless you know what you're doing since other hyperparameters like learning rate and temperature might be sensitive to this change in batch size. However, if"
      },
      {
        "start": 1396.59,
        "end": 1426.78,
        "text": "you're training a larger model on a larger data set and are running into memory errors, to make the error go away, it might help to decrease the batch size. The remaining cells have been configured to take in this context data frame we created,"
      },
      {
        "start": 1426.31,
        "end": 1456.5,
        "text": "train the model, and save it to a folder called output small. Now let's run this main function. Training will take some time. I trained my medium model for 12 epochs, and it took around two hours. So do sit back and grab a snack"
      },
      {
        "start": 1456.02,
        "end": 1486.21,
        "text": "while the model is training. You can see the progress in the progress bars above. All right, here we get back a perplexity answer. This usually refers to how confused the model is. If a model has a large perplexity, it means that the model"
      },
      {
        "start": 1485.74,
        "end": 1515.93,
        "text": "is pretty confused as to which words to choose to respond to a given situation, and the model might not be very smart. In our case, our data set is pretty small and only has 150 plus lines, so it makes sense that the perplexity"
      },
      {
        "start": 1515.45,
        "end": 1545.64,
        "text": "is high. To decrease the perplexity, we might need to train for more epochs. Cool. But now that the training is complete, we can load and chat with the model here. All right, let's change the name of the bot. Hello, fellow red writer. So"
      },
      {
        "start": 1545.17,
        "end": 1575.36,
        "text": "let's ask, How's created? There is no such thing as a bad red writer. Great. It looks like our chatbot is capable of making and maintaining a conversation. Now we can push the model to Hugging Face and start building our Discord chatbot. All right,"
      },
      {
        "start": 1574.88,
        "end": 1605.07,
        "text": "now let's change directory just into the content folder because we'll be doing our push there, and we do pip install Hugging Face command line client, and then we log in using our credentials. All right, after logging, we're assigned this token. We need to"
      },
      {
        "start": 1604.59,
        "end": 1634.79,
        "text": "grab this token for the cell that we need to do afterwards. So we can create a repository to store our model from the command line. Mine is going to be called dialogue GPT small Harry Potter. And our empty model repository is right here."
      },
      {
        "start": 1634.31,
        "end": 1664.5,
        "text": "There is nothing except for the Git attributes file, but we will be adding the model files soon. Now we install Git LFS, which stands for Git Large File Storage. This will allows us to push and pull our models, and we replace this token"
      },
      {
        "start": 1664.02,
        "end": 1694.22,
        "text": "with the token we just copied from above. So here's my username and my token. And we call that our training result is stored in this output small directory. And now we change directory into our dialogue GPT small directory because we need to do"
      },
      {
        "start": 1693.74,
        "end": 1723.93,
        "text": "Git add and commit from there. We install the Git LFS, and inspect the content of our current directory, which should be dialogue GPT small Harry Potter, and also just print out the working directory we are in to make sure that we are inside"
      },
      {
        "start": 1723.45,
        "end": 1753.65,
        "text": "content. Cool. Now we check the file status on Git. So these files that we need to add to Git. So we do Git add. This will take some time because the PyTorch model.bin is pretty large, and we configure the global username and user"
      },
      {
        "start": 1753.17,
        "end": 1783.36,
        "text": "email. These are just my Hugging Face credentials, and we commit with message initial commit, and finally we push the model. It's about 400 MB because the PyTorch model is itself about 400 MB. All right, looks like the push is complete. Now we see"
      },
      {
        "start": 1782.88,
        "end": 1813.07,
        "text": "our PyTorch model here. However, there's one more thing that we need to do before we can converse with the model on Hugging Face. That is, you see here, it's tagged as text generation. However, we know that we are training a chatbot model, and"
      },
      {
        "start": 1812.6,
        "end": 1842.79,
        "text": "we want our model to be conversational. For that purpose, we need to add a model card. So we create a model card here, and we're putting in our desired model tags. So our tag is conversational. And we commit our model card. And now"
      },
      {
        "start": 1842.31,
        "end": 1872.5,
        "text": "our model is correctly tagged as conversational. If we go to the main model page, we can start chatting with the model here. All right. Now that we have pushed our model to Hugging Face, we're ready to use it in our Discord chatbot. Now"
      },
      {
        "start": 1872.03,
        "end": 1902.22,
        "text": "we have our model. Let's build the Discord bot. Here, on Discord, I have my server, Lynn's Dev Lab. I have two channels, one for the Python bot and one for the JavaScript bot. The reason why we have separate channel for the bots is"
      },
      {
        "start": 1901.74,
        "end": 1931.93,
        "text": "because we don't want the bots to be talking to each other. So after we build the bot, we will learn how to set their permissions correctly so that they don't go outside of their dedicated channel. So we go to Discord's developers page, create"
      },
      {
        "start": 1931.46,
        "end": 1961.65,
        "text": "an application. We need one application per bot. So our name will be ChattyBot Python. So here we create a bot, and I'm going to name this Harry Potter bot Python and upload an icon. We will be using this API token here when we"
      },
      {
        "start": 1961.17,
        "end": 1991.36,
        "text": "create our bot in Python. We're going to host our bot on Repl.it. So sign up for Repl.it and create a new Python Repl here. Going to name this ChattyBot Python. And in here, we will need to store our API tokens for Hugging Face"
      },
      {
        "start": 1990.89,
        "end": 2021.08,
        "text": "and Discord as environmental variables. So here is a tab for the secrets for the environment variables. So the first one will be Hugging Face token, and for the value, we will go to our Hugging Face profile, edit profile, API tokens, copy the API"
      },
      {
        "start": 2020.6,
        "end": 2050.79,
        "text": "token, come back here, and fill in the value. Next, we'll create a Discord token, and for this value, we go to this Discord developers portal and copy the token. We add the token here, and our environment variables are all set. Next, I have"
      },
      {
        "start": 2050.32,
        "end": 2080.51,
        "text": "the Python file in my GitHub repository called Discord bot.py. So we grab the code from here, and I will explain the code line by line. Starting from line one, we first import the OS module that will help us reading our environment variables. Next,"
      },
      {
        "start": 2080.03,
        "end": 2110.22,
        "text": "we import modules that are useful for querying the Hugging Face model. Finally, we import the Discord module, and here I have my API URL pointing to my username, and we define a bot as follows. In the on ready function, it takes in a"
      },
      {
        "start": 2109.75,
        "end": 2139.94,
        "text": "model name, which for me will be dialogue GPT small Harry Potter. Then we store this API endpoint by concatenating this API URL, which is my profile link, with the model name. Then we retrieve the secret API token from the system environment by looking"
      },
      {
        "start": 2139.46,
        "end": 2169.65,
        "text": "up OS.environment Hugging Face token. Next, we format the header in our request to Hugging Face. For the authorization part, we put in bearer and the Hugging Face token. Next, we define a query method that takes in the payload. We dump the payload as"
      },
      {
        "start": 2169.17,
        "end": 2199.37,
        "text": "a JSON string, and use the request module to make an HTTP post request to the API endpoint using our defined request headers, which contains our Hugging Face API key and passing in the data. Once the request finishes, it should give us a response"
      },
      {
        "start": 2198.89,
        "end": 2229.08,
        "text": "object, and we decode it from UTF-8 and load the result as a string and return the string. Next, we define an asynchronous function named on ready. The next two function definitions are based on the Discord API. Both are asynchronous function. The first one"
      },
      {
        "start": 2228.6,
        "end": 2258.8,
        "text": "is on ready. This function will be called when the bot is logging in. So when the bot is logging in, we will print out logged in as, print out the bot's name and the bot's ID so that we know that the bot is"
      },
      {
        "start": 2258.32,
        "end": 2288.51,
        "text": "functioning. Next, because our bot is a chatbot, it needs to respond to messages. So on message is a method that will be called each time the bot sees a message in the channel. So given the message, if the message is coming from the"
      },
      {
        "start": 2288.03,
        "end": 2318.22,
        "text": "bot itself, the bot ignores the message and does not reply to it. Otherwise, it will form a query payload with the content of the message. And to make the bot more user-friendly, while the bot is waiting for the HTTP response from the model,"
      },
      {
        "start": 2317.75,
        "end": 2347.94,
        "text": "we set its status as typing so that the user will know that the bot is generating its response. So this is an asynchronous call with message.channel.typing. We call self.query using the payload and get back the response. If there is a valid generated response,"
      },
      {
        "start": 2347.46,
        "end": 2377.65,
        "text": "there will be a generated text field in this response, and we'll be able to get that out as the bot's response. Otherwise, there might be an error in the response. We just log out the error message so that we can debug the bot"
      },
      {
        "start": 2377.18,
        "end": 2407.37,
        "text": "later on. Finally, we use another asynchronous method to send the bot's response to the channel using message.channel.send. And that's it about our bot definition. In the main function, we just create a bot and pass in the model name. So for me, this is"
      },
      {
        "start": 2406.89,
        "end": 2437.08,
        "text": "dialogue GPT small Harry Potter, and use client.run looking up the Discord token from the environment variables. Great. Now that our bot should be all set up, let's invite the bot to our channel. In the OAuth2 tab, we are going to select the bot,"
      },
      {
        "start": 2436.61,
        "end": 2466.8,
        "text": "and for the bot permissions, the only thing it needs is to send messages. So we copy this URL, paste it in a new browser window, and invite it to my server. All right. Now that we see that our bot has appeared. However, it"
      },
      {
        "start": 2466.32,
        "end": 2496.51,
        "text": "shows as offline. So we need to run the Repl. So we hit run here, and Repl.it is installing all our dependencies and imports. Great. Now that our bot has logged in as Harry Potter bot Python, and this is its unique ID. Let's go"
      },
      {
        "start": 2496.04,
        "end": 2526.23,
        "text": "to the server, and now that the bot is online. I don't want the bot to appear in the general channel, so we go to the channel setting, permissions, advanced permissions, add the bot, and we remove its permission to send messages and save the"
      },
      {
        "start": 2525.75,
        "end": 2555.94,
        "text": "changes. Now, let's see what happens if I type something in the general channel. Nothing should happen because the bot shouldn't be able to send a message. Nothing happens although the bot is online. And now this bot should work in this Python bot channel,"
      },
      {
        "start": 2555.47,
        "end": 2585.66,
        "text": "so let's do hello. And we briefly saw that there's a typing prompt. Cool. So yeah, this is how we built a bot in Python. One thing to know in our Repl.it is that because we took away the bot's permission to send messages in"
      },
      {
        "start": 2585.18,
        "end": 2615.37,
        "text": "the general channel, it is showing an exception, and this is totally okay. If you don't like seeing this exception, you can use a try except block and log out this exception. Great. So now we're going to repeat the process for the JavaScript bot."
      },
      {
        "start": 2614.9,
        "end": 2645.09,
        "text": "So we go back to the Discord developer portal, and create new application. This time, I'm going to call it ChattyBot JavaScript. And we'll create a bot. Back to Repl.it, we create a Node.js app. Going to call it ChattyBot.js. We again create two environmental"
      },
      {
        "start": 2644.61,
        "end": 2674.8,
        "text": "variables. The first one is Hugging Face token, copying my API token from my profile, edit profile, putting here, and copy my Discord bot token. Call this one Discord token, and adding the value. Great. Now we have our environment variables set up. Go to"
      },
      {
        "start": 2674.32,
        "end": 2704.52,
        "text": "my GitHub repository. There is a Discord bot.js file that contains the code that we will use for this JavaScript chatbot. Let's copy paste, and I will go through the code line by line. So first, we import the Discord API for the JavaScript module,"
      },
      {
        "start": 2704.04,
        "end": 2734.23,
        "text": "and we import fetch for making HTTP requests, just like we did in Python, and we initialize a new Discord client and define the model URL just as my username and the model name. So this guy is dialogue GPT small Harry Potter. And this"
      },
      {
        "start": 2733.75,
        "end": 2763.95,
        "text": "is the same callback that is called when the bot is ready, just like the on ready function we saw in Python. So when the bot is ready and logged in, we print out logged in as client.user.tag. And here is another callback, this time"
      },
      {
        "start": 2763.47,
        "end": 2793.66,
        "text": "on message. We use an asynchronous callback because we are making HTTP requests. Like in the Python script, we ignore the message if the message is from the bot itself by checking if message.author is the bot. Now we form the payload. So the payload"
      },
      {
        "start": 2793.18,
        "end": 2823.38,
        "text": "is a dictionary containing inputs with text message.content, which is the message that the bot has received, and we form the request headers by again using the Hugging Face API key. So we read the Hugging Face token from the environment, process.env.HuggingFaceToken, and form the"
      },
      {
        "start": 2822.9,
        "end": 2853.09,
        "text": "headers. Right before we start making the HTTP request, we set the bot status to typing. Now we query the server. So the response is the result from this call to fetch using HTTP post, given the payload as the body and the headers using"
      },
      {
        "start": 2852.61,
        "end": 2882.8,
        "text": "the Hugging Face token, and we convert the response into JSON format and extract out the generated text field. If there isn't a generated text field in the response, but instead the response contains an error field, this means that the bot has encountered some"
      },
      {
        "start": 2882.33,
        "end": 2912.52,
        "text": "errors, and we may want to print out the error for further debugging. Now that we have the bot's response, we can clear out its typing status and send the message to the channel as a reply. This ends the definition of our client.on message"
      },
      {
        "start": 2912.04,
        "end": 2942.23,
        "text": "call. Down here, we log in using the Discord token. Now let's invite the bot to our server. So we go to OAuth, check the bot. It's only permission is to send messages. We copy this, paste in a new browser window, and invite it"
      },
      {
        "start": 2941.76,
        "end": 2971.95,
        "text": "to our server. Great. Looks like we have another bot. Remember to click on save changes. Otherwise, the bot's icon wouldn't be showing. Now that we have our bot, however, it's not logged in. So we need to go back to Repl to run our"
      },
      {
        "start": 2971.47,
        "end": 3001.66,
        "text": "script. But before we run our Repl, let's make sure that the bot doesn't have access to the general channel, nor does it have access to the Python channel because it's not supposed to go there. So in permissions, we find this ChattyBot JavaScript, remove"
      },
      {
        "start": 3001.19,
        "end": 3031.38,
        "text": "its permission to send messages, and always remember to save the changes. We do the same thing for it on the Python channel. And go to the JS channel. This time, the one we need to remove is the Python bot. So this Python bot"
      },
      {
        "start": 3030.9,
        "end": 3061.09,
        "text": "shouldn't be able to send messages to this JavaScript channel. Now we go back to run our Repl.it. If you see this error, this means that the Discord version.npm is trying to install is wrong. You can see that there are those warnings that the"
      },
      {
        "start": 3060.62,
        "end": 3090.81,
        "text": "newest Discord module is not compatible with Repl.it's version of Node or npm. So we need to manually change something in package.json. So here, we just use the older version and rerun it. Now that we are logged in as ChattyBot JavaScript 1048, let's go"
      },
      {
        "start": 3090.33,
        "end": 3120.52,
        "text": "back to our Discord channel. Cool. The ChattyBot is also online. Let's see if it responds to our messages. All right, so this is now an error message telling us that the model is still loading. The model will usually take one or two minutes"
      },
      {
        "start": 3120.05,
        "end": 3150.24,
        "text": "to load, so let's give it some time. Great. Looks like our bot is responding to us. And because we have set the bot's permissions correctly, the Python bot is not responding to any messages here, and the JavaScript bot shouldn't be able to talk"
      },
      {
        "start": 3149.76,
        "end": 3179.95,
        "text": "here. And in our general channel, no bot is ever allowed to talk here. Cool. So now we have successfully built the bot both in Python and in JavaScript. One thing to note is that if I close the browser tab for the Python bot,"
      },
      {
        "start": 3179.48,
        "end": 3209.67,
        "text": "the bot is no longer responding, although it still shows that the bot is online. So in the next part, we're going to look at how to keep the bot running indefinitely in the browser, even when we close the browser tab. In order to"
      },
      {
        "start": 3209.19,
        "end": 3239.38,
        "text": "get our bot to run indefinitely, we need to create a web server in Repl.it and set up a service called Uptime Robot to continuously ping the web server. So this is for the Python bot, and we create a new file called keep alive.py."
      },
      {
        "start": 3238.9,
        "end": 3269.1,
        "text": "And we add the code for a web server like this, and in our main.py, we import that part. And down here in the main function, right before the bot runs, we ask it to be kept alive, and we run it. When the code"
      },
      {
        "start": 3268.62,
        "end": 3298.81,
        "text": "runs, we see a URL shown in this tab, and we copy this URL and bring it to our Uptime Robot service. So here is the Uptime Robot website, and I already have an account, so I'll just go to my dashboard and add a"
      },
      {
        "start": 3298.33,
        "end": 3328.53,
        "text": "new monitor. Monitor type is going to be HTTPS, friendly name Discord Python bot, the URL is the one we copied from here, and the monitoring level will be a ping every five minutes. That should be sufficient, and finally we create monitor. And close"
      },
      {
        "start": 3328.05,
        "end": 3358.24,
        "text": "it. Now let's see if our Python bot is capable of running indefinitely. All right, I'm going to close this tab containing my Python script. And it looks like our model is still up. It's just that after some time, the model on Hugging Face"
      },
      {
        "start": 3357.76,
        "end": 3387.95,
        "text": "backend will reload. But because the bot itself is responding, we know that our web server approach has worked. Now let's repeat this process for the JavaScript bot. We create a new file called server.js, and copy paste this code. Then we import this part"
      },
      {
        "start": 3387.48,
        "end": 3417.67,
        "text": "from the file that we just created. Finally, right before the bot runs, we are going to call keep alive. We stop the service, and run it. All right, the server is now ready. We copy this URL, go to Uptime Robot, and add a"
      },
      {
        "start": 3417.19,
        "end": 3447.38,
        "text": "new monitor. It's again an HTTP monitor, Discord JS bot, and the URL is like this, and we create a monitor. Now we can safely close this browser window and go back to our Discord chat. And the bot is still running. Great. Now we're"
      },
      {
        "start": 3446.91,
        "end": 3472,
        "text": "all done. We have a cool Python chatbot and a cool JavaScript chatbot that can run indefinitely. I hope you enjoyed this video. Please subscribe for more content like this, and I'll see you in the next one."
      }
    ],
    "language": "en",
    "confidence": 0.95
  },
  "analysis": {
    "summary": "This tutorial details how to build a Discord AI chatbot that speaks like any chosen character.  It starts by outlining various data sources for character dialogue, including Kaggle, Transcript Wiki, and fandom websites.  The process involves gathering data, cleaning and preparing it (using tools like Google Colab, regular expressions, and Pandas), then training a GPT model using a GPU for acceleration. The tutorial emphasizes handling potential issues like overfitting and missing data, ensuring a comprehensive guide to creating a functional and engaging chatbot.",
    "key_points": [
      {
        "timestamp": 0,
        "text": "Create a Discord bot using AI to mimic your favorite character's speech.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 1,
        "text": "Tutorial evolved from a joke between friends into a popular project.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 2,
        "text": "Updated tutorial includes more characters and data sourcing techniques.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 3,
        "text": "Covers model training, deployment, common errors, and solutions.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 4,
        "text": "Builds the bot using Python and JavaScript.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 5,
        "text": "Deploys the bot to a Discord server, limiting it to specific channels and ensuring continuous operation.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 6,
        "text": "Data sources include Kaggle, Transcript Wiki, and fandom websites.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 7,
        "text": "Kaggle offers pre-made dialogue datasets for various characters.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 8,
        "text": "If Kaggle data is unavailable, Transcript Wiki and Google searches for transcripts are used.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 9,
        "text": "For real-life characters, interview scripts or personal messages can be used.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 10,
        "text": "Raw transcripts are parsed and converted into two-column datasets using Google Colab, regular expressions, and Pandas.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 11,
        "text": "Regular expression patterns are used to extract character names and lines from transcripts.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 12,
        "text": "Data is cleaned and transformed into a usable format for model training.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 13,
        "text": "A GPT (Generative Pre-trained Transformer) model is used for training.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 14,
        "text": "GPU acceleration is used for faster model training.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 15,
        "text": "Kaggle API key is required to download datasets from Kaggle.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 16,
        "text": "Data is split into training and testing sets to prevent overfitting.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 17,
        "text": "The model is trained on the training set and evaluated on the test set.",
        "importance": 0.9,
        "context": null
      },
      {
        "timestamp": 18,
        "text": "Contextual information is used to generate more organic and relevant responses.",
        "importance": 0.9,
        "context": null
      }
    ],
    "entities": [
      {
        "name": "Harry Potter",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 77,
          "end_char": 89
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Transcript Wiki",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 1684,
          "end_char": 1699
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Google Colab",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 4538,
          "end_char": 4550
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Hugging Face",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 12916,
          "end_char": 12928
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Uptime Robot",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 26484,
          "end_char": 26496
        },
        "confidence": 1.0,
        "timestamp": null
      },
      {
        "name": "Google Colab",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "FAC",
          "start_char": 4353,
          "end_char": 4365
        },
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "Discord",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 15,
          "end_char": 22
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Python",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 1347,
          "end_char": 1353
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Kaggle",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 1676,
          "end_char": 1682
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Google",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 1756,
          "end_char": 1762
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Peppa Pig",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 2580,
          "end_char": 2589
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Peppa",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 2946,
          "end_char": 2951
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Transformer",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 7239,
          "end_char": 7250
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Kaggle",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 7578,
          "end_char": 7584
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Harry",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 9057,
          "end_char": 9062
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Git",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 13510,
          "end_char": 13513
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Python",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 15541,
          "end_char": 15547
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "JavaScript",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 15568,
          "end_char": 15578
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "ChattyBot Python",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 15957,
          "end_char": 15973
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "Repl",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 20293,
          "end_char": 20297
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "ChattyBot",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 21569,
          "end_char": 21578
        },
        "confidence": 0.9,
        "timestamp": null
      },
      {
        "name": "the Discord",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "FAC",
          "start_char": 18282,
          "end_char": 18293
        },
        "confidence": 0.8999999999999999,
        "timestamp": null
      },
      {
        "name": "JavaScript",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "PRODUCT",
          "start_char": 1377,
          "end_char": 1387
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Besides Transcript Wiki",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 3222,
          "end_char": 3245
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Google Drive",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "FAC",
          "start_char": 4651,
          "end_char": 4663
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "PeppaPig.csv",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "PRODUCT",
          "start_char": 6457,
          "end_char": 6469
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Generative Pre-trained",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 7216,
          "end_char": 7238
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Harry Potter 1.csv",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 8000,
          "end_char": 8018
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Git Large File Storage",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 13617,
          "end_char": 13639
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Python Repl",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 16225,
          "end_char": 16236
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Discord Python",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 27102,
          "end_char": 27116
        },
        "confidence": 0.85,
        "timestamp": null
      },
      {
        "name": "Rick",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 59,
          "end_char": 63
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Morty",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 68,
          "end_char": 73
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Lynn",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 171,
          "end_char": 175
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Pandas",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 4968,
          "end_char": 4974
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "PyTorch",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 14358,
          "end_char": 14365
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "PyTorch",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 14596,
          "end_char": 14603
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "OAuth",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 24083,
          "end_char": 24088
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "Node",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 25240,
          "end_char": 25244
        },
        "confidence": 0.8,
        "timestamp": null
      },
      {
        "name": "the University of Chicago",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 389,
          "end_char": 414
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "Batman on Transcript Wiki",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "WORK_OF_ART",
          "start_char": 2977,
          "end_char": 3002
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "The Word Ends With You",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "WORK_OF_ART",
          "start_char": 3373,
          "end_char": 3395
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "script.ipynb",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 4499,
          "end_char": 4511
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "Discord bot.py",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "PRODUCT",
          "start_char": 16888,
          "end_char": 16902
        },
        "confidence": 0.7999999999999999,
        "timestamp": null
      },
      {
        "name": "George",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 6049,
          "end_char": 6055
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "Microsoft",
        "type": "ORGANIZATION",
        "properties": {
          "spacy_label": "ORG",
          "start_char": 10109,
          "end_char": 10118
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "Dev Lab",
        "type": "PERSON",
        "properties": {
          "spacy_label": "PERSON",
          "start_char": 15499,
          "end_char": 15506
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "UTF-8",
        "type": "LOCATION",
        "properties": {
          "spacy_label": "GPE",
          "start_char": 18116,
          "end_char": 18121
        },
        "confidence": 0.75,
        "timestamp": null
      },
      {
        "name": "message.content",
        "type": "PRODUCT",
        "properties": {
          "spacy_label": "PRODUCT",
          "start_char": 22997,
          "end_char": 23012
        },
        "confidence": 0.7499999999999999,
        "timestamp": null
      },
      {
        "name": "Discord",
        "type": "software",
        "properties": {},
        "confidence": 0.8352148532867432,
        "timestamp": null
      },
      {
        "name": "Rick and Morty",
        "type": "movie",
        "properties": {},
        "confidence": 0.8205140233039856,
        "timestamp": null
      },
      {
        "name": "Harry Potter",
        "type": "movie",
        "properties": {},
        "confidence": 0.8038054704666138,
        "timestamp": null
      },
      {
        "name": "Lynn",
        "type": "character",
        "properties": {},
        "confidence": 0.8973746299743652,
        "timestamp": null
      },
      {
        "name": "University of Chicago",
        "type": "organization",
        "properties": {},
        "confidence": 0.7276162505149841,
        "timestamp": null
      },
      {
        "name": "Discord bot",
        "type": "software",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "bot",
        "type": "model",
        "properties": {},
        "confidence": 0.7116631865501404,
        "timestamp": null
      },
      {
        "name": "favorite character",
        "type": "character",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "model",
        "type": "model",
        "properties": {},
        "confidence": 0.953525185585022,
        "timestamp": null
      },
      {
        "name": "Python",
        "type": "programming_language",
        "properties": {},
        "confidence": 0.9506585001945496,
        "timestamp": null
      },
      {
        "name": "JavaScript",
        "type": "programming_language",
        "properties": {},
        "confidence": 0.9421895742416382,
        "timestamp": null
      },
      {
        "name": "bot",
        "type": "software",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "character",
        "type": "character",
        "properties": {},
        "confidence": 0.8501603007316589,
        "timestamp": null
      },
      {
        "name": "Kaggle",
        "type": "software",
        "properties": {},
        "confidence": 0.8878624439239502,
        "timestamp": null
      },
      {
        "name": "Transcript Wiki",
        "type": "software",
        "properties": {},
        "confidence": 0.7358392477035522,
        "timestamp": null
      },
      {
        "name": "Google",
        "type": "software",
        "properties": {},
        "confidence": 0.7462185025215149,
        "timestamp": null
      },
      {
        "name": "Peppa Pig",
        "type": "character",
        "properties": {},
        "confidence": 0.9410619139671326,
        "timestamp": null
      },
      {
        "name": "video game",
        "type": "game",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "video games",
        "type": "game",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "game",
        "type": "game",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "you",
        "type": "character",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "Google Colab",
        "type": "software",
        "properties": {},
        "confidence": 0.8887805938720703,
        "timestamp": null
      },
      {
        "name": "Google",
        "type": "company",
        "properties": {},
        "confidence": 0.7377576231956482,
        "timestamp": null
      },
      {
        "name": "drive",
        "type": "hardware",
        "properties": {},
        "confidence": 0.9524496793746948,
        "timestamp": null
      },
      {
        "name": "regular expression",
        "type": "algorithm",
        "properties": {},
        "confidence": 0.8051311373710632,
        "timestamp": null
      },
      {
        "name": "Mama Pig",
        "type": "character",
        "properties": {},
        "confidence": 0.9026328921318054,
        "timestamp": null
      },
      {
        "name": "George",
        "type": "character",
        "properties": {},
        "confidence": 0.8864147067070007,
        "timestamp": null
      },
      {
        "name": "PeppaPig",
        "type": "character",
        "properties": {},
        "confidence": 0.9763714075088501,
        "timestamp": null
      },
      {
        "name": "GPT model",
        "type": "model",
        "properties": {},
        "confidence": 0.804124653339386,
        "timestamp": null
      },
      {
        "name": "we",
        "type": "character",
        "properties": {},
        "confidence": 0.8083429336547852,
        "timestamp": null
      },
      {
        "name": "our character",
        "type": "character",
        "properties": {},
        "confidence": 0.7857029438018799,
        "timestamp": null
      },
      {
        "name": "Harry",
        "type": "character",
        "properties": {},
        "confidence": 0.9386613368988037,
        "timestamp": null
      },
      {
        "name": "Microsoft",
        "type": "company",
        "properties": {},
        "confidence": 0.9123840928077698,
        "timestamp": null
      },
      {
        "name": "12 epochs",
        "type": "time",
        "properties": {},
        "confidence": 0.7145524024963379,
        "timestamp": null
      },
      {
        "name": "chatbot",
        "type": "software",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "Git",
        "type": "framework",
        "properties": {},
        "confidence": 0.7193344235420227,
        "timestamp": null
      },
      {
        "name": "username",
        "type": "person",
        "properties": {},
        "confidence": 0.8699728846549988,
        "timestamp": null
      },
      {
        "name": "Git",
        "type": "software",
        "properties": {},
        "confidence": 0.9124588370323181,
        "timestamp": null
      },
      {
        "name": "user",
        "type": "person",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "Discord",
        "type": "platform",
        "properties": {},
        "confidence": 0.9536486268043518,
        "timestamp": null
      },
      {
        "name": "channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.7005025148391724,
        "timestamp": null
      },
      {
        "name": "API",
        "type": "api",
        "properties": {},
        "confidence": 0.7799608707427979,
        "timestamp": null
      },
      {
        "name": "Discord",
        "type": "framework",
        "properties": {},
        "confidence": 0.95,
        "timestamp": null
      },
      {
        "name": "HTTP",
        "type": "protocol",
        "properties": {},
        "confidence": 0.9078415036201477,
        "timestamp": null
      },
      {
        "name": "Hugging Face API",
        "type": "api",
        "properties": {},
        "confidence": 0.9289038181304932,
        "timestamp": null
      },
      {
        "name": "Discord API",
        "type": "api",
        "properties": {},
        "confidence": 0.9273198843002319,
        "timestamp": null
      },
      {
        "name": "HTTP",
        "type": "channel",
        "properties": {},
        "confidence": 0.760124921798706,
        "timestamp": null
      },
      {
        "name": "Harry Potter",
        "type": "software",
        "properties": {},
        "confidence": 0.8982607126235962,
        "timestamp": null
      },
      {
        "name": "general channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.9639551043510437,
        "timestamp": null
      },
      {
        "name": "Python channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.9566041231155396,
        "timestamp": null
      },
      {
        "name": "JS channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.8923065066337585,
        "timestamp": null
      },
      {
        "name": "JavaScript channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.840682327747345,
        "timestamp": null
      },
      {
        "name": "npm",
        "type": "channel",
        "properties": {},
        "confidence": 0.7125272154808044,
        "timestamp": null
      },
      {
        "name": "Discord channel",
        "type": "channel",
        "properties": {},
        "confidence": 0.845048725605011,
        "timestamp": null
      },
      {
        "name": "web server",
        "type": "software",
        "properties": {},
        "confidence": 0.7969065308570862,
        "timestamp": null
      },
      {
        "name": "Uptime Robot",
        "type": "software",
        "properties": {},
        "confidence": 0.9436659216880798,
        "timestamp": null
      },
      {
        "name": "HTTPS",
        "type": "protocol",
        "properties": {},
        "confidence": 0.9097098112106323,
        "timestamp": null
      },
      {
        "name": "Discord JS bot",
        "type": "software",
        "properties": {},
        "confidence": 0.8758285641670227,
        "timestamp": null
      }
    ],
    "topics": [
      {
        "name": "Discord Bot Development",
        "confidence": 0.85
      },
      {
        "name": "AI Chatbot Creation",
        "confidence": 0.85
      },
      {
        "name": "Data Acquisition and Processing",
        "confidence": 0.85
      }
    ],
    "sentiment": null
  },
  "processing": {
    "cost": 0.44268,
    "time": 0.0,
    "processed_at": "2025-06-24T12:48:34.339357",
    "model": "gemini-1.5-flash",
    "extractor": "advanced_hybrid_v2.2"
  },
  "relationships": [
    {
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "use",
      "confidence": 0.9,
      "context": "Want to make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you"
    },
    {
      "subject": "Discord bot",
      "predicate": "instance of",
      "object": "artificial intelligence",
      "confidence": 0.9,
      "context": "Want to make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you"
    },
    {
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "uses",
      "confidence": 0.9,
      "context": "Want to make a Discord bot that talks like characters from Rick and Morty or Harry Potter? Maybe you"
    },
    {
      "subject": "chatbot",
      "predicate": "AI",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago"
    },
    {
      "subject": "Discord",
      "predicate": "instance of",
      "object": "chatbot",
      "confidence": 0.9,
      "context": "I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago"
    },
    {
      "subject": "Discord",
      "predicate": "instance of",
      "object": "AI chatbot",
      "confidence": 0.9,
      "context": "I'm a software engineer, hobbyist game developer, and recent graduate from the University of Chicago"
    },
    {
      "subject": "Python",
      "predicate": "influenced by",
      "object": "JavaScript",
      "confidence": 0.9,
      "context": "So keep watching till the end.\n\nThe original tutorial and my first Discord bot started as a joke bet"
    },
    {
      "subject": "Discord bot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So keep watching till the end.\n\nThe original tutorial and my first Discord bot started as a joke bet"
    },
    {
      "subject": "Discord",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So keep watching till the end.\n\nThe original tutorial and my first Discord bot started as a joke bet"
    },
    {
      "subject": "Kaggle",
      "predicate": "owned by",
      "object": "Google",
      "confidence": 0.9,
      "context": "I hope you're excited and let's jump into the tutorial.\n\nFirst, we are going to find data for our ch"
    },
    {
      "subject": "Google",
      "predicate": "Kaggle",
      "object": "owner of",
      "confidence": 0.9,
      "context": "I hope you're excited and let's jump into the tutorial.\n\nFirst, we are going to find data for our ch"
    },
    {
      "subject": "Kaggle",
      "predicate": "instance of",
      "object": "Google search",
      "confidence": 0.9,
      "context": "I hope you're excited and let's jump into the tutorial.\n\nFirst, we are going to find data for our ch"
    },
    {
      "subject": "data set",
      "predicate": "chatbot",
      "object": "use",
      "confidence": 0.9,
      "context": "I first search on Kaggle to see if there are pre-made dialogue data sets.\n\nFor example, if we search"
    },
    {
      "subject": "Rick and Morty",
      "predicate": "dialogue",
      "object": "genre",
      "confidence": 0.9,
      "context": "I first search on Kaggle to see if there are pre-made dialogue data sets.\n\nFor example, if we search"
    },
    {
      "subject": "data set",
      "predicate": "has part",
      "object": "dialogue",
      "confidence": 0.9,
      "context": "I first search on Kaggle to see if there are pre-made dialogue data sets.\n\nFor example, if we search"
    },
    {
      "subject": "model training",
      "predicate": "data set",
      "object": "uses",
      "confidence": 0.9,
      "context": "So these dialogue data sets on Kaggle are perfect for our requirement.\n\nAll right, if we succeeded i"
    },
    {
      "subject": "model training",
      "predicate": "data set",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So these dialogue data sets on Kaggle are perfect for our requirement.\n\nAll right, if we succeeded i"
    },
    {
      "subject": "model training",
      "predicate": "data sets",
      "object": "uses",
      "confidence": 0.9,
      "context": "So these dialogue data sets on Kaggle are perfect for our requirement.\n\nAll right, if we succeeded i"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "Peppa Pig",
      "object": "characters",
      "confidence": 0.9,
      "context": "But what if we cannot find a data set for our character on Kaggle? For example, if I want to find a "
    },
    {
      "subject": "Peppa Pig",
      "predicate": "Peppa Pig",
      "object": "present in work",
      "confidence": 0.9,
      "context": "But what if we cannot find a data set for our character on Kaggle? For example, if I want to find a "
    },
    {
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "game",
      "confidence": 0.9,
      "context": "We will see shortly how to turn a raw transcript like this into a data set like those we saw on Kagg"
    },
    {
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "fandom website",
      "confidence": 0.9,
      "context": "We will see shortly how to turn a raw transcript like this into a data set like those we saw on Kagg"
    },
    {
      "subject": "chatbot",
      "predicate": "dialogues",
      "object": "uses",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "dialogues",
      "predicate": "chatbot",
      "object": "used by",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "chatbot",
      "predicate": "text messages",
      "object": "uses",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "text messages",
      "predicate": "chatbot",
      "object": "used by",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "chatbot",
      "predicate": "text message",
      "object": "uses",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "text message",
      "predicate": "chatbot",
      "object": "used by",
      "confidence": 0.9,
      "context": "So be sure to utilize your Google search skills to find data for your character.\n\nIf, rather than fi"
    },
    {
      "subject": "two-column",
      "predicate": "character line",
      "object": "uses",
      "confidence": 0.9,
      "context": "And now we will look at how to turn raw transcript into data set.\n\nNow, suppose we have found our ra"
    },
    {
      "subject": "character line",
      "predicate": "two-column",
      "object": "used by",
      "confidence": 0.9,
      "context": "And now we will look at how to turn raw transcript into data set.\n\nNow, suppose we have found our ra"
    },
    {
      "subject": "character line",
      "predicate": "two-column",
      "object": "use",
      "confidence": 0.9,
      "context": "And now we will look at how to turn raw transcript into data set.\n\nNow, suppose we have found our ra"
    },
    {
      "subject": "two-column",
      "predicate": "character line",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "And now we will look at how to turn raw transcript into data set.\n\nNow, suppose we have found our ra"
    },
    {
      "subject": "Google Colab",
      "predicate": "has part",
      "object": "Google Drive",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive and then call drive.mount content drive.\n\nThis wi"
    },
    {
      "subject": "Google Drive",
      "predicate": "part of",
      "object": "Google Colab",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive and then call drive.mount content drive.\n\nThis wi"
    },
    {
      "subject": "Google Drive",
      "predicate": "has part",
      "object": "Google Colab",
      "confidence": 0.9,
      "context": "And we are going to from Google Colab import drive and then call drive.mount content drive.\n\nThis wi"
    },
    {
      "subject": "CSV",
      "predicate": "Pandas",
      "object": "used by",
      "confidence": 0.9,
      "context": "So here we are going to import regular expression to parse our transcript, put the parsed result int"
    },
    {
      "subject": "Pandas",
      "predicate": "CSV",
      "object": "use",
      "confidence": 0.9,
      "context": "So here we are going to import regular expression to parse our transcript, put the parsed result int"
    },
    {
      "subject": "Pandas",
      "predicate": "CSV",
      "object": "uses",
      "confidence": 0.9,
      "context": "So here we are going to import regular expression to parse our transcript, put the parsed result int"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "Mama Pig",
      "object": "mother",
      "confidence": 0.9,
      "context": "If we take the pattern to this site,\n\nand our test string is Peppa Pig,\n\nyou will see that we have t"
    },
    {
      "subject": "Mama Pig",
      "predicate": "Peppa Pig",
      "object": "child",
      "confidence": 0.9,
      "context": "If we take the pattern to this site,\n\nand our test string is Peppa Pig,\n\nyou will see that we have t"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "has part",
      "object": "Mama Pig",
      "confidence": 0.9,
      "context": "If we take the pattern to this site,\n\nand our test string is Peppa Pig,\n\nyou will see that we have t"
    },
    {
      "subject": "Mama Pig",
      "predicate": "part of",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "If we take the pattern to this site,\n\nand our test string is Peppa Pig,\n\nyou will see that we have t"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "Mama Pig",
      "object": "sibling",
      "confidence": 0.9,
      "context": "If we take the pattern to this site,\n\nand our test string is Peppa Pig,\n\nyou will see that we have t"
    },
    {
      "subject": "Mama Pig",
      "predicate": "Peppa Pig",
      "object": "sibling",
      "confidence": 0.9,
      "context": "If we take the pattern to this site,\n\nand our test string is Peppa Pig,\n\nyou will see that we have t"
    },
    {
      "subject": "result data frame",
      "predicate": "data frame",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So we know that we need the column name and the column line in our result data frame.\n\nAnd now we op"
    },
    {
      "subject": "result data frame",
      "predicate": "instance of",
      "object": "data frame",
      "confidence": 0.9,
      "context": "So we know that we need the column name and the column line in our result data frame.\n\nAnd now we op"
    },
    {
      "subject": "parametric",
      "predicate": "regular expression",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So we know that we need the column name and the column line in our result data frame.\n\nAnd now we op"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "George",
      "object": "sibling",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "Mama Pig",
      "predicate": "sibling",
      "object": "George",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "Peppa Pig",
      "predicate": "sibling",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "sibling",
      "predicate": "Peppa Pig",
      "object": "sibling",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "Mama Pig",
      "predicate": "sibling",
      "object": "Mama Pig",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "George",
      "predicate": "sibling",
      "object": "Mama Pig",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "sibling",
      "predicate": "Mama Pig",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "sibling",
      "predicate": "Peppa Pig",
      "object": "George",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "sibling",
      "predicate": "Mama Pig",
      "object": "sibling",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "George",
      "predicate": "sibling",
      "object": "Peppa Pig",
      "confidence": 0.9,
      "context": "Cool, so we have the name is Peppa Pig, saying that I'm Peppa Pig, and then George makes a sound and"
    },
    {
      "subject": "train the model",
      "predicate": "model training",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So DF.to_csv, the name will be PeppaPig.csv, and and we will drop the index. Cool. Now we should hav"
    },
    {
      "subject": "train the model",
      "predicate": "model training",
      "object": "use",
      "confidence": 0.9,
      "context": "So DF.to_csv, the name will be PeppaPig.csv, and and we will drop the index. Cool. Now we should hav"
    },
    {
      "subject": "DF.csv",
      "predicate": "part of",
      "object": "PeppaPig",
      "confidence": 0.9,
      "context": "So DF.to_csv, the name will be PeppaPig.csv, and and we will drop the index. Cool. Now we should hav"
    },
    {
      "subject": "Google Colab",
      "predicate": "part of",
      "object": "Google Drive",
      "confidence": 0.9,
      "context": "Go to my GitHub repository linked to in the description below and download the content.\n\nWe are goin"
    },
    {
      "subject": "Transformers",
      "predicate": "instance of",
      "object": "modules",
      "confidence": 0.9,
      "context": "Make sure to select GPU because this will accelerate our model training.\n\nSo now here, we mount the "
    },
    {
      "subject": "Transformers",
      "predicate": "GPUs",
      "object": "platform",
      "confidence": 0.9,
      "context": "Make sure to select GPU because this will accelerate our model training.\n\nSo now here, we mount the "
    },
    {
      "subject": "Transformers module",
      "predicate": "GPUs",
      "object": "platform",
      "confidence": 0.9,
      "context": "Make sure to select GPU because this will accelerate our model training.\n\nSo now here, we mount the "
    },
    {
      "subject": "Harry Potter",
      "predicate": "has part",
      "object": "Harry Potter 1",
      "confidence": 0.9,
      "context": "We're going to use the Harry Potter data set as an example.\n\nSo grab this username and the data set "
    },
    {
      "subject": "Harry Potter 1",
      "predicate": "part of",
      "object": "Harry Potter",
      "confidence": 0.9,
      "context": "We're going to use the Harry Potter data set as an example.\n\nSo grab this username and the data set "
    },
    {
      "subject": "Harry Potter data set",
      "predicate": "has part",
      "object": "Harry Potter 1",
      "confidence": 0.9,
      "context": "We're going to use the Harry Potter data set as an example.\n\nSo grab this username and the data set "
    },
    {
      "subject": "Harry Potter 1",
      "predicate": "part of",
      "object": "Harry Potter data set",
      "confidence": 0.9,
      "context": "We're going to use the Harry Potter data set as an example.\n\nSo grab this username and the data set "
    },
    {
      "subject": "separating",
      "predicate": "comma",
      "object": "different from",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "comma",
      "predicate": "separating",
      "object": "different from",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "separating",
      "predicate": "has part",
      "object": "semicolon",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "semicolon",
      "predicate": "part of",
      "object": "separating",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "semicolon",
      "predicate": "separating",
      "object": "use",
      "confidence": 0.9,
      "context": "So we need to take care of the semicolons when we are reading in the data into a Pandas data frame. "
    },
    {
      "subject": "parametric",
      "predicate": "has part",
      "object": "lines",
      "confidence": 0.9,
      "context": "Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is."
    },
    {
      "subject": "lines",
      "predicate": "part of",
      "object": "parametric",
      "confidence": 0.9,
      "context": "Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is."
    },
    {
      "subject": "parametric",
      "predicate": "lines",
      "object": "has parts of the class",
      "confidence": 0.9,
      "context": "Looks like we have successfully changed the name of our columns.\n\nNow let's see how big our data is."
    },
    {
      "subject": "conversational",
      "predicate": "has part",
      "object": "chatbot",
      "confidence": 0.9,
      "context": "So here, we change our character name to Harry,\n\nand we now run this cell to create a context data f"
    },
    {
      "subject": "chatbot",
      "predicate": "conversational",
      "object": "use",
      "confidence": 0.9,
      "context": "So here, we change our character name to Harry,\n\nand we now run this cell to create a context data f"
    },
    {
      "subject": "conversational",
      "predicate": "chatbot",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So here, we change our character name to Harry,\n\nand we now run this cell to create a context data f"
    },
    {
      "subject": "Harry",
      "predicate": "instance of",
      "object": "conversational chatbot",
      "confidence": 0.9,
      "context": "So here, we change our character name to Harry,\n\nand we now run this cell to create a context data f"
    },
    {
      "subject": "training set",
      "predicate": "data set",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So in the context of clearly something something, our character responds with seems a pity not to as"
    },
    {
      "subject": "test set",
      "predicate": "data set",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So in the context of clearly something something, our character responds with seems a pity not to as"
    },
    {
      "subject": "GPT small",
      "predicate": "Microsoft",
      "object": "developer",
      "confidence": 0.9,
      "context": "We want the conversation to be more organic.\n\nSo we're only training the model on the training set a"
    },
    {
      "subject": "pre-trained",
      "predicate": "training",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "We want the conversation to be more organic.\n\nSo we're only training the model on the training set a"
    },
    {
      "subject": "small",
      "predicate": "Microsoft",
      "object": "developer",
      "confidence": 0.9,
      "context": "We want the conversation to be more organic.\n\nSo we're only training the model on the training set a"
    },
    {
      "subject": "My production chatbot",
      "predicate": "instance of",
      "object": "medium model",
      "confidence": 0.9,
      "context": "Generally, the larger the model, the longer it takes to train, but the smarter the model can get.\n\nI"
    },
    {
      "subject": "My production chatbot",
      "predicate": "medium model",
      "object": "use",
      "confidence": 0.9,
      "context": "Generally, the larger the model, the longer it takes to train, but the smarter the model can get.\n\nI"
    },
    {
      "subject": "My production chatbot",
      "predicate": "instance of",
      "object": "chatbot",
      "confidence": 0.9,
      "context": "Generally, the larger the model, the longer it takes to train, but the smarter the model can get.\n\nI"
    },
    {
      "subject": "num train epochs",
      "predicate": "instance of",
      "object": "hyperparameters",
      "confidence": 0.9,
      "context": "For this tutorial, for the sake of time, I'm training just a small model.\n\nYou can see here it's dow"
    },
    {
      "subject": "num train epochs",
      "predicate": "hyperparameters",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "For this tutorial, for the sake of time, I'm training just a small model.\n\nYou can see here it's dow"
    },
    {
      "subject": "num train epochs",
      "predicate": "instance of",
      "object": "hyperparameter",
      "confidence": 0.9,
      "context": "For this tutorial, for the sake of time, I'm training just a small model.\n\nYou can see here it's dow"
    },
    {
      "subject": "batch size",
      "predicate": "hyperparameter",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "As long as the model is not overfitting, increasing the number of training epochs usually results in"
    },
    {
      "subject": "batch size",
      "predicate": "instance of",
      "object": "hyperparameter",
      "confidence": 0.9,
      "context": "As long as the model is not overfitting, increasing the number of training epochs usually results in"
    },
    {
      "subject": "overfitting",
      "predicate": "gradient",
      "object": "has effect",
      "confidence": 0.9,
      "context": "As long as the model is not overfitting, increasing the number of training epochs usually results in"
    },
    {
      "subject": "learning rate",
      "predicate": "hyperparameters",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "I wouldn't recommend changing this unless you know what you're doing since other hyperparameters lik"
    },
    {
      "subject": "temperature",
      "predicate": "hyperparameters",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "I wouldn't recommend changing this unless you know what you're doing since other hyperparameters lik"
    },
    {
      "subject": "learning rate",
      "predicate": "instance of",
      "object": "hyperparameters",
      "confidence": 0.9,
      "context": "I wouldn't recommend changing this unless you know what you're doing since other hyperparameters lik"
    },
    {
      "subject": "temperature",
      "predicate": "instance of",
      "object": "hyperparameters",
      "confidence": 0.9,
      "context": "I wouldn't recommend changing this unless you know what you're doing since other hyperparameters lik"
    },
    {
      "subject": "neurotransmitter",
      "predicate": "neurotransmitter",
      "object": "different from",
      "confidence": 0.9,
      "context": "However, if you're training a larger model on a larger data set and are running into memory errors, "
    },
    {
      "subject": "data frame",
      "predicate": "part of",
      "object": "data set",
      "confidence": 0.9,
      "context": "However, if you're training a larger model on a larger data set and are running into memory errors, "
    },
    {
      "subject": "data set",
      "predicate": "has part",
      "object": "data frame",
      "confidence": 0.9,
      "context": "However, if you're training a larger model on a larger data set and are running into memory errors, "
    },
    {
      "subject": "epochs",
      "predicate": "part of",
      "object": "data set",
      "confidence": 0.9,
      "context": "However, if you're training a larger model on a larger data set and are running into memory errors, "
    },
    {
      "subject": "train",
      "predicate": "data set",
      "object": "uses",
      "confidence": 0.9,
      "context": "So do sit back and grab a snack while the model is training.\n\nYou can see the progress in the progre"
    },
    {
      "subject": "data set",
      "predicate": "train",
      "object": "used by",
      "confidence": 0.9,
      "context": "So do sit back and grab a snack while the model is training.\n\nYou can see the progress in the progre"
    },
    {
      "subject": "confused",
      "predicate": "perplexity answer",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So do sit back and grab a snack while the model is training.\n\nYou can see the progress in the progre"
    },
    {
      "subject": "perplexity answer",
      "predicate": "has part",
      "object": "confused",
      "confidence": 0.9,
      "context": "So do sit back and grab a snack while the model is training.\n\nYou can see the progress in the progre"
    },
    {
      "subject": "confused answer",
      "predicate": "has part",
      "object": "confused",
      "confidence": 0.9,
      "context": "So do sit back and grab a snack while the model is training.\n\nYou can see the progress in the progre"
    },
    {
      "subject": "neurotransmitter",
      "predicate": "neurotransmitter",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "To decrease the perplexity, we might need to train for more epochs. Cool. But now that the training "
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "command line client",
      "confidence": 0.9,
      "context": "It looks like our chatbot is capable of making and maintaining a conversation.\n\nNow we can push the "
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "command line",
      "confidence": 0.9,
      "context": "It looks like our chatbot is capable of making and maintaining a conversation.\n\nNow we can push the "
    },
    {
      "subject": "Hugging Face",
      "predicate": "command line",
      "object": "use",
      "confidence": 0.9,
      "context": "It looks like our chatbot is capable of making and maintaining a conversation.\n\nNow we can push the "
    },
    {
      "subject": "Git LFS",
      "predicate": "instance of",
      "object": "repository",
      "confidence": 0.9,
      "context": "So we can create a repository to store our model from the command line. Mine is going to be called d"
    },
    {
      "subject": "Git LFS",
      "predicate": "repository",
      "object": "use",
      "confidence": 0.9,
      "context": "So we can create a repository to store our model from the command line. Mine is going to be called d"
    },
    {
      "subject": "Git",
      "predicate": "instance of",
      "object": "repository",
      "confidence": 0.9,
      "context": "So we can create a repository to store our model from the command line. Mine is going to be called d"
    },
    {
      "subject": "commit",
      "predicate": "part of",
      "object": "Git",
      "confidence": 0.9,
      "context": "This will allows us to push and pull our models, and we replace this token with the token we just co"
    },
    {
      "subject": "commit",
      "predicate": "Git",
      "object": "used by",
      "confidence": 0.9,
      "context": "This will allows us to push and pull our models, and we replace this token with the token we just co"
    },
    {
      "subject": "Git",
      "predicate": "commit",
      "object": "uses",
      "confidence": 0.9,
      "context": "This will allows us to push and pull our models, and we replace this token with the token we just co"
    },
    {
      "subject": "Git LFS",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We install the Git LFS,\n\nand inspect the content of our current directory, which should be dialogue "
    },
    {
      "subject": "Git LFS",
      "predicate": "Git",
      "object": "use",
      "confidence": 0.9,
      "context": "We install the Git LFS,\n\nand inspect the content of our current directory, which should be dialogue "
    },
    {
      "subject": "Git",
      "predicate": "LFS",
      "object": "uses",
      "confidence": 0.9,
      "context": "We install the Git LFS,\n\nand inspect the content of our current directory, which should be dialogue "
    },
    {
      "subject": "PyTorch",
      "predicate": "text generation",
      "object": "use",
      "confidence": 0.9,
      "context": "These are just my Hugging Face credentials,\n\nand we commit with message initial commit, and finally "
    },
    {
      "subject": "Hugging Face",
      "predicate": "has part",
      "object": "PyTorch",
      "confidence": 0.9,
      "context": "These are just my Hugging Face credentials,\n\nand we commit with message initial commit, and finally "
    },
    {
      "subject": "Hugging Face",
      "predicate": "PyTorch",
      "object": "uses",
      "confidence": 0.9,
      "context": "These are just my Hugging Face credentials,\n\nand we commit with message initial commit, and finally "
    },
    {
      "subject": "chatbot",
      "predicate": "conversational",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "However, we know that we are training a chatbot model, and we want our model to be conversational. F"
    },
    {
      "subject": "Discord bot",
      "predicate": "instance of",
      "object": "chatbot",
      "confidence": 0.9,
      "context": "Now that we have pushed our model to Hugging Face, we're ready to use it in our Discord chatbot.\n\nNo"
    },
    {
      "subject": "Discord bot",
      "predicate": "chatbot",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "Now that we have pushed our model to Hugging Face, we're ready to use it in our Discord chatbot.\n\nNo"
    },
    {
      "subject": "Python bot",
      "predicate": "JavaScript bot",
      "object": "different from",
      "confidence": 0.9,
      "context": "I have two channels, one for the Python bot and one for the JavaScript bot.\n\nThe reason why we have "
    },
    {
      "subject": "JavaScript bot",
      "predicate": "Python bot",
      "object": "different from",
      "confidence": 0.9,
      "context": "I have two channels, one for the Python bot and one for the JavaScript bot.\n\nThe reason why we have "
    },
    {
      "subject": "Python bot",
      "predicate": "instance of",
      "object": "bots",
      "confidence": 0.9,
      "context": "I have two channels, one for the Python bot and one for the JavaScript bot.\n\nThe reason why we have "
    },
    {
      "subject": "JavaScript bot",
      "predicate": "instance of",
      "object": "bots",
      "confidence": 0.9,
      "context": "I have two channels, one for the Python bot and one for the JavaScript bot.\n\nThe reason why we have "
    },
    {
      "subject": "ChattyBot Python",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We need one application per bot.\n\nSo our name will be ChattyBot Python.\n\nSo here we create a bot,\n\na"
    },
    {
      "subject": "ChattyBot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We need one application per bot.\n\nSo our name will be ChattyBot Python.\n\nSo here we create a bot,\n\na"
    },
    {
      "subject": "Python Repl",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We need one application per bot.\n\nSo our name will be ChattyBot Python.\n\nSo here we create a bot,\n\na"
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "API tokens",
      "confidence": 0.9,
      "context": "So here is a tab for the secrets for the environment variables. So the first one will be Hugging Fac"
    },
    {
      "subject": "Python",
      "predicate": "has part",
      "object": "OS module",
      "confidence": 0.9,
      "context": "We add the token here,\n\nand our environment variables are all set.\n\nNext, I have the Python file in "
    },
    {
      "subject": "OS module",
      "predicate": "part of",
      "object": "Python",
      "confidence": 0.9,
      "context": "We add the token here,\n\nand our environment variables are all set.\n\nNext, I have the Python file in "
    },
    {
      "subject": "Hugging Face",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "We add the token here,\n\nand our environment variables are all set.\n\nNext, I have the Python file in "
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "API",
      "confidence": 0.9,
      "context": "In the on ready function,\n\nit takes in a model name, which for me will be dialogue GPT small Harry P"
    },
    {
      "subject": "API endpoint",
      "predicate": "part of",
      "object": "API",
      "confidence": 0.9,
      "context": "In the on ready function,\n\nit takes in a model name, which for me will be dialogue GPT small Harry P"
    },
    {
      "subject": "API endpoint",
      "predicate": "API",
      "object": "use",
      "confidence": 0.9,
      "context": "In the on ready function,\n\nit takes in a model name, which for me will be dialogue GPT small Harry P"
    },
    {
      "subject": "Hugging Face",
      "predicate": "instance of",
      "object": "bearer",
      "confidence": 0.9,
      "context": "For the authorization part, we put in bearer and the Hugging Face token.\n\nNext, we define a query me"
    },
    {
      "subject": "Hugging Face",
      "predicate": "authorization",
      "object": "use",
      "confidence": 0.9,
      "context": "For the authorization part, we put in bearer and the Hugging Face token.\n\nNext, we define a query me"
    },
    {
      "subject": "Hugging Face",
      "predicate": "has part",
      "object": "bearer",
      "confidence": 0.9,
      "context": "For the authorization part, we put in bearer and the Hugging Face token.\n\nNext, we define a query me"
    },
    {
      "subject": "HTTP",
      "predicate": "API",
      "object": "uses",
      "confidence": 0.9,
      "context": "We dump the payload as a JSON string,\n\nand use the request module to make an HTTP post request to th"
    },
    {
      "subject": "API",
      "predicate": "HTTP",
      "object": "used by",
      "confidence": 0.9,
      "context": "We dump the payload as a JSON string,\n\nand use the request module to make an HTTP post request to th"
    },
    {
      "subject": "API endpoint",
      "predicate": "part of",
      "object": "HTTP",
      "confidence": 0.9,
      "context": "We dump the payload as a JSON string,\n\nand use the request module to make an HTTP post request to th"
    },
    {
      "subject": "on ready",
      "predicate": "asynchronous function",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "Both are asynchronous function. The first one is on ready. This function will be called when the bot"
    },
    {
      "subject": "on ready",
      "predicate": "instance of",
      "object": "asynchronous function",
      "confidence": 0.9,
      "context": "Both are asynchronous function. The first one is on ready. This function will be called when the bot"
    },
    {
      "subject": "onready",
      "predicate": "asynchronous function",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "Both are asynchronous function. The first one is on ready. This function will be called when the bot"
    },
    {
      "subject": "ignoring",
      "predicate": "reply",
      "object": "opposite of",
      "confidence": 0.9,
      "context": "So given the message, if the message is coming from the bot itself, the bot ignores the message and "
    },
    {
      "subject": "Ignore",
      "predicate": "reply",
      "object": "opposite of",
      "confidence": 0.9,
      "context": "So given the message, if the message is coming from the bot itself, the bot ignores the message and "
    },
    {
      "subject": "HTTP",
      "predicate": "message",
      "object": "uses",
      "confidence": 0.9,
      "context": "So given the message, if the message is coming from the bot itself, the bot ignores the message and "
    },
    {
      "subject": "authentically",
      "predicate": "authentically",
      "object": "different from",
      "confidence": 0.9,
      "context": "We call self.query using the payload and get back the response.\n\nIf there is a valid generated respo"
    },
    {
      "subject": "pid",
      "predicate": "pid tag",
      "object": "different from",
      "confidence": 0.9,
      "context": "We call self.query using the payload and get back the response.\n\nIf there is a valid generated respo"
    },
    {
      "subject": "pid tag",
      "predicate": "pid",
      "object": "different from",
      "confidence": 0.9,
      "context": "We call self.query using the payload and get back the response.\n\nIf there is a valid generated respo"
    },
    {
      "subject": "authentically",
      "predicate": "authentically",
      "object": "facet of",
      "confidence": 0.9,
      "context": "We call self.query using the payload and get back the response.\n\nIf there is a valid generated respo"
    },
    {
      "subject": "GPT",
      "predicate": "Harry Potter",
      "object": "present in work",
      "confidence": 0.9,
      "context": "In the main function, we just create a bot and pass in the model name. So for me, this is dialogue G"
    },
    {
      "subject": "Harry Potter",
      "predicate": "GPT",
      "object": "characters",
      "confidence": 0.9,
      "context": "In the main function, we just create a bot and pass in the model name. So for me, this is dialogue G"
    },
    {
      "subject": "GPT",
      "predicate": "Harry Potter",
      "object": "used by",
      "confidence": 0.9,
      "context": "In the main function, we just create a bot and pass in the model name. So for me, this is dialogue G"
    },
    {
      "subject": "Harry Potter",
      "predicate": "GPT",
      "object": "uses",
      "confidence": 0.9,
      "context": "In the main function, we just create a bot and pass in the model name. So for me, this is dialogue G"
    },
    {
      "subject": "bot",
      "predicate": "protocol",
      "object": "uses",
      "confidence": 0.9,
      "context": "In the main function, we just create a bot and pass in the model name. So for me, this is dialogue G"
    },
    {
      "subject": "protocol",
      "predicate": "bot",
      "object": "used by",
      "confidence": 0.9,
      "context": "In the main function, we just create a bot and pass in the model name. So for me, this is dialogue G"
    },
    {
      "subject": "Repl.it",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Now that we see that our bot has appeared. However, it shows as offline. So we need to run the Repl."
    },
    {
      "subject": "Repl",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Now that we see that our bot has appeared. However, it shows as offline. So we need to run the Repl."
    },
    {
      "subject": "Python",
      "predicate": "has part",
      "object": "dependencies",
      "confidence": 0.9,
      "context": "Now that we see that our bot has appeared. However, it shows as offline. So we need to run the Repl."
    },
    {
      "subject": "dependencies",
      "predicate": "part of",
      "object": "Python",
      "confidence": 0.9,
      "context": "Now that we see that our bot has appeared. However, it shows as offline. So we need to run the Repl."
    },
    {
      "subject": "permissions, advanced permissions",
      "predicate": "channel setting",
      "object": "facet of",
      "confidence": 0.9,
      "context": "Let's go to the server, and now that the bot is online.\n\nI don't want the bot to appear in the gener"
    },
    {
      "subject": "permissions, advanced permissions",
      "predicate": "channel setting",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "Let's go to the server, and now that the bot is online.\n\nI don't want the bot to appear in the gener"
    },
    {
      "subject": "permissions, advanced permissions",
      "predicate": "part of",
      "object": "server",
      "confidence": 0.9,
      "context": "Let's go to the server, and now that the bot is online.\n\nI don't want the bot to appear in the gener"
    },
    {
      "subject": "try except block",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "And now this bot should work in this Python bot channel, so let's do hello.\n\nAnd we briefly saw that"
    },
    {
      "subject": "try except block",
      "predicate": "exception",
      "object": "use",
      "confidence": 0.9,
      "context": "And now this bot should work in this Python bot channel, so let's do hello.\n\nAnd we briefly saw that"
    },
    {
      "subject": "ChattyBot",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So now we're going to repeat the process for the JavaScript bot. So we go back to the Discord develo"
    },
    {
      "subject": "ChattyBot",
      "predicate": "Node.js",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So now we're going to repeat the process for the JavaScript bot. So we go back to the Discord develo"
    },
    {
      "subject": "ChattyBot JavaScript",
      "predicate": "Node.js",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So now we're going to repeat the process for the JavaScript bot. So we go back to the Discord develo"
    },
    {
      "subject": "Discord bot",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Call this one Discord token, and adding the value.\n\nGreat. Now we have our environment variables set"
    },
    {
      "subject": "Discord",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Call this one Discord token, and adding the value.\n\nGreat. Now we have our environment variables set"
    },
    {
      "subject": "GitHub",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Call this one Discord token, and adding the value.\n\nGreat. Now we have our environment variables set"
    },
    {
      "subject": "fetch",
      "predicate": "part of",
      "object": "HTTP",
      "confidence": 0.9,
      "context": "Let's copy paste, and I will go through the code line by line.\n\nSo first, we import the Discord API "
    },
    {
      "subject": "Discord",
      "predicate": "instance of",
      "object": "API",
      "confidence": 0.9,
      "context": "Let's copy paste, and I will go through the code line by line.\n\nSo first, we import the Discord API "
    },
    {
      "subject": "HTTP",
      "predicate": "instance of",
      "object": "API",
      "confidence": 0.9,
      "context": "Let's copy paste, and I will go through the code line by line.\n\nSo first, we import the Discord API "
    },
    {
      "subject": "asynchronous callback",
      "predicate": "callback",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So when the bot is ready and logged in, we print out logged in as client.user.tag.\n\nAnd here is anot"
    },
    {
      "subject": "asynchronous",
      "predicate": "callback",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So when the bot is ready and logged in, we print out logged in as client.user.tag.\n\nAnd here is anot"
    },
    {
      "subject": "Python script",
      "predicate": "asynchronous",
      "object": "use",
      "confidence": 0.9,
      "context": "So when the bot is ready and logged in, we print out logged in as client.user.tag.\n\nAnd here is anot"
    },
    {
      "subject": "Hugging FaceToken",
      "predicate": "instance of",
      "object": "API key",
      "confidence": 0.9,
      "context": "So the payload is a dictionary containing inputs with text message.content, which is the message tha"
    },
    {
      "subject": "HuggingFaceToken",
      "predicate": "instance of",
      "object": "API key",
      "confidence": 0.9,
      "context": "So the payload is a dictionary containing inputs with text message.content, which is the message tha"
    },
    {
      "subject": "body",
      "predicate": "part of",
      "object": "HTTP",
      "confidence": 0.9,
      "context": "So the response is the result from this call to fetch using HTTP post, given the payload as the body"
    },
    {
      "subject": "headers",
      "predicate": "part of",
      "object": "HTTP",
      "confidence": 0.9,
      "context": "So the response is the result from this call to fetch using HTTP post, given the payload as the body"
    },
    {
      "subject": "body",
      "predicate": "payload",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So the response is the result from this call to fetch using HTTP post, given the payload as the body"
    },
    {
      "subject": "headers",
      "predicate": "payload",
      "object": "subclass of",
      "confidence": 0.9,
      "context": "So the response is the result from this call to fetch using HTTP post, given the payload as the body"
    },
    {
      "subject": "HTTP post",
      "predicate": "part of",
      "object": "HTTP",
      "confidence": 0.9,
      "context": "So the response is the result from this call to fetch using HTTP post, given the payload as the body"
    },
    {
      "subject": "error field",
      "predicate": "debugging",
      "object": "use",
      "confidence": 0.9,
      "context": "If there isn't a generated text field in the response, but instead the response contains an error fi"
    },
    {
      "subject": "debugging",
      "predicate": "error field",
      "object": "uses",
      "confidence": 0.9,
      "context": "If there isn't a generated text field in the response, but instead the response contains an error fi"
    },
    {
      "subject": "IPv6",
      "predicate": "IPv7",
      "object": "followed by",
      "confidence": 0.9,
      "context": "If there isn't a generated text field in the response, but instead the response contains an error fi"
    },
    {
      "subject": "IPv7",
      "predicate": "IPv6",
      "object": "follows",
      "confidence": 0.9,
      "context": "If there isn't a generated text field in the response, but instead the response contains an error fi"
    },
    {
      "subject": "Repl",
      "predicate": "OAuth",
      "object": "uses",
      "confidence": 0.9,
      "context": "So we go to OAuth,\n\ncheck the bot. It's only permission is to send messages. We copy this,\n\npaste in"
    },
    {
      "subject": "authenticallycheck",
      "predicate": "part of",
      "object": "OAuth",
      "confidence": 0.9,
      "context": "So we go to OAuth,\n\ncheck the bot. It's only permission is to send messages. We copy this,\n\npaste in"
    },
    {
      "subject": "Node",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "This time, the one we need to remove is the Python bot.\n\nSo this Python bot shouldn't be able to sen"
    },
    {
      "subject": "npm",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "This time, the one we need to remove is the Python bot.\n\nSo this Python bot shouldn't be able to sen"
    },
    {
      "subject": "npm",
      "predicate": "Node",
      "object": "based on",
      "confidence": 0.9,
      "context": "This time, the one we need to remove is the Python bot.\n\nSo this Python bot shouldn't be able to sen"
    },
    {
      "subject": "ChattyBot JavaScript 1048",
      "predicate": "instance of",
      "object": "ChattyBot",
      "confidence": 0.9,
      "context": "So we need to manually change something in package.json.\n\nSo here, we just use the older version and"
    },
    {
      "subject": "ChattyBot",
      "predicate": "has part",
      "object": "ChattyBot JavaScript 1048",
      "confidence": 0.9,
      "context": "So we need to manually change something in package.json.\n\nSo here, we just use the older version and"
    },
    {
      "subject": "JavaScript",
      "predicate": "influenced by",
      "object": "Python",
      "confidence": 0.9,
      "context": "Looks like our bot is responding to us.\n\nAnd because we have set the bot's permissions correctly, th"
    },
    {
      "subject": "Python bot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So now we have successfully built the bot both in Python and in JavaScript.\n\nOne thing to note is th"
    },
    {
      "subject": "keep alive",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "So now we have successfully built the bot both in Python and in JavaScript.\n\nOne thing to note is th"
    },
    {
      "subject": "Discord Python bot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "Monitor type is going to be HTTPS, friendly name Discord Python bot, the URL is the one we copied fr"
    },
    {
      "subject": "keep alive",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "But because the bot itself is responding, we know that our web server approach has worked.\n\nNow let'"
    },
    {
      "subject": "Uptime Robot",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "But because the bot itself is responding, we know that our web server approach has worked.\n\nNow let'"
    },
    {
      "subject": "keep alive",
      "predicate": "instance of",
      "object": "JavaScript bot",
      "confidence": 0.9,
      "context": "But because the bot itself is responding, we know that our web server approach has worked.\n\nNow let'"
    },
    {
      "subject": "chatbot",
      "predicate": "JavaScript",
      "object": "programming language",
      "confidence": 0.9,
      "context": "It's again an HTTP monitor, Discord JS bot, and the URL is like this,\n\nand we create a monitor.\n\nNow"
    },
    {
      "subject": "chatbot",
      "predicate": "Python",
      "object": "programming language",
      "confidence": 0.9,
      "context": "It's again an HTTP monitor, Discord JS bot, and the URL is like this,\n\nand we create a monitor.\n\nNow"
    }
  ],
  "knowledge_graph": {
    "nodes": [
      {
        "id": "Harry Potter",
        "type": "software",
        "confidence": 0.8982607126235962
      },
      {
        "id": "Transcript Wiki",
        "type": "software",
        "confidence": 0.7358392477035522
      },
      {
        "id": "Google Colab",
        "type": "software",
        "confidence": 0.8887805938720703
      },
      {
        "id": "Hugging Face",
        "type": "ORGANIZATION",
        "confidence": 1.0
      },
      {
        "id": "Uptime Robot",
        "type": "software",
        "confidence": 0.9436659216880798
      },
      {
        "id": "Discord",
        "type": "framework",
        "confidence": 0.95
      },
      {
        "id": "Python",
        "type": "programming_language",
        "confidence": 0.9506585001945496
      },
      {
        "id": "Kaggle",
        "type": "software",
        "confidence": 0.8878624439239502
      },
      {
        "id": "Google",
        "type": "company",
        "confidence": 0.7377576231956482
      },
      {
        "id": "Peppa Pig",
        "type": "character",
        "confidence": 0.9410619139671326
      },
      {
        "id": "Peppa",
        "type": "PERSON",
        "confidence": 0.9
      },
      {
        "id": "Transformer",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Harry",
        "type": "character",
        "confidence": 0.9386613368988037
      },
      {
        "id": "Git",
        "type": "software",
        "confidence": 0.9124588370323181
      },
      {
        "id": "JavaScript",
        "type": "programming_language",
        "confidence": 0.9421895742416382
      },
      {
        "id": "ChattyBot Python",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "Repl",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "ChattyBot",
        "type": "ORGANIZATION",
        "confidence": 0.9
      },
      {
        "id": "the Discord",
        "type": "LOCATION",
        "confidence": 0.8999999999999999
      },
      {
        "id": "Besides Transcript Wiki",
        "type": "PERSON",
        "confidence": 0.85
      },
      {
        "id": "Google Drive",
        "type": "LOCATION",
        "confidence": 0.85
      },
      {
        "id": "PeppaPig.csv",
        "type": "PRODUCT",
        "confidence": 0.85
      },
      {
        "id": "Generative Pre-trained",
        "type": "PERSON",
        "confidence": 0.85
      },
      {
        "id": "Harry Potter 1.csv",
        "type": "PERSON",
        "confidence": 0.85
      },
      {
        "id": "Git Large File Storage",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Python Repl",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Discord Python",
        "type": "ORGANIZATION",
        "confidence": 0.85
      },
      {
        "id": "Rick",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "Morty",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "Lynn",
        "type": "character",
        "confidence": 0.8973746299743652
      },
      {
        "id": "Pandas",
        "type": "ORGANIZATION",
        "confidence": 0.8
      },
      {
        "id": "PyTorch",
        "type": "PERSON",
        "confidence": 0.8
      },
      {
        "id": "OAuth",
        "type": "LOCATION",
        "confidence": 0.8
      },
      {
        "id": "Node",
        "type": "LOCATION",
        "confidence": 0.8
      },
      {
        "id": "the University of Chicago",
        "type": "ORGANIZATION",
        "confidence": 0.7999999999999999
      },
      {
        "id": "Batman on Transcript Wiki",
        "type": "PRODUCT",
        "confidence": 0.7999999999999999
      },
      {
        "id": "The Word Ends With You",
        "type": "PRODUCT",
        "confidence": 0.7999999999999999
      },
      {
        "id": "script.ipynb",
        "type": "ORGANIZATION",
        "confidence": 0.7999999999999999
      },
      {
        "id": "Discord bot.py",
        "type": "PRODUCT",
        "confidence": 0.7999999999999999
      },
      {
        "id": "George",
        "type": "character",
        "confidence": 0.8864147067070007
      },
      {
        "id": "Microsoft",
        "type": "company",
        "confidence": 0.9123840928077698
      },
      {
        "id": "Dev Lab",
        "type": "PERSON",
        "confidence": 0.75
      },
      {
        "id": "UTF-8",
        "type": "LOCATION",
        "confidence": 0.75
      },
      {
        "id": "message.content",
        "type": "PRODUCT",
        "confidence": 0.7499999999999999
      },
      {
        "id": "Rick and Morty",
        "type": "movie",
        "confidence": 0.8205140233039856
      },
      {
        "id": "University of Chicago",
        "type": "organization",
        "confidence": 0.7276162505149841
      },
      {
        "id": "Discord bot",
        "type": "software",
        "confidence": 0.95
      },
      {
        "id": "bot",
        "type": "software",
        "confidence": 0.95
      },
      {
        "id": "favorite character",
        "type": "character",
        "confidence": 0.95
      },
      {
        "id": "model",
        "type": "model",
        "confidence": 0.953525185585022
      },
      {
        "id": "character",
        "type": "character",
        "confidence": 0.8501603007316589
      },
      {
        "id": "video game",
        "type": "game",
        "confidence": 0.95
      },
      {
        "id": "video games",
        "type": "game",
        "confidence": 0.95
      },
      {
        "id": "game",
        "type": "game",
        "confidence": 0.95
      },
      {
        "id": "you",
        "type": "character",
        "confidence": 0.95
      },
      {
        "id": "drive",
        "type": "hardware",
        "confidence": 0.9524496793746948
      },
      {
        "id": "regular expression",
        "type": "algorithm",
        "confidence": 0.8051311373710632
      },
      {
        "id": "Mama Pig",
        "type": "character",
        "confidence": 0.9026328921318054
      },
      {
        "id": "PeppaPig",
        "type": "character",
        "confidence": 0.9763714075088501
      },
      {
        "id": "GPT model",
        "type": "model",
        "confidence": 0.804124653339386
      },
      {
        "id": "we",
        "type": "character",
        "confidence": 0.8083429336547852
      },
      {
        "id": "our character",
        "type": "character",
        "confidence": 0.7857029438018799
      },
      {
        "id": "12 epochs",
        "type": "time",
        "confidence": 0.7145524024963379
      },
      {
        "id": "chatbot",
        "type": "software",
        "confidence": 0.95
      },
      {
        "id": "username",
        "type": "person",
        "confidence": 0.8699728846549988
      },
      {
        "id": "user",
        "type": "person",
        "confidence": 0.95
      },
      {
        "id": "channel",
        "type": "channel",
        "confidence": 0.7005025148391724
      },
      {
        "id": "API",
        "type": "api",
        "confidence": 0.7799608707427979
      },
      {
        "id": "HTTP",
        "type": "channel",
        "confidence": 0.760124921798706
      },
      {
        "id": "Hugging Face API",
        "type": "api",
        "confidence": 0.9289038181304932
      },
      {
        "id": "Discord API",
        "type": "api",
        "confidence": 0.9273198843002319
      },
      {
        "id": "general channel",
        "type": "channel",
        "confidence": 0.9639551043510437
      },
      {
        "id": "Python channel",
        "type": "channel",
        "confidence": 0.9566041231155396
      },
      {
        "id": "JS channel",
        "type": "channel",
        "confidence": 0.8923065066337585
      },
      {
        "id": "JavaScript channel",
        "type": "channel",
        "confidence": 0.840682327747345
      },
      {
        "id": "npm",
        "type": "channel",
        "confidence": 0.7125272154808044
      },
      {
        "id": "Discord channel",
        "type": "channel",
        "confidence": 0.845048725605011
      },
      {
        "id": "web server",
        "type": "software",
        "confidence": 0.7969065308570862
      },
      {
        "id": "HTTPS",
        "type": "protocol",
        "confidence": 0.9097098112106323
      },
      {
        "id": "Discord JS bot",
        "type": "software",
        "confidence": 0.8758285641670227
      },
      {
        "id": "use",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "artificial intelligence",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "uses",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "subclass of",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "AI chatbot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "programming language",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "owner of",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Google search",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "data set",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "genre",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "dialogue",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "model training",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "characters",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "present in work",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "fandom website",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "dialogues",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "used by",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "text messages",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "text message",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "two-column",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "character line",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "CSV",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "mother",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "child",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "sibling",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "result data frame",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "data frame",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "parametric",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "train the model",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "DF.csv",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Transformers",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "modules",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "platform",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Transformers module",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Harry Potter 1",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Harry Potter data set",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "separating",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "different from",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "comma",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "semicolon",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "lines",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "has parts of the class",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "conversational",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "conversational chatbot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "training set",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "test set",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "GPT small",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "developer",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "pre-trained",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "small",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "My production chatbot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "medium model",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "num train epochs",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "hyperparameters",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "hyperparameter",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "batch size",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "overfitting",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "has effect",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "learning rate",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "temperature",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "neurotransmitter",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "epochs",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "train",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "confused",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "perplexity answer",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "confused answer",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "command line client",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "command line",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Git LFS",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "repository",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "commit",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Python bot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "JavaScript bot",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "bots",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "API tokens",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "OS module",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "API endpoint",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "bearer",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "on ready",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "asynchronous function",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "onready",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "ignoring",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "opposite of",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Ignore",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "authentically",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "pid",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "pid tag",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "facet of",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "GPT",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "protocol",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Repl.it",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "dependencies",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "permissions, advanced permissions",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "server",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "try except block",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "ChattyBot JavaScript",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "GitHub",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "fetch",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "asynchronous callback",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "asynchronous",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Python script",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Hugging FaceToken",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "API key",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "HuggingFaceToken",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "body",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "headers",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "HTTP post",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "error field",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "debugging",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "IPv6",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "followed by",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "IPv7",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "follows",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "authenticallycheck",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "based on",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "ChattyBot JavaScript 1048",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "keep alive",
        "type": "unknown",
        "confidence": 0.9
      },
      {
        "id": "Discord Python bot",
        "type": "unknown",
        "confidence": 0.9
      }
    ],
    "edges": [
      {
        "source": "Harry Potter",
        "target": "Harry Potter 1",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter",
        "target": "characters",
        "predicate": "GPT",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter",
        "target": "uses",
        "predicate": "GPT",
        "confidence": 0.9
      },
      {
        "source": "Google Colab",
        "target": "Google Drive",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "command line client",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "command line",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "use",
        "predicate": "authorization",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "PyTorch",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "uses",
        "predicate": "PyTorch",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "API tokens",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "API",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Hugging Face",
        "target": "bearer",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Uptime Robot",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "AI chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "Discord",
        "target": "API",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Python",
        "target": "JavaScript",
        "predicate": "influenced by",
        "confidence": 0.9
      },
      {
        "source": "Python",
        "target": "OS module",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Python",
        "target": "dependencies",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Kaggle",
        "target": "Google",
        "predicate": "owned by",
        "confidence": 0.9
      },
      {
        "source": "Kaggle",
        "target": "Google search",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Google",
        "target": "owner of",
        "predicate": "Kaggle",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "characters",
        "predicate": "Peppa Pig",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "present in work",
        "predicate": "Peppa Pig",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "mother",
        "predicate": "Mama Pig",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "Mama Pig",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "sibling",
        "predicate": "George",
        "confidence": 0.9
      },
      {
        "source": "Peppa Pig",
        "target": "Peppa Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "Harry",
        "target": "conversational chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Git",
        "target": "repository",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Git",
        "target": "uses",
        "predicate": "LFS",
        "confidence": 0.9
      },
      {
        "source": "JavaScript",
        "target": "Python",
        "predicate": "influenced by",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot Python",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Repl",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Repl",
        "target": "uses",
        "predicate": "OAuth",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot",
        "target": "programming language",
        "predicate": "Node.js",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot",
        "target": "ChattyBot JavaScript 1048",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Google Drive",
        "target": "Google Colab",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Python Repl",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "Pandas",
        "target": "use",
        "predicate": "CSV",
        "confidence": 0.9
      },
      {
        "source": "Pandas",
        "target": "uses",
        "predicate": "CSV",
        "confidence": 0.9
      },
      {
        "source": "PyTorch",
        "target": "use",
        "predicate": "text generation",
        "confidence": 0.9
      },
      {
        "source": "Node",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "The Word Ends With You",
        "target": "game",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "The Word Ends With You",
        "target": "fandom website",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "George",
        "target": "Mama Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "George",
        "target": "Peppa Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "Rick and Morty",
        "target": "genre",
        "predicate": "dialogue",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "use",
        "predicate": "artificial intelligence",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "artificial intelligence",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "uses",
        "predicate": "artificial intelligence",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Discord bot",
        "target": "subclass of",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "bot",
        "target": "uses",
        "predicate": "protocol",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "child",
        "predicate": "Peppa Pig",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "Peppa Pig",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "sibling",
        "predicate": "Peppa Pig",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "George",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "Mama Pig",
        "target": "Mama Pig",
        "predicate": "sibling",
        "confidence": 0.9
      },
      {
        "source": "chatbot",
        "target": "subclass of",
        "predicate": "conversational",
        "confidence": 0.9
      },
      {
        "source": "chatbot",
        "target": "uses",
        "predicate": "text message",
        "confidence": 0.9
      },
      {
        "source": "chatbot",
        "target": "use",
        "predicate": "conversational",
        "confidence": 0.9
      },
      {
        "source": "chatbot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "API",
        "target": "used by",
        "predicate": "HTTP",
        "confidence": 0.9
      },
      {
        "source": "HTTP",
        "target": "uses",
        "predicate": "message",
        "confidence": 0.9
      },
      {
        "source": "HTTP",
        "target": "API",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "npm",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "npm",
        "target": "based on",
        "predicate": "Node",
        "confidence": 0.9
      },
      {
        "source": "data set",
        "target": "use",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "data set",
        "target": "dialogue",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "data set",
        "target": "data frame",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "data set",
        "target": "used by",
        "predicate": "train",
        "confidence": 0.9
      },
      {
        "source": "model training",
        "target": "uses",
        "predicate": "data sets",
        "confidence": 0.9
      },
      {
        "source": "model training",
        "target": "subclass of",
        "predicate": "data set",
        "confidence": 0.9
      },
      {
        "source": "dialogues",
        "target": "used by",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "text messages",
        "target": "used by",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "text message",
        "target": "used by",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "two-column",
        "target": "uses",
        "predicate": "character line",
        "confidence": 0.9
      },
      {
        "source": "two-column",
        "target": "subclass of",
        "predicate": "character line",
        "confidence": 0.9
      },
      {
        "source": "character line",
        "target": "used by",
        "predicate": "two-column",
        "confidence": 0.9
      },
      {
        "source": "character line",
        "target": "use",
        "predicate": "two-column",
        "confidence": 0.9
      },
      {
        "source": "CSV",
        "target": "used by",
        "predicate": "Pandas",
        "confidence": 0.9
      },
      {
        "source": "sibling",
        "target": "sibling",
        "predicate": "Mama Pig",
        "confidence": 0.9
      },
      {
        "source": "sibling",
        "target": "Peppa Pig",
        "predicate": "Mama Pig",
        "confidence": 0.9
      },
      {
        "source": "sibling",
        "target": "George",
        "predicate": "Peppa Pig",
        "confidence": 0.9
      },
      {
        "source": "result data frame",
        "target": "subclass of",
        "predicate": "data frame",
        "confidence": 0.9
      },
      {
        "source": "result data frame",
        "target": "data frame",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "data frame",
        "target": "data set",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "parametric",
        "target": "subclass of",
        "predicate": "regular expression",
        "confidence": 0.9
      },
      {
        "source": "parametric",
        "target": "lines",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "parametric",
        "target": "has parts of the class",
        "predicate": "lines",
        "confidence": 0.9
      },
      {
        "source": "train the model",
        "target": "subclass of",
        "predicate": "model training",
        "confidence": 0.9
      },
      {
        "source": "train the model",
        "target": "use",
        "predicate": "model training",
        "confidence": 0.9
      },
      {
        "source": "DF.csv",
        "target": "PeppaPig",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Transformers",
        "target": "modules",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Transformers",
        "target": "platform",
        "predicate": "GPUs",
        "confidence": 0.9
      },
      {
        "source": "Transformers module",
        "target": "platform",
        "predicate": "GPUs",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter 1",
        "target": "Harry Potter",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter 1",
        "target": "Harry Potter data set",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "Harry Potter data set",
        "target": "Harry Potter 1",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "separating",
        "target": "different from",
        "predicate": "comma",
        "confidence": 0.9
      },
      {
        "source": "separating",
        "target": "semicolon",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "comma",
        "target": "different from",
        "predicate": "separating",
        "confidence": 0.9
      },
      {
        "source": "semicolon",
        "target": "separating",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "semicolon",
        "target": "use",
        "predicate": "separating",
        "confidence": 0.9
      },
      {
        "source": "lines",
        "target": "parametric",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "conversational",
        "target": "chatbot",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "conversational",
        "target": "subclass of",
        "predicate": "chatbot",
        "confidence": 0.9
      },
      {
        "source": "training set",
        "target": "subclass of",
        "predicate": "data set",
        "confidence": 0.9
      },
      {
        "source": "test set",
        "target": "subclass of",
        "predicate": "data set",
        "confidence": 0.9
      },
      {
        "source": "GPT small",
        "target": "developer",
        "predicate": "Microsoft",
        "confidence": 0.9
      },
      {
        "source": "pre-trained",
        "target": "subclass of",
        "predicate": "training",
        "confidence": 0.9
      },
      {
        "source": "small",
        "target": "developer",
        "predicate": "Microsoft",
        "confidence": 0.9
      },
      {
        "source": "My production chatbot",
        "target": "medium model",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "My production chatbot",
        "target": "use",
        "predicate": "medium model",
        "confidence": 0.9
      },
      {
        "source": "My production chatbot",
        "target": "chatbot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "num train epochs",
        "target": "hyperparameters",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "num train epochs",
        "target": "subclass of",
        "predicate": "hyperparameters",
        "confidence": 0.9
      },
      {
        "source": "num train epochs",
        "target": "hyperparameter",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "batch size",
        "target": "subclass of",
        "predicate": "hyperparameter",
        "confidence": 0.9
      },
      {
        "source": "batch size",
        "target": "hyperparameter",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "overfitting",
        "target": "has effect",
        "predicate": "gradient",
        "confidence": 0.9
      },
      {
        "source": "learning rate",
        "target": "subclass of",
        "predicate": "hyperparameters",
        "confidence": 0.9
      },
      {
        "source": "learning rate",
        "target": "hyperparameters",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "temperature",
        "target": "subclass of",
        "predicate": "hyperparameters",
        "confidence": 0.9
      },
      {
        "source": "temperature",
        "target": "hyperparameters",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "neurotransmitter",
        "target": "different from",
        "predicate": "neurotransmitter",
        "confidence": 0.9
      },
      {
        "source": "neurotransmitter",
        "target": "subclass of",
        "predicate": "neurotransmitter",
        "confidence": 0.9
      },
      {
        "source": "epochs",
        "target": "data set",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "train",
        "target": "uses",
        "predicate": "data set",
        "confidence": 0.9
      },
      {
        "source": "confused",
        "target": "subclass of",
        "predicate": "perplexity answer",
        "confidence": 0.9
      },
      {
        "source": "perplexity answer",
        "target": "confused",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "confused answer",
        "target": "confused",
        "predicate": "has part",
        "confidence": 0.9
      },
      {
        "source": "Git LFS",
        "target": "repository",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Git LFS",
        "target": "use",
        "predicate": "Git",
        "confidence": 0.9
      },
      {
        "source": "Git LFS",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "commit",
        "target": "Git",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "commit",
        "target": "used by",
        "predicate": "Git",
        "confidence": 0.9
      },
      {
        "source": "Python bot",
        "target": "different from",
        "predicate": "JavaScript bot",
        "confidence": 0.9
      },
      {
        "source": "Python bot",
        "target": "bots",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Python bot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "JavaScript bot",
        "target": "different from",
        "predicate": "Python bot",
        "confidence": 0.9
      },
      {
        "source": "JavaScript bot",
        "target": "bots",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "OS module",
        "target": "Python",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "API endpoint",
        "target": "API",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "API endpoint",
        "target": "use",
        "predicate": "API",
        "confidence": 0.9
      },
      {
        "source": "API endpoint",
        "target": "HTTP",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "on ready",
        "target": "subclass of",
        "predicate": "asynchronous function",
        "confidence": 0.9
      },
      {
        "source": "on ready",
        "target": "asynchronous function",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "onready",
        "target": "subclass of",
        "predicate": "asynchronous function",
        "confidence": 0.9
      },
      {
        "source": "ignoring",
        "target": "opposite of",
        "predicate": "reply",
        "confidence": 0.9
      },
      {
        "source": "Ignore",
        "target": "opposite of",
        "predicate": "reply",
        "confidence": 0.9
      },
      {
        "source": "authentically",
        "target": "different from",
        "predicate": "authentically",
        "confidence": 0.9
      },
      {
        "source": "authentically",
        "target": "facet of",
        "predicate": "authentically",
        "confidence": 0.9
      },
      {
        "source": "pid",
        "target": "different from",
        "predicate": "pid tag",
        "confidence": 0.9
      },
      {
        "source": "pid tag",
        "target": "different from",
        "predicate": "pid",
        "confidence": 0.9
      },
      {
        "source": "GPT",
        "target": "present in work",
        "predicate": "Harry Potter",
        "confidence": 0.9
      },
      {
        "source": "GPT",
        "target": "used by",
        "predicate": "Harry Potter",
        "confidence": 0.9
      },
      {
        "source": "protocol",
        "target": "used by",
        "predicate": "bot",
        "confidence": 0.9
      },
      {
        "source": "Repl.it",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "dependencies",
        "target": "Python",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "permissions, advanced permissions",
        "target": "facet of",
        "predicate": "channel setting",
        "confidence": 0.9
      },
      {
        "source": "permissions, advanced permissions",
        "target": "subclass of",
        "predicate": "channel setting",
        "confidence": 0.9
      },
      {
        "source": "permissions, advanced permissions",
        "target": "server",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "try except block",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      },
      {
        "source": "try except block",
        "target": "use",
        "predicate": "exception",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot JavaScript",
        "target": "programming language",
        "predicate": "Node.js",
        "confidence": 0.9
      },
      {
        "source": "GitHub",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "fetch",
        "target": "HTTP",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "asynchronous callback",
        "target": "subclass of",
        "predicate": "callback",
        "confidence": 0.9
      },
      {
        "source": "asynchronous",
        "target": "subclass of",
        "predicate": "callback",
        "confidence": 0.9
      },
      {
        "source": "Python script",
        "target": "use",
        "predicate": "asynchronous",
        "confidence": 0.9
      },
      {
        "source": "Hugging FaceToken",
        "target": "API key",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "HuggingFaceToken",
        "target": "API key",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "body",
        "target": "HTTP",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "body",
        "target": "subclass of",
        "predicate": "payload",
        "confidence": 0.9
      },
      {
        "source": "headers",
        "target": "HTTP",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "headers",
        "target": "subclass of",
        "predicate": "payload",
        "confidence": 0.9
      },
      {
        "source": "HTTP post",
        "target": "HTTP",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "error field",
        "target": "use",
        "predicate": "debugging",
        "confidence": 0.9
      },
      {
        "source": "debugging",
        "target": "uses",
        "predicate": "error field",
        "confidence": 0.9
      },
      {
        "source": "IPv6",
        "target": "followed by",
        "predicate": "IPv7",
        "confidence": 0.9
      },
      {
        "source": "IPv7",
        "target": "follows",
        "predicate": "IPv6",
        "confidence": 0.9
      },
      {
        "source": "authenticallycheck",
        "target": "OAuth",
        "predicate": "part of",
        "confidence": 0.9
      },
      {
        "source": "ChattyBot JavaScript 1048",
        "target": "ChattyBot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "keep alive",
        "target": "programming language",
        "predicate": "JavaScript",
        "confidence": 0.9
      },
      {
        "source": "keep alive",
        "target": "JavaScript bot",
        "predicate": "instance of",
        "confidence": 0.9
      },
      {
        "source": "Discord Python bot",
        "target": "programming language",
        "predicate": "Python",
        "confidence": 0.9
      }
    ],
    "node_count": 198,
    "edge_count": 191,
    "connected_components": 63,
    "density": 0.004896682561657181
  },
  "key_facts": [
    {
      "fact": "Discord bot artificial intelligence use",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "use",
      "type": "relationship"
    },
    {
      "fact": "Create a Discord bot using AI to mimic your favorite character's speech.",
      "confidence": 0.9,
      "timestamp": 0,
      "type": "key_point"
    },
    {
      "fact": "Harry Potter has spacy_label: PERSON",
      "confidence": 1.0,
      "subject": "Harry Potter",
      "type": "entity_property"
    },
    {
      "fact": "Discord bot instance of artificial intelligence",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "instance of",
      "object": "artificial intelligence",
      "type": "relationship"
    },
    {
      "fact": "Tutorial evolved from a joke between friends into a popular project.",
      "confidence": 0.9,
      "timestamp": 1,
      "type": "key_point"
    },
    {
      "fact": "Harry Potter has start_char: 77",
      "confidence": 1.0,
      "subject": "Harry Potter",
      "type": "entity_property"
    },
    {
      "fact": "Discord bot artificial intelligence uses",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "artificial intelligence",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Updated tutorial includes more characters and data sourcing techniques.",
      "confidence": 0.9,
      "timestamp": 2,
      "type": "key_point"
    },
    {
      "fact": "Harry Potter has end_char: 89",
      "confidence": 1.0,
      "subject": "Harry Potter",
      "type": "entity_property"
    },
    {
      "fact": "chatbot AI subclass of",
      "confidence": 0.9,
      "subject": "chatbot",
      "predicate": "AI",
      "object": "subclass of",
      "type": "relationship"
    },
    {
      "fact": "Covers model training, deployment, common errors, and solutions.",
      "confidence": 0.9,
      "timestamp": 3,
      "type": "key_point"
    },
    {
      "fact": "Transcript Wiki has spacy_label: PERSON",
      "confidence": 1.0,
      "subject": "Transcript Wiki",
      "type": "entity_property"
    },
    {
      "fact": "Discord instance of chatbot",
      "confidence": 0.9,
      "subject": "Discord",
      "predicate": "instance of",
      "object": "chatbot",
      "type": "relationship"
    },
    {
      "fact": "Builds the bot using Python and JavaScript.",
      "confidence": 0.9,
      "timestamp": 4,
      "type": "key_point"
    },
    {
      "fact": "Transcript Wiki has start_char: 1684",
      "confidence": 1.0,
      "subject": "Transcript Wiki",
      "type": "entity_property"
    },
    {
      "fact": "Discord instance of AI chatbot",
      "confidence": 0.9,
      "subject": "Discord",
      "predicate": "instance of",
      "object": "AI chatbot",
      "type": "relationship"
    },
    {
      "fact": "Deploys the bot to a Discord server, limiting it to specific channels and ensuring continuous operation.",
      "confidence": 0.9,
      "timestamp": 5,
      "type": "key_point"
    },
    {
      "fact": "Transcript Wiki has end_char: 1699",
      "confidence": 1.0,
      "subject": "Transcript Wiki",
      "type": "entity_property"
    },
    {
      "fact": "Python influenced by JavaScript",
      "confidence": 0.9,
      "subject": "Python",
      "predicate": "influenced by",
      "object": "JavaScript",
      "type": "relationship"
    },
    {
      "fact": "Data sources include Kaggle, Transcript Wiki, and fandom websites.",
      "confidence": 0.9,
      "timestamp": 6,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has spacy_label: ORG",
      "confidence": 1.0,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Discord bot Python programming language",
      "confidence": 0.9,
      "subject": "Discord bot",
      "predicate": "Python",
      "object": "programming language",
      "type": "relationship"
    },
    {
      "fact": "Kaggle offers pre-made dialogue datasets for various characters.",
      "confidence": 0.9,
      "timestamp": 7,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has start_char: 4538",
      "confidence": 1.0,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Discord Python programming language",
      "confidence": 0.9,
      "subject": "Discord",
      "predicate": "Python",
      "object": "programming language",
      "type": "relationship"
    },
    {
      "fact": "If Kaggle data is unavailable, Transcript Wiki and Google searches for transcripts are used.",
      "confidence": 0.9,
      "timestamp": 8,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has end_char: 4550",
      "confidence": 1.0,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Kaggle owned by Google",
      "confidence": 0.9,
      "subject": "Kaggle",
      "predicate": "owned by",
      "object": "Google",
      "type": "relationship"
    },
    {
      "fact": "For real-life characters, interview scripts or personal messages can be used.",
      "confidence": 0.9,
      "timestamp": 9,
      "type": "key_point"
    },
    {
      "fact": "Hugging Face has spacy_label: ORG",
      "confidence": 1.0,
      "subject": "Hugging Face",
      "type": "entity_property"
    },
    {
      "fact": "Google Kaggle owner of",
      "confidence": 0.9,
      "subject": "Google",
      "predicate": "Kaggle",
      "object": "owner of",
      "type": "relationship"
    },
    {
      "fact": "Raw transcripts are parsed and converted into two-column datasets using Google Colab, regular expressions, and Pandas.",
      "confidence": 0.9,
      "timestamp": 10,
      "type": "key_point"
    },
    {
      "fact": "Hugging Face has start_char: 12916",
      "confidence": 1.0,
      "subject": "Hugging Face",
      "type": "entity_property"
    },
    {
      "fact": "Kaggle instance of Google search",
      "confidence": 0.9,
      "subject": "Kaggle",
      "predicate": "instance of",
      "object": "Google search",
      "type": "relationship"
    },
    {
      "fact": "Regular expression patterns are used to extract character names and lines from transcripts.",
      "confidence": 0.9,
      "timestamp": 11,
      "type": "key_point"
    },
    {
      "fact": "Hugging Face has end_char: 12928",
      "confidence": 1.0,
      "subject": "Hugging Face",
      "type": "entity_property"
    },
    {
      "fact": "data set chatbot use",
      "confidence": 0.9,
      "subject": "data set",
      "predicate": "chatbot",
      "object": "use",
      "type": "relationship"
    },
    {
      "fact": "Data is cleaned and transformed into a usable format for model training.",
      "confidence": 0.9,
      "timestamp": 12,
      "type": "key_point"
    },
    {
      "fact": "Uptime Robot has spacy_label: ORG",
      "confidence": 1.0,
      "subject": "Uptime Robot",
      "type": "entity_property"
    },
    {
      "fact": "Rick and Morty dialogue genre",
      "confidence": 0.9,
      "subject": "Rick and Morty",
      "predicate": "dialogue",
      "object": "genre",
      "type": "relationship"
    },
    {
      "fact": "A GPT (Generative Pre-trained Transformer) model is used for training.",
      "confidence": 0.9,
      "timestamp": 13,
      "type": "key_point"
    },
    {
      "fact": "Uptime Robot has start_char: 26484",
      "confidence": 1.0,
      "subject": "Uptime Robot",
      "type": "entity_property"
    },
    {
      "fact": "data set has part dialogue",
      "confidence": 0.9,
      "subject": "data set",
      "predicate": "has part",
      "object": "dialogue",
      "type": "relationship"
    },
    {
      "fact": "GPU acceleration is used for faster model training.",
      "confidence": 0.9,
      "timestamp": 14,
      "type": "key_point"
    },
    {
      "fact": "Uptime Robot has end_char: 26496",
      "confidence": 1.0,
      "subject": "Uptime Robot",
      "type": "entity_property"
    },
    {
      "fact": "model training data set uses",
      "confidence": 0.9,
      "subject": "model training",
      "predicate": "data set",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Kaggle API key is required to download datasets from Kaggle.",
      "confidence": 0.9,
      "timestamp": 15,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has spacy_label: FAC",
      "confidence": 0.95,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "model training data set subclass of",
      "confidence": 0.9,
      "subject": "model training",
      "predicate": "data set",
      "object": "subclass of",
      "type": "relationship"
    },
    {
      "fact": "Data is split into training and testing sets to prevent overfitting.",
      "confidence": 0.9,
      "timestamp": 16,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has start_char: 4353",
      "confidence": 0.95,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "model training data sets uses",
      "confidence": 0.9,
      "subject": "model training",
      "predicate": "data sets",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "The model is trained on the training set and evaluated on the test set.",
      "confidence": 0.9,
      "timestamp": 17,
      "type": "key_point"
    },
    {
      "fact": "Google Colab has end_char: 4365",
      "confidence": 0.95,
      "subject": "Google Colab",
      "type": "entity_property"
    },
    {
      "fact": "Peppa Pig Peppa Pig characters",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "predicate": "Peppa Pig",
      "object": "characters",
      "type": "relationship"
    },
    {
      "fact": "Contextual information is used to generate more organic and relevant responses.",
      "confidence": 0.9,
      "timestamp": 18,
      "type": "key_point"
    },
    {
      "fact": "Discord has spacy_label: ORG",
      "confidence": 0.9,
      "subject": "Discord",
      "type": "entity_property"
    },
    {
      "fact": "Peppa Pig Peppa Pig present in work",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "predicate": "Peppa Pig",
      "object": "present in work",
      "type": "relationship"
    },
    {
      "fact": "Discord has start_char: 15",
      "confidence": 0.9,
      "subject": "Discord",
      "type": "entity_property"
    },
    {
      "fact": "The Word Ends With You instance of game",
      "confidence": 0.9,
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "game",
      "type": "relationship"
    },
    {
      "fact": "Discord has end_char: 22",
      "confidence": 0.9,
      "subject": "Discord",
      "type": "entity_property"
    },
    {
      "fact": "The Word Ends With You instance of fandom website",
      "confidence": 0.9,
      "subject": "The Word Ends With You",
      "predicate": "instance of",
      "object": "fandom website",
      "type": "relationship"
    },
    {
      "fact": "Python has spacy_label: GPE",
      "confidence": 0.9,
      "subject": "Python",
      "type": "entity_property"
    },
    {
      "fact": "chatbot dialogues uses",
      "confidence": 0.9,
      "subject": "chatbot",
      "predicate": "dialogues",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Python has start_char: 1347",
      "confidence": 0.9,
      "subject": "Python",
      "type": "entity_property"
    },
    {
      "fact": "dialogues chatbot used by",
      "confidence": 0.9,
      "subject": "dialogues",
      "predicate": "chatbot",
      "object": "used by",
      "type": "relationship"
    },
    {
      "fact": "Python has end_char: 1353",
      "confidence": 0.9,
      "subject": "Python",
      "type": "entity_property"
    },
    {
      "fact": "chatbot text messages uses",
      "confidence": 0.9,
      "subject": "chatbot",
      "predicate": "text messages",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Kaggle has spacy_label: PERSON",
      "confidence": 0.9,
      "subject": "Kaggle",
      "type": "entity_property"
    },
    {
      "fact": "text messages chatbot used by",
      "confidence": 0.9,
      "subject": "text messages",
      "predicate": "chatbot",
      "object": "used by",
      "type": "relationship"
    },
    {
      "fact": "Kaggle has start_char: 1676",
      "confidence": 0.9,
      "subject": "Kaggle",
      "type": "entity_property"
    },
    {
      "fact": "chatbot text message uses",
      "confidence": 0.9,
      "subject": "chatbot",
      "predicate": "text message",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Kaggle has end_char: 1682",
      "confidence": 0.9,
      "subject": "Kaggle",
      "type": "entity_property"
    },
    {
      "fact": "text message chatbot used by",
      "confidence": 0.9,
      "subject": "text message",
      "predicate": "chatbot",
      "object": "used by",
      "type": "relationship"
    },
    {
      "fact": "Google has spacy_label: ORG",
      "confidence": 0.9,
      "subject": "Google",
      "type": "entity_property"
    },
    {
      "fact": "two-column character line uses",
      "confidence": 0.9,
      "subject": "two-column",
      "predicate": "character line",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Google has start_char: 1756",
      "confidence": 0.9,
      "subject": "Google",
      "type": "entity_property"
    },
    {
      "fact": "character line two-column used by",
      "confidence": 0.9,
      "subject": "character line",
      "predicate": "two-column",
      "object": "used by",
      "type": "relationship"
    },
    {
      "fact": "Google has end_char: 1762",
      "confidence": 0.9,
      "subject": "Google",
      "type": "entity_property"
    },
    {
      "fact": "character line two-column use",
      "confidence": 0.9,
      "subject": "character line",
      "predicate": "two-column",
      "object": "use",
      "type": "relationship"
    },
    {
      "fact": "Peppa Pig has spacy_label: PERSON",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "type": "entity_property"
    },
    {
      "fact": "two-column character line subclass of",
      "confidence": 0.9,
      "subject": "two-column",
      "predicate": "character line",
      "object": "subclass of",
      "type": "relationship"
    },
    {
      "fact": "Peppa Pig has start_char: 2580",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "type": "entity_property"
    },
    {
      "fact": "Google Colab has part Google Drive",
      "confidence": 0.9,
      "subject": "Google Colab",
      "predicate": "has part",
      "object": "Google Drive",
      "type": "relationship"
    },
    {
      "fact": "Peppa Pig has end_char: 2589",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "type": "entity_property"
    },
    {
      "fact": "Google Drive part of Google Colab",
      "confidence": 0.9,
      "subject": "Google Drive",
      "predicate": "part of",
      "object": "Google Colab",
      "type": "relationship"
    },
    {
      "fact": "Peppa has spacy_label: PERSON",
      "confidence": 0.9,
      "subject": "Peppa",
      "type": "entity_property"
    },
    {
      "fact": "Google Drive has part Google Colab",
      "confidence": 0.9,
      "subject": "Google Drive",
      "predicate": "has part",
      "object": "Google Colab",
      "type": "relationship"
    },
    {
      "fact": "Peppa has start_char: 2946",
      "confidence": 0.9,
      "subject": "Peppa",
      "type": "entity_property"
    },
    {
      "fact": "CSV Pandas used by",
      "confidence": 0.9,
      "subject": "CSV",
      "predicate": "Pandas",
      "object": "used by",
      "type": "relationship"
    },
    {
      "fact": "Peppa has end_char: 2951",
      "confidence": 0.9,
      "subject": "Peppa",
      "type": "entity_property"
    },
    {
      "fact": "Pandas CSV use",
      "confidence": 0.9,
      "subject": "Pandas",
      "predicate": "CSV",
      "object": "use",
      "type": "relationship"
    },
    {
      "fact": "Transformer has spacy_label: ORG",
      "confidence": 0.9,
      "subject": "Transformer",
      "type": "entity_property"
    },
    {
      "fact": "Pandas CSV uses",
      "confidence": 0.9,
      "subject": "Pandas",
      "predicate": "CSV",
      "object": "uses",
      "type": "relationship"
    },
    {
      "fact": "Transformer has start_char: 7239",
      "confidence": 0.9,
      "subject": "Transformer",
      "type": "entity_property"
    },
    {
      "fact": "Peppa Pig Mama Pig mother",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "predicate": "Mama Pig",
      "object": "mother",
      "type": "relationship"
    },
    {
      "fact": "Transformer has end_char: 7250",
      "confidence": 0.9,
      "subject": "Transformer",
      "type": "entity_property"
    },
    {
      "fact": "Mama Pig Peppa Pig child",
      "confidence": 0.9,
      "subject": "Mama Pig",
      "predicate": "Peppa Pig",
      "object": "child",
      "type": "relationship"
    },
    {
      "fact": "Kaggle has spacy_label: GPE",
      "confidence": 0.9,
      "subject": "Kaggle",
      "type": "entity_property"
    },
    {
      "fact": "Peppa Pig has part Mama Pig",
      "confidence": 0.9,
      "subject": "Peppa Pig",
      "predicate": "has part",
      "object": "Mama Pig",
      "type": "relationship"
    }
  ],
  "extraction_stats": {
    "spacy_entities": 49,
    "gliner_entities": 112,
    "llm_validated": 107,
    "relationships": 210,
    "graph_nodes": 198,
    "graph_edges": 191
  }
}